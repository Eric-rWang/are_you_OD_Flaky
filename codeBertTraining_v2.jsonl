{"code": "def test_check_authenticated_access_to_collection(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_authenticated_access_to_dataset(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_authenticated_access_to_object(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_authenticated_access_to_users(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_authenticated_access_to_sessions(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_authenticated_access_to_apikeys(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_authenticated_access_to_preferences(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_login_logout():\n\n    \"\"\"\n    See if we can login and log out correctly.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-loginlogout.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-loginlogout.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-loginlogout.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser3@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser3@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # try logging in now with correct password\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    # this should fail because we haven't verified our email yet\n    assert login[\"success\"] is False\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # now make a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n\n    # and now try to log in again\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    assert login[\"success\"] is True\n\n    # make sure the session token we used to log in is gone\n    # check if our session was deleted correctly\n    session_still_exists = actions.auth_session_exists(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n    )\n    assert session_still_exists[\"success\"] is False\n\n    # start a new session with this user's user ID\n    authenticated_session_token = actions.auth_session_new(\n        {\n            \"user_id\": login[\"user_id\"],\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    # now see if we can log out\n    logged_out = actions.auth_user_logout(\n        {\n            \"session_token\": authenticated_session_token[\"session_token\"],\n            \"user_id\": login[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    assert logged_out[\"success\"] is True\n\n    # check if our session was deleted correctly\n    session_still_exists = actions.auth_session_exists(\n        {\n            \"session_token\": authenticated_session_token,\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-loginlogout.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    assert session_still_exists[\"success\"] is False\n\n    try:\n        os.remove(\"test-loginlogout.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-loginlogout.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-loginlogout.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_create_user():\n    \"\"\"\n    This runs through various iterations of creating a user.\n\n    \"\"\"\n    try:\n        os.remove(\"test-creation.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    suff_list = get_public_suffix_list()\n\n    # 0a. full name spam with no http://\n    payload = {\n        \"full_name\": \"Test User bIt.Ly/hahaspam\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"password\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n        \"public_suffix_list\": suff_list,\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] is None\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert user_created[\"failure_reason\"] == \"invalid full name\"\n\n    # 0b. full name spam with http://\n    payload = {\n        \"full_name\": \"Test User HttPs://BIT.lY/hahaspam\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"password\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n        \"public_suffix_list\": suff_list,\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] is None\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert user_created[\"failure_reason\"] == \"invalid full name\"\n\n    # 0c. full name spam with http:// and checking if currproc works OK\n    payload = {\n        \"full_name\": \"Test User HttPs://BIT.lY/hahaspam\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"password\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] is None\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert user_created[\"failure_reason\"] == \"invalid full name\"\n\n    # 1. dumb password\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"password\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n        \"public_suffix_list\": suff_list,\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert (\n        \"Your password is too short. It must have at least 12 characters.\"\n        in user_created[\"messages\"]\n    )\n    assert (\n        \"Your password is too similar to either \"\n        \"the domain name of this server or your \"\n        \"own name or email address.\" in user_created[\"messages\"]\n    )\n    assert (\n        \"Your password is on the list of the most common \"\n        \"passwords and is vulnerable to guessing.\" in user_created[\"messages\"]\n    )\n\n    # 1a. 'clever'-dumb password\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"passwordpassword123\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    msg_found = False\n    for msg in user_created[\"messages\"]:\n        if \"recently compromised Web account passwords from\" in msg:\n            msg_found = True\n            break\n    assert msg_found, f\"Pwned message not in {user_created['messages']}\"\n\n    # 2. all numeric password\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"239420349823904802398402375025\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n        \"public_suffix_list\": suff_list,\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert \"Your password cannot be all numbers.\" in user_created[\"messages\"]\n\n    # 3a. password ~= email address\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"testuser\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert (\n        \"Your password is too similar to either \"\n        \"the domain name of this server or your \"\n        \"own name or email address.\" in user_created[\"messages\"]\n    )\n\n    # 3b. password ~= full name\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"TestUser123\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n        \"public_suffix_list\": suff_list,\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] is None\n    assert user_created[\"send_verification\"] is False\n    assert (\n        \"Your password is too similar to either \"\n        \"the domain name of this server or your \"\n        \"own name or email address.\" in user_created[\"messages\"]\n    )\n\n    # 4. password is OK\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"system_id\": \"totally-random-systemid-1234\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n    assert user_created[\"system_id\"] == \"totally-random-systemid-1234\"\n    assert user_created[\"send_verification\"] is True\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # 5. try to create a new user with an existing email address\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n        \"public_suffix_list\": suff_list,\n    }\n    user_created = actions.create_new_user(\n        payload, override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is False\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n\n    # we should not send a verification email because the user already has an\n    # account or if the account is not active yet, the last verification email\n    # was sent less than 24 hours ago\n    assert user_created[\"send_verification\"] is False\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    try:\n        os.remove(\"test-creation.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 1}
{"code": "def test_sessions():\n    \"\"\"\n    This tests session token generation, readback, deletion, and expiry.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-creation.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n\n    # session token payload\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.2.3.4\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n\n    # check creation\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # check deletion\n    deleted = actions.auth_session_delete(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"reqid\": 1,\n            \"pii_salt\": \"super-random-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n    assert deleted[\"success\"] is True\n\n    # check readback of deleted\n    check = actions.auth_session_exists(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"reqid\": 1,\n            \"pii_salt\": \"super-random-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n    assert check[\"success\"] is False\n\n    # new session token payload\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.2.3.4\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n\n    # check creation\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n    assert session_token1[\"session_token\"] != session_token2[\"session_token\"]\n\n    # get items for session_token\n    check = actions.auth_session_exists(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"reqid\": 1,\n            \"pii_salt\": \"super-random-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n\n    assert check[\"success\"] is True\n\n    for key in (\n        \"user_id\",\n        \"full_name\",\n        \"email\",\n        \"email_verified\",\n        \"emailverify_sent_datetime\",\n        \"is_active\",\n        \"last_login_try\",\n        \"last_login_success\",\n        \"created_on\",\n        \"user_role\",\n        \"session_token\",\n        \"ip_address\",\n        \"user_agent\",\n        \"created\",\n        \"expires\",\n        \"extra_info_json\",\n    ):\n        assert key in check[\"session_info\"]\n\n    assert check[\"session_info\"][\"user_id\"] == 2\n    assert (\n        check[\"session_info\"][\"full_name\"] == \"The systemwide anonymous user\"\n    )\n    assert check[\"session_info\"][\"email\"] == \"anonuser@localhost\"\n    assert check[\"session_info\"][\"email_verified\"] is True\n    assert check[\"session_info\"][\"is_active\"] is True\n    assert check[\"session_info\"][\"last_login_try\"] is None\n    assert check[\"session_info\"][\"last_login_success\"] is None\n    assert check[\"session_info\"][\"user_role\"] == \"anonymous\"\n    assert (\n        check[\"session_info\"][\"session_token\"]\n        == session_token2[\"session_token\"]\n    )\n    assert check[\"session_info\"][\"ip_address\"] == session_payload[\"ip_address\"]\n    assert check[\"session_info\"][\"user_agent\"] == session_payload[\"user_agent\"]\n    assert check[\"session_info\"][\"expires\"] == session_payload[\"expires\"]\n    assert (\n        check[\"session_info\"][\"extra_info_json\"]\n        == session_payload[\"extra_info_json\"]\n    )\n\n    # new session token payload\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(seconds=5),\n        \"ip_address\": \"1.2.3.4\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"reqid\": 1,\n        \"pii_salt\": \"super-random-salt\",\n    }\n\n    # check creation\n    session_token3 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n    assert session_token3[\"success\"] is True\n    assert session_token3[\"session_token\"] is not None\n    assert session_token3[\"session_token\"] != session_token2[\"session_token\"]\n\n    # check readback when expired\n    time.sleep(10.0)\n\n    check = actions.auth_session_exists(\n        {\n            \"session_token\": session_token3[\"session_token\"],\n            \"reqid\": 1,\n            \"pii_salt\": \"super-random-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-creation.authdb.sqlite\",\n    )\n\n    assert check[\"success\"] is False\n\n    try:\n        os.remove(\"test-creation.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-creation.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_check_anonymous_access_to_collection(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_anonymous_access_to_dataset(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_anonymous_access_to_object(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_anonymous_access_to_users(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_anonymous_access_to_sessions(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_anonymous_access_to_apikeys(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_anonymous_access_to_preferences(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_email_works(tmpdir):\n    \"\"\"\n    This is a basic test of the email server working OK.\n\n    \"\"\"\n\n    email_server, maildir = generate_email_server(tmpdir)\n    email_server.start()\n    time.sleep(3.0)\n\n    # send a test email\n    email_sent = actions.send_email(\n        \"test@test.org\",\n        \"Hello\",\n        \"this is a test\",\n        [\"test@test.org\"],\n        \"127.0.0.1\",\n        None,\n        None,\n        \"salt\",\n        port=9487,\n    )\n\n    assert email_sent is True\n\n    # check if it was received\n    mailbox = Maildir(maildir)\n\n    for _, message in mailbox.items():\n\n        if message[\"Subject\"] == \"Hello\":\n            assert message[\"From\"] == \"test@test.org\"\n            assert message[\"To\"] == \"test@test.org\"\n            assert \"this is a test\" in message.as_string()\n\n    email_server.stop()", "od": 0}
{"code": "def test_create_user_with_email(tmpdir):\n    \"\"\"\n    This creates a user and tries to send a verification code to their email.\n\n    \"\"\"\n\n    test_authdb_url = get_test_authdb(tmpdir)\n    get_public_suffix_list()\n\n    # 0. start the email server\n    email_server, maildir = generate_email_server(tmpdir)\n    email_server.start()\n    time.sleep(3.0)\n\n    # 1a. create a new session\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    session_token_info = actions.auth_session_new(\n        session_payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n\n    # 1b. create a new user\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n    assert user_created[\"send_verification\"] is True\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    token_key = Fernet.generate_key()\n\n    # 2. generate a verification token and send them an email\n    verify_token = tokens.generate_email_token(\n        session_payload[\"ip_address\"],\n        session_payload[\"user_agent\"],\n        \"testuser@test.org\",\n        session_token_info[\"session_token\"],\n        token_key,\n    )\n\n    # this uses the payload method of sending SMTP settings to the backend\n    # function\n    verification_email_info = actions.send_signup_verification_email(\n        {\n            \"email_address\": \"testuser@test.org\",\n            \"session_token\": session_token_info[\"session_token\"],\n            \"created_info\": user_created,\n            \"server_name\": \"Authnzerver\",\n            \"server_baseurl\": \"https://localhost/auth\",\n            \"account_verify_url\": \"/users/verify\",\n            \"verification_token\": verify_token,\n            \"verification_expiry\": 900,\n            \"emailuser\": None,\n            \"emailpass\": None,\n            \"emailserver\": \"localhost\",\n            \"emailport\": 9487,\n            \"emailsender\": \"Authnzerver <authnzerver@test.org>\",\n            \"reqid\": 1337,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n    assert verification_email_info[\"success\"] is True\n    assert verification_email_info[\"email_address\"] == \"testuser@test.org\"\n\n    # 3. check the mailbox to see if the email was received\n    mailbox = Maildir(maildir)\n\n    email_found = False\n\n    for _, message in mailbox.items():\n\n        if \"Please verify your account sign up request\" in message[\"Subject\"]:\n\n            email_found = True\n            assert message[\"From\"] == \"Authnzerver <authnzerver@test.org>\"\n            assert message[\"To\"] == \"testuser@test.org\"\n            assert (\n                \"\\n\".join(textwrap.wrap(verify_token.decode()))\n                in message.as_string()\n            )\n            break\n\n    assert email_found is True\n\n    # now verify that the token from the email contains the same info we\n    # provided\n    received_token_base64 = re.findall(\n        r\"enter this code:([\\S\\n]+)into the account verification\",\n        message.as_string(),\n    )\n    received_token_base64 = received_token_base64[0]\n    received_token_base64 = received_token_base64.replace(\"\\n\", \"\")\n    received_token_valid = tokens.verify_email_token(\n        received_token_base64,\n        session_payload[\"ip_address\"],\n        session_payload[\"user_agent\"],\n        session_token_info[\"session_token\"],\n        \"testuser@test.org\",\n        token_key,\n        match_returned_items=(\"ipa\", \"usa\", \"stk\", \"ema\"),\n    )\n    assert received_token_valid is True\n\n    # 4. set the user's email address as verified\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuser@test.org\",\n            \"reqid\": 123,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 4\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    # 5. send a password forgot email to the user\n\n    # 5a. create a new session for the user first\n    session_payload = {\n        \"user_id\": 4,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    session_token_info = actions.auth_session_new(\n        session_payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n\n    # 5b. now send a forgot-password email\n    forgotpass_token = tokens.generate_email_token(\n        session_payload[\"ip_address\"],\n        session_payload[\"user_agent\"],\n        \"testuser@test.org\",\n        session_token_info[\"session_token\"],\n        token_key,\n    )\n\n    # this uses the config object method of sending SMTP settings to the backend\n    # function\n    config_obj = SimpleNamespace()\n    config_obj.emailuser = None\n    config_obj.emailpass = None\n    config_obj.emailserver = \"localhost\"\n    config_obj.emailport = 9487\n    config_obj.emailsender = \"Authnzerver <authnzerver@test.org>\"\n\n    forgotpass_email_info = actions.send_forgotpass_verification_email(\n        {\n            \"email_address\": \"testuser@test.org\",\n            \"session_token\": session_token_info[\"session_token\"],\n            \"server_name\": \"Authnzerver\",\n            \"server_baseurl\": \"https://localhost/auth\",\n            \"password_forgot_url\": \"/password/reset-step1\",\n            \"verification_token\": forgotpass_token,\n            \"verification_expiry\": 900,\n            \"reqid\": 1337,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        config=config_obj,\n    )\n    assert forgotpass_email_info[\"success\"] is True\n    assert forgotpass_email_info[\"email_address\"] == \"testuser@test.org\"\n\n    # 6. check the mailbox to see if the forgot password email was received\n    mailbox = Maildir(maildir)\n\n    email_found = False\n\n    for _, message in mailbox.items():\n\n        if \"Please verify your password reset request\" in message[\"Subject\"]:\n\n            email_found = True\n            assert message[\"From\"] == \"Authnzerver <authnzerver@test.org>\"\n            assert message[\"To\"] == \"testuser@test.org\"\n            assert (\n                \"\\n\".join(textwrap.wrap(forgotpass_token.decode()))\n                in message.as_string()\n            )\n            break\n\n    assert email_found is True\n\n    # now verify that the token from the email contains the same info we\n    # provided\n    received_token_base64 = re.findall(\n        r\"enter this code:([\\S\\n]+)into the password reset\",\n        message.as_string(),\n    )\n    received_token_base64 = received_token_base64[0]\n    received_token_base64 = received_token_base64.replace(\"\\n\", \"\")\n    received_token_valid = tokens.verify_email_token(\n        received_token_base64,\n        session_payload[\"ip_address\"],\n        session_payload[\"user_agent\"],\n        session_token_info[\"session_token\"],\n        \"testuser@test.org\",\n        token_key,\n        match_returned_items=(\"ipa\", \"usa\", \"stk\", \"ema\"),\n    )\n    assert received_token_valid is True\n\n    #\n    # clean up\n    #\n\n    email_server.stop()", "od": 0}
{"code": "def test_superuser_access_to_collection(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_superuser_access_to_dataset(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_superuser_access_to_object(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_superuser_access_to_users(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_superuser_access_to_sessions(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_superuser_access_to_apikeys(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_superuser_access_to_preferences(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_sessions_delete_userid():\n    \"\"\"\n    This tests if we can delete sessions for a user.\n\n    \"\"\"\n\n    db_file, db_url = get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-sessiondelete@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    print(db_url)\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=db_url,\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-sessiondelete@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=db_url,\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # login 1\n    # make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n\n    # login 2\n    # make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Searchzilla Oxide\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.2\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n\n    # login 3\n    # make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Pear Adventure\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.3\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    session_token3 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n\n    #\n    # Now we have three sessions. Kill all of them.\n    #\n\n    sessions_killed = actions.auth_delete_sessions_userid(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"session_token\": None,\n            \"keep_current_session\": False,\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n\n    assert sessions_killed[\"success\"] is True\n\n    # check if any of these sessions exist\n    session_check_1 = actions.auth_session_exists(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n    assert session_check_1[\"success\"] is False\n\n    session_check_2 = actions.auth_session_exists(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n    assert session_check_2[\"success\"] is False\n\n    session_check_3 = actions.auth_session_exists(\n        {\n            \"session_token\": session_token3[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n    assert session_check_3[\"success\"] is False\n\n    #\n    # Now login 3 times again\n    #\n\n    # login 1\n    # make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n\n    # login 2\n    # make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Searchzilla Oxide\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.2\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n\n    # login 3\n    # make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Pear Adventure\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.3\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    session_token3 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=db_url,\n    )\n\n    #\n    # Now we have three sessions. Kill all of them except for the last one.\n    #\n\n    sessions_killed = actions.auth_delete_sessions_userid(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"session_token\": session_token3[\"session_token\"],\n            \"keep_current_session\": True,\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n\n    assert sessions_killed[\"success\"] is True\n\n    # check if any of these sessions exist\n    session_check_1 = actions.auth_session_exists(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n    assert session_check_1[\"success\"] is False\n\n    session_check_2 = actions.auth_session_exists(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n    assert session_check_2[\"success\"] is False\n\n    session_check_3 = actions.auth_session_exists(\n        {\n            \"session_token\": session_token3[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        raiseonfail=True,\n        override_authdb_path=db_url,\n    )\n    assert session_check_3[\"success\"] is True\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(db_file)\n    except Exception:\n        pass", "od": 0}
{"code": "def test_internal_session_edit():\n    \"\"\"\n    This tests if we can add session info to a session dict.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-sessioninfo.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-sessioninfo.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-sessioninfo.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-sessioninfo@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-sessioninfo.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-sessioninfo@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-sessioninfo.authdb.sqlite\",\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-sessioninfo.authdb.sqlite\",\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # now make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\n            \"pref_datasets_always_private\": True,\n            \"pref_advancedbits\": \"so-advanced-much-progress\",\n        },\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-sessioninfo.authdb.sqlite\",\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n\n    #\n    # now try to add info to the session\n    #\n\n    session_info_added = actions.internal_edit_session(\n        {\n            \"target_session_token\": session_token2[\"session_token\"],\n            \"update_dict\": {\n                \"this\": \"is\",\n                \"a\": \"test\",\n                \"pref_datasets_always_private\": False,\n                \"pref_advancedbits\": \"__delete__\",\n            },\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-sessioninfo.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    new_session_info = session_info_added[\"session_info\"]\n\n    assert session_info_added[\"success\"] is True\n    assert isinstance(new_session_info[\"extra_info_json\"], dict)\n    assert new_session_info[\"extra_info_json\"][\"this\"] == \"is\"\n    assert new_session_info[\"extra_info_json\"][\"a\"] == \"test\"\n    assert (\n        new_session_info[\"extra_info_json\"][\"pref_datasets_always_private\"]\n        is False\n    )\n    assert new_session_info.get(\"pref_advancedbits\", None) is None\n\n    # get back the new session info\n    info_check = actions.auth_session_exists(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-sessioninfo.authdb.sqlite\",\n    )\n\n    assert info_check[\"success\"] is True\n    assert isinstance(info_check[\"session_info\"][\"extra_info_json\"], dict)\n    assert info_check[\"session_info\"][\"extra_info_json\"][\"this\"] == \"is\"\n    assert info_check[\"session_info\"][\"extra_info_json\"][\"a\"] == \"test\"\n    assert (\n        new_session_info[\"extra_info_json\"][\"pref_datasets_always_private\"]\n        is False\n    )\n    assert new_session_info.get(\"pref_advancedbits\", None) is None\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-sessioninfo.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-sessioninfo.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-sessioninfo.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_add_key(dictcache_obj):\n    \"\"\"\n    Tests simple add.\n\n    \"\"\"\n\n    retval = dictcache_obj.add(\"test_key\", 123)\n    assert retval == 123\n    assert dictcache_obj.get(\"test_key\") == 123", "od": 0}
{"code": "def test_add_same_key(dictcache_obj):\n    \"\"\"\n    Tests if adding the same key with a new value doesn't do anything.\n\n    \"\"\"\n\n    retval = dictcache_obj.add(\"test_key\", 123)\n    assert retval == 123\n    dictcache_obj.add(\"test_key\", 456)\n    assert dictcache_obj.get(\"test_key\") == 123\n    assert dictcache_obj.size() == 1", "od": 0}
{"code": "def test_cache_capacity(dictcache_obj):\n    \"\"\"\n    Tests if the cache maintains the set capacity.\n\n    \"\"\"\n\n    # overfill the cache\n    for x in range(1100):\n        dictcache_obj.add(f\"key_{x}\", f\"value_{x}\")\n\n    # check if the size was maintained\n    assert dictcache_obj.size() == 1000\n    assert len(dictcache_obj.container) == 1000\n    assert len(dictcache_obj.sortedkeys) == 1000\n\n    # check if the first 100 keys were removed as expected\n    for x in range(100):\n        assert dictcache_obj.get(f\"key_{x}\") is None\n\n    # check if the next 1000 keys are as expected\n    for x in range(100, 1100):\n        assert dictcache_obj.get(f\"key_{x}\") == f\"value_{x}\"", "od": 0}
{"code": "def test_cache_delete(dictcache_obj):\n    \"\"\"\n    Tests if the cache deletes things correctly.\n\n    \"\"\"\n\n    for x in range(1000):\n        dictcache_obj.add(f\"key_{x}\", f\"value_{x}\", ttl=10.0)\n\n    for x in range(1000):\n        dictcache_obj.delete(f\"key_{x}\")\n\n    assert dictcache_obj.size() == 0\n    assert len(dictcache_obj.container) == 0\n    assert len(dictcache_obj.sortedkeys) == 0\n    assert len(dictcache_obj.expireable_key_ttls) == 0", "od": 0}
{"code": "def test_cache_flush(dictcache_obj):\n    \"\"\"\n    Tests if the cache flushes correctly.\n\n    \"\"\"\n\n    for x in range(1100):\n        dictcache_obj.add(f\"key_{x}\", f\"value_{x}\", ttl=10.0)\n\n    # check if the size was maintained\n    assert dictcache_obj.size() == 1000\n    assert len(dictcache_obj.container) == 1000\n    assert len(dictcache_obj.sortedkeys) == 1000\n\n    dictcache_obj.flush()\n    assert dictcache_obj.size() == 0\n    assert len(dictcache_obj.container) == 0\n    assert len(dictcache_obj.sortedkeys) == 0", "od": 0}
{"code": "def test_add_key_with_ttl(dictcache_obj):\n    \"\"\"\n    Tests add with key TTL.\n\n    \"\"\"\n\n    add_time = time.time()\n    retval = dictcache_obj.add(\"test_key\", 123, ttl=1.0)\n    assert retval == 123\n\n    keyval, keytime, keyttl = dictcache_obj.get(\"test_key\", time_and_ttl=True)\n    assert keyval == 123\n    assert keyttl == 1.0\n    assert keytime == pytest.approx(add_time, rel=1.0e-3)\n\n    time.sleep(1.5)\n    assert dictcache_obj.get(\"test_key\") is None\n    assert dictcache_obj.size() == 0", "od": 0}
{"code": "def test_set_key(dictcache_obj):\n    \"\"\"\n    Tests setting a key to a new value.\n\n    Tests setting a non-existent key with add_ifnotexists=True adds the key.\n\n    Tests setting a non-existent key with add_ifnotexists=False does nothing.\n\n    \"\"\"\n\n    retval = dictcache_obj.add(\"test_key\", 123)\n    assert retval == 123\n\n    dictcache_obj.set(\"test_key\", \"hello-world!\")\n    assert dictcache_obj.get(\"test_key\") == \"hello-world!\"\n\n    dictcache_obj.set(\"another_test_key\", \"hello-world-this-is-new\")\n    assert dictcache_obj.get(\"another_test_key\") == \"hello-world-this-is-new\"\n\n    dictcache_obj.set(\n        \"one_more_test_key\",\n        \"hello-world-this-should-fail\",\n        add_ifnotexists=False,\n    )\n    assert dictcache_obj.get(\"one_more_test_key\") is None", "od": 0}
{"code": "def test_set_key_ttl(dictcache_obj):\n    \"\"\"\n    Tests if setting a key's TTL works.\n\n    \"\"\"\n\n    add_time = time.time()\n    retval = dictcache_obj.add(\"test_key\", 123, ttl=2.0)\n    assert retval == 123\n\n    # test if setting a key TTL to a new value works\n    dictcache_obj.set(\"test_key\", 456, ttl=5.0)\n    keyval, keytime, keyttl = dictcache_obj.get(\"test_key\", time_and_ttl=True)\n    assert keyval == 456\n    assert keyttl == 5.0\n    assert keytime == pytest.approx(add_time, rel=1.0e-3)\n\n    time.sleep(4.0)\n    assert dictcache_obj.get(\"test_key\") == 456\n\n    time.sleep(2.0)\n    assert dictcache_obj.get(\"test_key\") is None\n\n    # check if we can set ttl < 0\n    with pytest.raises(ValueError, match=\"Can't set ttl < 0\"):\n        dictcache_obj.add(\"test_key_bad_ttl\", 123, ttl=-10)", "od": 0}
{"code": "def test_set_key_persistent(dictcache_obj):\n    \"\"\"\n    Tests if setting a key's TTL to None makes it persistent.\n\n    \"\"\"\n\n    add_time = time.time()\n    retval = dictcache_obj.add(\"test_key\", 123, ttl=2.0)\n    assert retval == 123\n\n    # test if setting an expireable key's TTL to None makes it persistent\n    dictcache_obj.set(\"test_key\", 456, ttl=None)\n    keyval, keytime, keyttl = dictcache_obj.get(\"test_key\", time_and_ttl=True)\n    assert keyval == 456\n    assert keyttl is None\n    assert keytime == pytest.approx(add_time, rel=1.0e-3)\n\n    time.sleep(3.0)\n    assert dictcache_obj.get(\"test_key\") == 456", "od": 0}
{"code": "def test_set_key_expireable(dictcache_obj):\n    \"\"\"\n    Tests if setting a key's TTL from None to a time val makes it expireable.\n\n    \"\"\"\n\n    add_time = time.time()\n    retval = dictcache_obj.add(\"test_key\", 123, ttl=None)\n    assert retval == 123\n\n    # test if setting an expireable key's TTL to None makes it expireable\n    dictcache_obj.set(\"test_key\", 456, ttl=2.0)\n    keyval, keytime, keyttl = dictcache_obj.get(\"test_key\", time_and_ttl=True)\n    assert keyval == 456\n    assert keyttl == 2.0\n    assert keytime == pytest.approx(add_time, rel=1.0e-3)\n\n    time.sleep(3.0)\n    assert dictcache_obj.get(\"test_key\") is None", "od": 0}
{"code": "def test_counterkey_increment(dictcache_obj):\n    \"\"\"\n    Tests if a counter key is incremented correctly.\n\n    \"\"\"\n\n    count = dictcache_obj.counter_increment(\"test_key\")\n\n    assert count == 1\n\n    for _ in range(99):\n        dictcache_obj.counter_increment(\"test_key\")\n\n    assert dictcache_obj.counter_get(\"test_key\") == 100", "od": 0}
{"code": "def test_counterkey_decrement(dictcache_obj):\n    \"\"\"\n    Tests if a counter key is decremented correctly.\n\n    \"\"\"\n\n    count = dictcache_obj.counter_increment(\"test_key\")\n\n    assert count == 1\n\n    for _ in range(99):\n        dictcache_obj.counter_increment(\"test_key\")\n\n    assert dictcache_obj.counter_get(\"test_key\") == 100\n\n    for _ in range(99):\n        dictcache_obj.counter_decrement(\"test_key\")\n\n    assert dictcache_obj.counter_get(\"test_key\") == 1\n\n    # test that the key is deleted when the last decrement brings the counter to\n    # zero\n    lastval = dictcache_obj.counter_decrement(\"test_key\")\n    assert lastval == 0\n    assert dictcache_obj.counter_get(\"test_key\") == 0\n    assert dictcache_obj.get(\"test_key-dictcache-counterkey\") is None", "od": 0}
{"code": "def test_counterkey_addset(dictcache_obj):\n    \"\"\"\n    Tests if a counter key can be added/set at a specific values.\n\n    \"\"\"\n\n    count = dictcache_obj.counter_add(\"test_key\", 100)\n\n    assert count == 100\n    assert dictcache_obj.counter_get(\"test_key\") == 100\n    assert dictcache_obj.get(\"test_key-dictcache-counterkey\") == 100\n\n    count = dictcache_obj.counter_set(\"test_key\", 50)\n    assert count == 50\n    assert dictcache_obj.counter_get(\"test_key\") == 50\n    assert dictcache_obj.get(\"test_key-dictcache-counterkey\") == 50", "od": 0}
{"code": "def test_counterkey_rate(dictcache_obj):\n    \"\"\"\n    Tests if a counter key rate is calculated correctly.\n\n    \"\"\"\n\n    total_time = 0.0\n    time_step = 0.01\n\n    start_time = time.time()\n    for _ in range(100):\n        dictcache_obj.counter_increment(\"test_key\")\n        time.sleep(time_step)\n        total_time = total_time + time_step\n    end_time = time.time()\n\n    (rate, currval, initval, currtime, inittime) = dictcache_obj.counter_rate(\n        \"test_key\", 1.0, return_allinfo=True\n    )\n    assert rate == pytest.approx(\n        (100 - 1) / ((end_time - start_time) / 1.0), rel=1.0e-3\n    )\n\n    # now check decreasing rates\n    dictcache_obj.counter_add(\"test_key_two\", 101)\n\n    total_time = 0.0\n\n    start_time = time.time()\n    for _ in range(100):\n        dictcache_obj.counter_decrement(\"test_key_two\")\n        time.sleep(time_step)\n        total_time = total_time + time_step\n    end_time = time.time()\n\n    (rate, currval, initval, currtime, inittime) = dictcache_obj.counter_rate(\n        \"test_key_two\", 1.0, return_allinfo=True\n    )\n    expected_rate = abs((1 - 101) / ((end_time - start_time) / 1.0))\n    assert rate == pytest.approx(expected_rate, rel=1.0e-3)", "od": 0}
{"code": "def test_issue_apikey(tmpdir):\n    \"\"\"\n    Test if issuing an API key works.\n\n    \"\"\"\n\n    delete_test_authdb(tmpdir)\n    test_authdb_url = get_test_authdb(tmpdir)\n    teardown()\n\n    get_public_suffix_list()\n\n    # 1. create a new user\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n\n    # 2. verify their email\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuser@test.org\",\n            \"reqid\": 2,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 4\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    # 3. generate an API key\n    apikey_issue_payload = {\n        \"issuer\": \"authnzerver\",\n        \"audience\": \"test-service\",\n        \"subject\": \"/test-endpoint\",\n        \"apiversion\": 1,\n        \"expires_seconds\": 7,\n        \"not_valid_before\": 1,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"ip_address\": \"1.2.3.4\",\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 2,\n        \"reqid\": 3,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    apikey_info = actions.issue_apikey_nosession(\n        apikey_issue_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert apikey_info[\"success\"] is True\n    for key in (\"apikey\", \"expires\", \"refresh_token\", \"refresh_token_expires\"):\n        assert key in apikey_info\n\n    apikey = json.loads(apikey_info[\"apikey\"])\n\n    assert apikey[\"ipa\"] == apikey_issue_payload[\"ip_address\"]\n    assert apikey[\"uid\"] == apikey_issue_payload[\"user_id\"]\n    assert apikey[\"rol\"] == apikey_issue_payload[\"user_role\"]\n\n    teardown()", "od": 0}
{"code": "def test_verify_apikey(tmpdir):\n    \"\"\"\n    This tests if the issued API key can be verified:\n\n    - within expiry time\n    - within expiry but with other user\n    - after expiry time\n\n    \"\"\"\n\n    delete_test_authdb(tmpdir)\n    test_authdb_url = get_test_authdb(tmpdir)\n    teardown()\n\n    get_public_suffix_list()\n\n    # 1. create a couple of new users\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n\n    payload = {\n        \"full_name\": \"Another Test User\",\n        \"email\": \"testuse2r@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 2,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuse2r@test.org\"\n    assert user_created[\"user_id\"] == 5\n\n    # 2. verify their emails\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuser@test.org\",\n            \"reqid\": 3,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 4\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuse2r@test.org\",\n            \"reqid\": 4,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 5\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    # 3. generate an API key for the first user\n    apikey_issue_payload = {\n        \"issuer\": \"authnzerver\",\n        \"audience\": \"test-service\",\n        \"subject\": \"/test-endpoint\",\n        \"apiversion\": 1,\n        \"expires_seconds\": 6,\n        \"not_valid_before\": 2,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"ip_address\": \"1.2.3.4\",\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 2,\n        \"reqid\": 4,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    apikey_info = actions.issue_apikey_nosession(\n        apikey_issue_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_info[\"success\"] is True\n\n    apikey_dict = json.loads(apikey_info[\"apikey\"])\n\n    # 4. try to verify the API key immediately - should fail because of\n    # not-before\n    apikey_verification = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 5,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_verification[\"success\"] is False\n\n    # 5. wait 3 seconds, then verify again - this should pass\n    time.sleep(3)\n    apikey_verification = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 6,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_verification[\"success\"] is True\n\n    # 6. try to verify the API key as a different user - this should fail\n    apikey_verification = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 5,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 6,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_verification[\"success\"] is False\n\n    # 7. wait 6 seconds, then try to reverify the API key as the original user\n    # it should have expired by now so this should fail\n    time.sleep(6)\n    apikey_verification = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 7,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n    assert apikey_verification[\"success\"] is False\n\n    teardown()", "od": 0}
{"code": "def test_revoke_apikey(tmpdir):\n    \"\"\"\n    This tests if an apikey can be revoked.\n\n    - by the original user\n    - by another user who somehow gets the API key\n\n    \"\"\"\n\n    delete_test_authdb(tmpdir)\n    test_authdb_url = get_test_authdb(tmpdir)\n    teardown()\n\n    get_public_suffix_list()\n\n    # 1. create a couple of new users\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n\n    payload = {\n        \"full_name\": \"Another Test User\",\n        \"email\": \"testuse2r@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 2,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuse2r@test.org\"\n    assert user_created[\"user_id\"] == 5\n\n    # 2. verify their emails\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuser@test.org\",\n            \"reqid\": 3,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 4\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuse2r@test.org\",\n            \"reqid\": 4,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 5\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    # 3. generate an API key for the first user\n    apikey_issue_payload = {\n        \"issuer\": \"authnzerver\",\n        \"audience\": \"test-service\",\n        \"subject\": \"/test-endpoint\",\n        \"apiversion\": 1,\n        \"expires_seconds\": 6,\n        \"not_valid_before\": 2,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"ip_address\": \"1.2.3.4\",\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 2,\n        \"reqid\": 5,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    apikey_info = actions.issue_apikey_nosession(\n        apikey_issue_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_info[\"success\"] is True\n\n    apikey_dict = json.loads(apikey_info[\"apikey\"])\n    time.sleep(2)\n\n    # 4. try to revoke the API key as a different user\n    # this should fail\n    apikey_revocation = actions.revoke_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 5,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 6,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_revocation[\"success\"] is False\n\n    # 5. try to revoke the API key as the correct user\n    # this should pass\n    apikey_revocation = actions.revoke_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 7,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_revocation[\"success\"] is True\n\n    # 6. try to verify the API key after it has been revoked\n    # this should fail\n    apikey_verification = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 8,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_verification[\"success\"] is False\n\n    # 7. try to verify the API key as a different user - this should fail anyway\n    apikey_verification = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_dict,\n            \"user_id\": 5,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 9,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert apikey_verification[\"success\"] is False\n\n    teardown()", "od": 0}
{"code": "def test_revoke_all_apikeys(tmpdir):\n    \"\"\"\n    This tests if all API keys for a user can be revoked.\n\n    \"\"\"\n\n    delete_test_authdb(tmpdir)\n    test_authdb_url = get_test_authdb(tmpdir)\n    teardown()\n\n    get_public_suffix_list()\n\n    # 1. create a new user\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n\n    # 2. verify their email\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuser@test.org\",\n            \"reqid\": 2,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 4\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    # 3. generate a couple of API keys\n    apikey_payload_one = {\n        \"issuer\": \"authnzerver\",\n        \"audience\": \"test-service\",\n        \"subject\": \"/test-endpoint-one\",\n        \"apiversion\": 1,\n        \"expires_seconds\": 7,\n        \"not_valid_before\": 1,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"ip_address\": \"1.2.3.4\",\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 2,\n        \"reqid\": 3,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    apikey_info_one = actions.issue_apikey_nosession(\n        apikey_payload_one,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    apikey_one = json.loads(apikey_info_one[\"apikey\"])\n\n    apikey_payload_two = {\n        \"issuer\": \"authnzerver\",\n        \"audience\": \"test-service\",\n        \"subject\": \"/test-endpoint-two\",\n        \"apiversion\": 1,\n        \"expires_seconds\": 7,\n        \"not_valid_before\": 1,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"ip_address\": \"1.2.3.4\",\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 2,\n        \"reqid\": 3,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    apikey_info_two = actions.issue_apikey_nosession(\n        apikey_payload_two,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    apikey_two = json.loads(apikey_info_two[\"apikey\"])\n\n    time.sleep(2)\n\n    # 1. try to revoke all API keys with an incorrect API key\n    good_tkn = apikey_one[\"tkn\"]\n    apikey_one[\"tkn\"] = \"haha-bad-token\"\n    revoke_one = actions.revoke_all_apikeys_nosession(\n        {\n            \"apikey_dict\": apikey_one,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 2,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert revoke_one[\"success\"] is False\n\n    # 2. try to revoke all API keys with a correct API key\n    revoke_two = actions.revoke_all_apikeys_nosession(\n        {\n            \"apikey_dict\": apikey_two,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 2,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert revoke_two[\"success\"] is True\n\n    # 3. make sure we can't use any API key afterwards\n    apikey_one[\"tkn\"] = good_tkn\n\n    verify_one = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_one,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 3,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert verify_one[\"success\"] is False\n\n    verify_two = actions.verify_apikey_nosession(\n        {\n            \"apikey_dict\": apikey_two,\n            \"user_id\": 4,\n            \"user_role\": \"authenticated\",\n            \"reqid\": 4,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n    assert verify_two[\"success\"] is False\n\n    teardown()", "od": 0}
{"code": "def test_refresh_apikey(tmpdir):\n    \"\"\"\n    This tests refreshing an API key.\n\n    - before it expires\n    - after it expires\n    - with an unexpired correct refresh token\n    - with the incorrect refresh token\n    - with an expired refresh token\n\n    \"\"\"\n\n    delete_test_authdb(tmpdir)\n    test_authdb_url = get_test_authdb(tmpdir)\n    teardown()\n\n    get_public_suffix_list()\n\n    # 1. create a new user\n    payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"reqid\": 1,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n    user_created = actions.create_new_user(\n        payload, raiseonfail=True, override_authdb_path=test_authdb_url\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser@test.org\"\n    assert user_created[\"user_id\"] == 4\n\n    # 2. verify their email\n    email_verified_info = actions.set_user_emailaddr_verified(\n        {\n            \"email\": \"testuser@test.org\",\n            \"reqid\": 2,\n            \"pii_salt\": \"super-secret-salt\",\n        },\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n    )\n\n    assert email_verified_info[\"success\"] is True\n    assert email_verified_info[\"user_id\"] == 4\n    assert email_verified_info[\"is_active\"] is True\n    assert email_verified_info[\"user_role\"] == \"authenticated\"\n\n    # 3. generate an API key\n    apikey_issue_payload = {\n        \"issuer\": \"authnzerver\",\n        \"audience\": \"test-service\",\n        \"subject\": \"/test-endpoint\",\n        \"apiversion\": 1,\n        \"expires_seconds\": 6,\n        \"not_valid_before\": 1,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"ip_address\": \"1.2.3.4\",\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 1,\n        \"reqid\": 3,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    apikey_info = actions.issue_apikey_nosession(\n        apikey_issue_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert apikey_info[\"success\"] is True\n    for key in (\"apikey\", \"expires\", \"refresh_token\", \"refresh_token_expires\"):\n        assert key in apikey_info\n\n    apikey = json.loads(apikey_info[\"apikey\"])\n\n    assert apikey[\"ipa\"] == apikey_issue_payload[\"ip_address\"]\n    assert apikey[\"uid\"] == apikey_issue_payload[\"user_id\"]\n    assert apikey[\"rol\"] == apikey_issue_payload[\"user_role\"]\n\n    # 4. refresh the key immediately - this should fail because of refresh_nbf\n    apikey_refresh_payload = {\n        \"apikey_dict\": apikey,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"refresh_token\": apikey_info[\"refresh_token\"],\n        \"ip_address\": \"1.2.3.4\",\n        \"expires_seconds\": 4,\n        \"not_valid_before\": 1,\n        \"refresh_expires\": 10,\n        \"refresh_nbf\": 1,\n        \"reqid\": 3,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    refreshed_apikey = actions.refresh_apikey_nosession(\n        apikey_refresh_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert refreshed_apikey[\"success\"] is False\n\n    # 5. now try to refresh within the lifetime of the key but with incorrect\n    # refresh token - should fail\n    time.sleep(2)\n\n    apikey_refresh_payload[\"refresh_token\"] = \"haha wrong token\"\n\n    refreshed_apikey = actions.refresh_apikey_nosession(\n        apikey_refresh_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert refreshed_apikey[\"success\"] is False\n\n    # 6. now try to refresh with correct refresh token - should pass\n    apikey_refresh_payload[\"refresh_token\"] = apikey_info[\"refresh_token\"]\n\n    refreshed_apikey = actions.refresh_apikey_nosession(\n        apikey_refresh_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert refreshed_apikey[\"success\"] is True\n\n    # 7. now try to refresh after the key expires - should pass\n    time.sleep(6)\n\n    refreshed_apikey_dict = json.loads(refreshed_apikey[\"apikey\"])\n\n    apikey_refresh_payload = {\n        \"apikey_dict\": refreshed_apikey_dict,\n        \"user_id\": 4,\n        \"user_role\": \"authenticated\",\n        \"refresh_token\": refreshed_apikey[\"refresh_token\"],\n        \"ip_address\": \"1.2.3.4\",\n        \"expires_seconds\": 4,\n        \"not_valid_before\": 1,\n        \"refresh_expires\": 5,\n        \"refresh_nbf\": 1,\n        \"reqid\": 3,\n        \"pii_salt\": \"super-secret-salt\",\n    }\n\n    refreshed_apikey = actions.refresh_apikey_nosession(\n        apikey_refresh_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert refreshed_apikey[\"success\"] is True\n\n    # 8. now try to refresh after the refresh token expires - should fail\n    time.sleep(6)\n\n    refreshed_apikey = actions.refresh_apikey_nosession(\n        apikey_refresh_payload,\n        raiseonfail=True,\n        override_authdb_path=test_authdb_url,\n        override_permissions_json=permissions_json,\n    )\n\n    assert refreshed_apikey[\"success\"] is False\n\n    teardown()", "od": 0}
{"code": "def test_passcheck():\n    \"\"\"\n    This tests if we can check the password for a logged-in user.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-passcheck@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-passcheck@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # now make a new session token to simulate a logged-in user\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n\n    #\n    # now run a password check\n    #\n\n    # correct password\n    pass_check = actions.auth_password_check(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert pass_check[\"success\"] is True\n    assert pass_check[\"user_id\"] == emailverify[\"user_id\"]\n\n    # incorrect password\n    pass_check = actions.auth_password_check(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"password\": \"incorrectponylithiumfastener\",\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert pass_check[\"success\"] is False\n    assert pass_check[\"user_id\"] is None\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_passcheck_nosession():\n    \"\"\"\n    This tests if we can check the password for a user with their email and\n    password only, with no need for an existing session.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-passcheck@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-passcheck@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    #\n    # now run a password check\n    #\n\n    # correct password\n    pass_check = actions.auth_password_check_nosession(\n        {\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert pass_check[\"success\"] is True\n    assert pass_check[\"user_id\"] == emailverify[\"user_id\"]\n\n    # incorrect password\n    pass_check = actions.auth_password_check_nosession(\n        {\n            \"email\": user_payload[\"email\"],\n            \"password\": \"incorrectponylithiumfastener\",\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-passcheck.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert pass_check[\"success\"] is False\n    assert pass_check[\"user_id\"] is None\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-passcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_role_permissions():\n    \"\"\"\n    This tests if we can check the permissions for a logged-in user.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-permcheck@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-permcheck@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n    )\n\n    # make a non-verified user\n    user_payload2 = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-permcheck2@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created2 = actions.create_new_user(\n        user_payload2,\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n    )\n    assert user_created2[\"success\"] is True\n    assert user_created2[\"user_email\"] == \"testuser-permcheck2@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created2[\"messages\"]\n    )\n\n    #\n    # now run the permissions checks\n    #\n\n    # get the permissions JSON\n    thisdir = os.path.dirname(__file__)\n    permissions_json = os.path.abspath(\n        os.path.join(thisdir, \"..\", \"default-permissions-model.json\")\n    )\n\n    # 1. view a non-owned public object\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"user_role\": \"authenticated\",\n            \"action\": \"view\",\n            \"target_name\": \"object\",\n            \"target_owner\": 1,\n            \"target_visibility\": \"public\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is True\n    assert (\n        \"Access request check successful. Access granted: True.\"\n        in access_check[\"messages\"]\n    )\n\n    # 2. delete a non-owned public object\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"user_role\": \"authenticated\",\n            \"action\": \"delete\",\n            \"target_name\": \"object\",\n            \"target_owner\": 1,\n            \"target_visibility\": \"public\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is False\n    assert (\n        \"Access request check successful. Access granted: False.\"\n        in access_check[\"messages\"]\n    )\n\n    # 3. edit a self owned dataset\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"user_role\": \"authenticated\",\n            \"action\": \"edit\",\n            \"target_name\": \"dataset\",\n            \"target_owner\": emailverify[\"user_id\"],\n            \"target_visibility\": \"private\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is True\n    assert (\n        \"Access request check successful. Access granted: True.\"\n        in access_check[\"messages\"]\n    )\n\n    # 3. as superuser, delete someone else's private dataset\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": 1,\n            \"user_role\": \"superuser\",\n            \"action\": \"delete\",\n            \"target_name\": \"dataset\",\n            \"target_owner\": 4,\n            \"target_visibility\": \"private\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is True\n    assert (\n        \"Access request check successful. Access granted: True.\"\n        in access_check[\"messages\"]\n    )\n\n    # 4. as locked user, try to view a public collection\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": 3,\n            \"user_role\": \"locked\",\n            \"action\": \"view\",\n            \"target_name\": \"collection\",\n            \"target_owner\": 1,\n            \"target_visibility\": \"public\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is False\n    assert (\n        \"Access request check successful. Access granted: False.\"\n        in access_check[\"messages\"]\n    )\n\n    # 5. as an unknown user with superuser privileges, try to edit a private\n    # dataset\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": 10,\n            \"user_role\": \"superuser\",\n            \"action\": \"edit\",\n            \"target_name\": \"dataset\",\n            \"target_owner\": 1,\n            \"target_visibility\": \"private\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is False\n    assert (\n        \"Access request check successful. Access granted: False.\"\n        in access_check[\"messages\"]\n    )\n\n    # 6. as a known user but non-activated account, try to view a collection\n    access_check = actions.check_user_access(\n        {\n            \"user_id\": 5,\n            \"user_role\": \"authenticated\",\n            \"action\": \"view\",\n            \"target_name\": \"collection\",\n            \"target_owner\": 1,\n            \"target_visibility\": \"public\",\n            \"target_sharedwith\": \"\",\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert access_check[\"success\"] is False\n    assert (\n        \"Access request check successful. Access granted: False.\"\n        in access_check[\"messages\"]\n    )\n\n    #\n    # teardown\n    #\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 1}
{"code": "def test_role_limits():\n    \"\"\"\n    This tests if we can check the permissions for a logged-in user.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-permcheck@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-permcheck@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n    )\n\n    # make a non-verified user\n    user_payload2 = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-permcheck2@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created2 = actions.create_new_user(\n        user_payload2,\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n    )\n    assert user_created2[\"success\"] is True\n    assert user_created2[\"user_email\"] == \"testuser-permcheck2@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created2[\"messages\"]\n    )\n\n    #\n    # now run the limit checks\n    #\n\n    # get the permissions JSON\n    thisdir = os.path.dirname(__file__)\n    permissions_json = os.path.abspath(\n        os.path.join(thisdir, \"..\", \"default-permissions-model.json\")\n    )\n\n    # 1. superuser 10000 requests\n    limit_check = actions.check_user_limit(\n        {\n            \"user_id\": 1,\n            \"user_role\": \"superuser\",\n            \"limit_name\": \"max_requests\",\n            \"value_to_check\": 10000,\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert limit_check[\"success\"] is True\n    assert (\n        \"Limit check successful. Limit check passed: True.\"\n        in limit_check[\"messages\"]\n    )\n\n    # 2. superuser 10000000 requests/minute\n    # (this would probably melt the Ethernet card before it hits our server)\n    limit_check = actions.check_user_limit(\n        {\n            \"user_id\": 1,\n            \"user_role\": \"superuser\",\n            \"limit_name\": \"max_requests_per_minute\",\n            \"value_to_check\": 10000000,\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert limit_check[\"success\"] is False\n    assert (\n        \"Limit check successful. Limit check passed: False.\"\n        in limit_check[\"messages\"]\n    )\n\n    # 3. authenticated 10000 requests\n    limit_check = actions.check_user_limit(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"user_role\": \"authenticated\",\n            \"limit_name\": \"max_requests\",\n            \"value_to_check\": 10000,\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert limit_check[\"success\"] is True\n    assert (\n        \"Limit check successful. Limit check passed: True.\"\n        in limit_check[\"messages\"]\n    )\n\n    # 4. authenticated 10000000 requests/minute\n    # (this would probably melt the Ethernet card before it hits our server)\n    limit_check = actions.check_user_limit(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"user_role\": \"authenticated\",\n            \"limit_name\": \"max_requests_per_minute\",\n            \"value_to_check\": 10000000,\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert limit_check[\"success\"] is False\n    assert (\n        \"Limit check successful. Limit check passed: False.\"\n        in limit_check[\"messages\"]\n    )\n\n    # 5. invalid superuser 1000 requests\n    limit_check = actions.check_user_limit(\n        {\n            \"user_id\": emailverify[\"user_id\"],\n            \"user_role\": \"superuser\",\n            \"limit_name\": \"max_requests\",\n            \"value_to_check\": 1000,\n            \"reqid\": 1,\n            \"pii_salt\": \"dummy-pii-salt\",\n        },\n        override_authdb_path=\"sqlite:///test-permcheck.authdb.sqlite\",\n        override_permissions_json=permissions_json,\n        raiseonfail=True,\n    )\n    assert limit_check[\"success\"] is False\n    assert (\n        \"Limit check successful. Limit check passed: False.\"\n        in limit_check[\"messages\"]\n    )\n\n    #\n    # teardown\n    #\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-permcheck.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_internal_user_edit():\n    \"\"\"\n    This tests if we can add user info to a user dict.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-userinfo.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userinfo.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userinfo.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-userinfo@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n        \"extra_info\": {\n            \"pref_thing_always_private\": True,\n            \"pref_advancedbits\": \"this should be deleted\",\n        },\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-userinfo.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-userinfo@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    #\n    # now try to edit info for the user\n    #\n\n    user_info_added = actions.internal_edit_user(\n        {\n            \"target_userid\": user_created[\"user_id\"],\n            \"update_dict\": {\n                \"extra_info\": {\n                    \"this\": \"is\",\n                    \"a\": \"test\",\n                    \"pref_thing_always_private\": False,\n                    \"pref_advancedbits\": \"__delete__\",\n                },\n                \"is_active\": True,\n                \"email_verified\": True,\n                \"full_name\": \"Test Middle Named User\",\n            },\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userinfo.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert user_info_added[\"success\"] is True\n\n    new_user_info = user_info_added[\"user_info\"]\n\n    assert new_user_info[\"email_verified\"] is True\n    assert new_user_info[\"is_active\"] is True\n    assert isinstance(new_user_info[\"extra_info\"], dict)\n    assert new_user_info[\"extra_info\"][\"this\"] == \"is\"\n    assert new_user_info[\"extra_info\"][\"a\"] == \"test\"\n    assert new_user_info[\"extra_info\"][\"pref_thing_always_private\"] is False\n    assert new_user_info[\"extra_info\"].get(\"pref_advancedbits\", None) is None\n\n    # now try to update some disallowed fields and see if it fails as expected\n    user_info_added = actions.internal_edit_user(\n        {\n            \"target_userid\": user_created[\"user_id\"],\n            \"update_dict\": {\n                \"user_id\": 10,\n                \"system_id\": \"pwned\",\n                \"password\": \"pwnedx2\",\n            },\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userinfo.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    print(user_info_added[\"failure_reason\"])\n    assert user_info_added[\"success\"] is False\n    assert (\n        \"invalid request: disallowed keys in update_dict\"\n        in user_info_added[\"failure_reason\"]\n    )\n    assert \"password\" in user_info_added[\"failure_reason\"]\n    assert \"user_id\" in user_info_added[\"failure_reason\"]\n    assert \"system_id\" in user_info_added[\"failure_reason\"]\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-userinfo.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userinfo.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userinfo.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_user_lock():\n    \"\"\"\n    This tests if we can add session info to a session dict.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-userlock.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userlock.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userlock.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser-userlock@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser-userlock@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # set our user_role to staff -- this tests if the user's user_role is reset\n    # to their original user_role after unlocking\n    user_edit = actions.internal_edit_user(\n        {\n            \"target_userid\": user_created[\"user_id\"],\n            \"update_dict\": {\"user_role\": \"staff\"},\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 2,\n        },\n        raiseonfail=True,\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert user_edit[\"success\"] is True\n    assert user_edit[\"user_info\"][\"user_role\"] == \"staff\"\n\n    # now make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n\n    #\n    # 1. try to lock this user\n    #\n\n    user_locked = actions.internal_toggle_user_lock(\n        {\n            \"target_userid\": emailverify[\"user_id\"],\n            \"action\": \"lock\",\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n        raiseonfail=True,\n    )\n\n    assert user_locked[\"success\"] is True\n    assert user_locked[\"user_info\"][\"user_role\"] == \"locked\"\n    assert user_locked[\"user_info\"][\"is_active\"] is False\n\n    # check if the session token for this logged in user still exists\n    info_check = actions.auth_session_exists(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert info_check[\"success\"] is False\n\n    # try to login as this user using another session\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token3 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert session_token3[\"success\"] is True\n    assert session_token3[\"session_token\"] is not None\n\n    # try logging in now\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token3[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n\n    # this should fail\n    assert login[\"success\"] is False\n\n    #\n    # 2. unlock the user now\n    #\n\n    user_unlocked = actions.internal_toggle_user_lock(\n        {\n            \"target_userid\": emailverify[\"user_id\"],\n            \"action\": \"unlock\",\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n        raiseonfail=True,\n    )\n    assert user_unlocked[\"success\"] is True\n    assert user_unlocked[\"user_info\"][\"user_role\"] == \"staff\"\n    assert user_unlocked[\"user_info\"][\"is_active\"] is True\n\n    # try to login\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token3 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n    assert session_token3[\"success\"] is True\n    assert session_token3[\"session_token\"] is not None\n\n    # try logging in now with correct password\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token3[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-userlock.authdb.sqlite\",\n    )\n\n    # this should succeed\n    assert login[\"success\"] is True\n\n    currproc = mp.current_process()\n    if getattr(currproc, \"authdb_meta\", None):\n        del currproc.authdb_meta\n\n    if getattr(currproc, \"connection\", None):\n        currproc.authdb_conn.close()\n        del currproc.authdb_conn\n\n    if getattr(currproc, \"authdb_engine\", None):\n        currproc.authdb_engine.dispose()\n        del currproc.authdb_engine\n\n    try:\n        os.remove(\"test-userlock.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userlock.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-userlock.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_ratelimits(monkeypatch, tmpdir):\n    \"\"\"\n    This tests if the server does rate-limiting correctly.\n\n    \"\"\"\n\n    # the basedir will be the pytest provided temporary directory\n    basedir = str(tmpdir)\n\n    # we'll make the auth DB and secrets file first\n    (\n        authdb_path,\n        creds,\n        secrets_file,\n        salt_file,\n        env_file,\n    ) = autogen_secrets_authdb(basedir, interactive=False)\n\n    # read in the secrets file for the secret\n    with open(secrets_file, \"r\") as infd:\n        secret = infd.read().strip(\"\\n\")\n\n    # read in the salts file for the salt\n    with open(salt_file, \"r\") as infd:\n        salt = infd.read().strip(\"\\n\")\n\n    # read the creds file so we can try logging in\n    with open(creds, \"r\") as infd:\n        useremail, password = infd.read().strip(\"\\n\").split()\n\n    # get a temp directory\n    tmpdir = os.path.join(\"/tmp\", \"authnzrv-%s\" % secrets.token_urlsafe(8))\n\n    server_listen = \"127.0.0.1\"\n    server_port = \"18158\"\n\n    # set up the environment\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", authdb_path)\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", basedir)\n    monkeypatch.setenv(\"AUTHNZERVER_CACHEDIR\", tmpdir)\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", server_listen)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", server_port)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", \"none\")\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"1\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n\n    # set the session request rate-limit to 120 per 60 seconds\n    # set the limit for the 'user-list' API call to 10 per 60 seconds\n    monkeypatch.setenv(\n        \"AUTHNZERVER_RATELIMITS\",\n        \"ipaddr:300;user:360;session:120;apikey:720;burst:150;user-list:10\",\n    )\n\n    # launch the server subprocess\n    p = subprocess.Popen(\"authnzrv\", shell=True)\n\n    # wait 2.5 seconds for the server to start\n    time.sleep(2.5)\n\n    try:\n\n        #\n        # 1. hit the server with 300 session-new requests\n        #\n        nreqs = 300\n\n        resplist = []\n        for req_ind in range(1, nreqs + 1):\n\n            # create a new anonymous session token\n            session_payload = {\n                \"user_id\": 2,\n                \"user_agent\": \"Mozzarella Killerwhale\",\n                \"expires\": datetime.utcnow() + timedelta(hours=1),\n                \"ip_address\": \"1.1.1.1\",\n                \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            }\n\n            request_dict = {\n                \"request\": \"session-new\",\n                \"body\": session_payload,\n                \"reqid\": req_ind,\n                \"client_ipaddr\": \"1.1.1.1\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=5.0,\n            )\n            resplist.append(resp.status_code)\n\n        # now check if we have about the right number of successful requests\n        # should be around 150 (max burst allowed) after which we get all 429s\n        respcounter = Counter(resplist)\n        print(respcounter)\n        assert respcounter[200] / nreqs == approx(150 / nreqs, rel=1.0e-3)\n        assert respcounter[429] / nreqs == approx(150 / nreqs, rel=1.0e-3)\n\n        #\n        # 2. check if the specific rate-limiting works as expected\n        #\n        resplist = []\n        for req_ind in range(1, nreqs + 1):\n\n            # create a new anonymous session token\n            list_payload = {\n                \"user_id\": 3,\n            }\n\n            request_dict = {\n                \"request\": \"user-list\",\n                \"body\": list_payload,\n                \"reqid\": req_ind,\n                \"client_ipaddr\": \"1.1.1.1\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=5.0,\n            )\n            resplist.append(resp.status_code)\n\n        # now check if we have about the right number of successful requests\n        # should be around 10 (max allowed / 60 sec) after which we get all\n        # 429s\n        respcounter = Counter(resplist)\n        print(respcounter)\n        assert respcounter[200] / nreqs == approx(10 / nreqs, rel=1.0e-3)\n        assert respcounter[429] / nreqs == approx(290 / nreqs, rel=1.0e-3)\n\n        #\n        # 2. check if the default aggressive rate-limiting on sensitive\n        # operations works as expected\n        #\n        resplist = []\n        for req_ind in range(1, nreqs + 1):\n\n            # create a new anonymous session token\n            user_payload = {\n                \"email\": f\"{secrets.token_hex(6)}@example.com\",\n                \"password\": secrets.token_hex(16),\n                \"full_name\": secrets.token_hex(8),\n            }\n\n            request_dict = {\n                \"request\": \"user-new\",\n                \"body\": user_payload,\n                \"reqid\": req_ind,\n                \"client_ipaddr\": \"1.1.1.1\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=5.0,\n            )\n            resplist.append(resp.status_code)\n\n        # now check if we have about the right number of successful requests\n        # should be around 5 (max allowed / 60 sec) after which we get all\n        # 429s\n        respcounter = Counter(resplist)\n        print(respcounter)\n        assert respcounter[200] / nreqs == approx(5 / nreqs, rel=1.0e-3)\n        assert respcounter[429] / nreqs == approx(295 / nreqs, rel=1.0e-3)\n\n    #\n    # kill the server at the end\n    #\n\n    finally:\n\n        p.terminate()\n        try:\n            p.communicate(timeout=5.0)\n            p.kill()\n        except Exception:\n            pass", "od": 0}
{"code": "def test_server_with_env(monkeypatch, tmpdir):\n    \"\"\"\n    This tests if the server starts fine with all config in the environment.\n\n    \"\"\"\n\n    # the basedir will be the pytest provided temporary directory\n    basedir = str(tmpdir)\n\n    # we'll make the auth DB and secrets file first\n    (\n        authdb_path,\n        creds,\n        secrets_file,\n        salt_file,\n        env_file,\n    ) = autogen_secrets_authdb(basedir, interactive=False)\n\n    # read in the secrets file for the secret\n    with open(secrets_file, \"r\") as infd:\n        secret = infd.read().strip(\"\\n\")\n\n    # read in the salts file for the salt\n    with open(salt_file, \"r\") as infd:\n        salt = infd.read().strip(\"\\n\")\n\n    # read the creds file so we can try logging in\n    with open(creds, \"r\") as infd:\n        useremail, password = infd.read().strip(\"\\n\").split()\n\n    # get a temp directory\n    tmpdir = os.path.join(\"/tmp\", \"authnzrv-%s\" % secrets.token_urlsafe(8))\n\n    server_listen = \"127.0.0.1\"\n    server_port = \"18158\"\n\n    # set up the environment\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", authdb_path)\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", basedir)\n    monkeypatch.setenv(\"AUTHNZERVER_CACHEDIR\", tmpdir)\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", server_listen)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", server_port)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", salt)\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"1\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n    monkeypatch.setenv(\n        \"AUTHNZERVER_RATELIMITS\",\n        \"ipaddr:300;user:360;session:120;apikey:720;burst:150;\"\n        \"user-new:50;user-login:50\",\n    )\n\n    # launch the server subprocess\n    p = subprocess.Popen(\"authnzrv\", shell=True)\n\n    # wait 2.5 seconds for the server to start\n    time.sleep(2.5)\n\n    try:\n\n        #\n        # 1. hit the server with a request for a new session\n        #\n\n        # create a new anonymous session token\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        }\n\n        request_dict = {\n            \"request\": \"session-new\",\n            \"body\": session_payload,\n            \"reqid\": 101,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=1.0,\n        )\n        resp.raise_for_status()\n\n        # decrypt the response\n        response_dict = decrypt_message(resp.text, secret)\n\n        assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert response_dict[\"success\"] is True\n        assert isinstance(response_dict[\"response\"], dict)\n        assert response_dict[\"response\"][\"session_token\"] is not None\n\n        #\n        # 2. login as the superuser\n        #\n        request_dict = {\n            \"request\": \"user-login\",\n            \"body\": {\n                \"session_token\": response_dict[\"response\"][\"session_token\"],\n                \"email\": useremail,\n                \"password\": password,\n            },\n            \"reqid\": 102,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=1.0,\n        )\n        resp.raise_for_status()\n\n        # decrypt the response\n        response_dict = decrypt_message(resp.text, secret)\n\n        assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert response_dict[\"success\"] is True\n        assert isinstance(response_dict[\"response\"], dict)\n        assert response_dict[\"response\"][\"user_id\"] == 1\n\n        #\n        # kill the server at the end\n        #\n\n    finally:\n\n        p.terminate()\n        try:\n            p.communicate(timeout=3.0)\n            p.kill()\n        except Exception:\n            pass", "od": 0}
{"code": "def test_server_invalid_logins(monkeypatch, tmpdir):\n    \"\"\"This tests if the server responds appropriately to invalid logins.\n\n    The timing difference between successive failed logins should increase\n    roughly exponentially.\n\n    \"\"\"\n\n    # the basedir will be the pytest provided temporary directory\n    basedir = str(tmpdir)\n\n    # we'll make the auth DB and secrets file first\n    (\n        authdb_path,\n        creds,\n        secrets_file,\n        salt_file,\n        env_file,\n    ) = autogen_secrets_authdb(basedir, interactive=False)\n\n    # read in the secrets file for the secret\n    with open(secrets_file, \"r\") as infd:\n        secret = infd.read().strip(\"\\n\")\n\n    # read in the salts file for the salt\n    with open(salt_file, \"r\") as infd:\n        salt = infd.read().strip(\"\\n\")\n\n    # read the creds file so we can try logging in\n    with open(creds, \"r\") as infd:\n        useremail, password = infd.read().strip(\"\\n\").split()\n\n    # get a temp directory\n    tmpdir = os.path.join(\"/tmp\", \"authnzrv-%s\" % secrets.token_urlsafe(8))\n\n    server_listen = \"127.0.0.1\"\n    server_port = \"18158\"\n\n    # set up the environment\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", authdb_path)\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", basedir)\n    monkeypatch.setenv(\"AUTHNZERVER_CACHEDIR\", tmpdir)\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", server_listen)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", server_port)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", salt)\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"1\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n    monkeypatch.setenv(\n        \"AUTHNZERVER_RATELIMITS\",\n        \"ipaddr:300;user:360;session:120;apikey:720;burst:150;\"\n        \"user-new:50;user-login:50\",\n    )\n\n    # launch the server subprocess\n    p = subprocess.Popen(\"authnzrv\", shell=True)\n\n    # wait 2.5 seconds for the server to start\n    time.sleep(2.5)\n\n    timing = []\n\n    try:\n\n        #\n        # attempt to login as the superuser several times with the wrong\n        # password\n        #\n        for i in range(5):\n\n            # create a new anonymous session token\n            session_payload = {\n                \"user_id\": 2,\n                \"user_agent\": \"Mozzarella Killerwhale\",\n                \"expires\": datetime.utcnow() + timedelta(hours=1),\n                \"ip_address\": \"1.1.1.1\",\n                \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            }\n\n            request_dict = {\n                \"request\": \"session-new\",\n                \"body\": session_payload,\n                \"reqid\": i,\n                \"client_ipaddr\": \"1.2.3.4\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=1.0,\n            )\n            resp.raise_for_status()\n\n            # decrypt the response\n            session_dict = decrypt_message(resp.text, secret)\n\n            assert session_dict[\"reqid\"] == request_dict[\"reqid\"]\n            assert session_dict[\"success\"] is True\n            assert isinstance(session_dict[\"response\"], dict)\n            assert session_dict[\"response\"][\"session_token\"] is not None\n\n            request_dict = {\n                \"request\": \"user-login\",\n                \"body\": {\n                    \"session_token\": session_dict[\"response\"][\"session_token\"],\n                    \"email\": useremail,\n                    \"password\": \"%s-%i\" % (password, i),\n                },\n                \"reqid\": 10 * i + 10,\n                \"client_ipaddr\": \"1.2.3.4\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            start_login_time = time.monotonic()\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=60.0,\n            )\n            resp.raise_for_status()\n\n            timing.append(time.monotonic() - start_login_time)\n\n            # decrypt the response\n            response_dict = decrypt_message(resp.text, secret)\n\n            assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n            assert response_dict[\"success\"] is False\n            assert isinstance(response_dict[\"response\"], dict)\n            assert response_dict[\"response\"][\"user_id\"] is None\n\n        #\n        # check if the timings follow the expected trend\n        #\n        diffs = [timing[x + 1] - timing[x] for x in range(4)]\n        diffs_increasing = all(diffs[x + 1] > diffs[x] for x in range(3))\n        assert diffs_increasing is True\n\n        # now login wih the correct password and see if the login time goes back\n        # to normal\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        }\n\n        request_dict = {\n            \"request\": \"session-new\",\n            \"body\": session_payload,\n            \"reqid\": 1004,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=1.0,\n        )\n        resp.raise_for_status()\n\n        # decrypt the response\n        session_dict = decrypt_message(resp.text, secret)\n\n        assert session_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert session_dict[\"success\"] is True\n        assert isinstance(session_dict[\"response\"], dict)\n        assert session_dict[\"response\"][\"session_token\"] is not None\n\n        request_dict = {\n            \"request\": \"user-login\",\n            \"body\": {\n                \"session_token\": session_dict[\"response\"][\"session_token\"],\n                \"email\": useremail,\n                \"password\": password,\n            },\n            \"reqid\": 1005,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        start_login_time = time.monotonic()\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=60.0,\n        )\n        resp.raise_for_status()\n\n        timing.append(time.monotonic() - start_login_time)\n\n        # decrypt the response\n        response_dict = decrypt_message(resp.text, secret)\n\n        assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert response_dict[\"success\"] is True\n        assert isinstance(response_dict[\"response\"], dict)\n        assert response_dict[\"response\"][\"user_id\"] == 1\n\n        # the latest time should be less than the 1st time (when throttling was\n        # activated) and also less than the immediately previous time\n        assert (timing[-1] < timing[0]) and (timing[-1] < timing[-2])\n\n    finally:\n\n        #\n        # kill the server at the end\n        #\n\n        p.terminate()\n        try:\n            p.communicate(timeout=3.0)\n            p.kill()\n        except Exception:\n            pass", "od": 0}
{"code": "def test_server_invalid_logins_with_lock(monkeypatch, tmpdir):\n    \"\"\"This tests if the server responds appropriately to invalid logins.\n\n    The timing difference between successive failed logins should increase\n    roughly exponentially. In addition, the user should be locked out of their\n    account for the configured amount of time and unlocked thereafter.\n\n    \"\"\"\n\n    # the basedir will be the pytest provided temporary directory\n    basedir = str(tmpdir)\n\n    # we'll make the auth DB and secrets file first\n    (\n        authdb_path,\n        creds,\n        secrets_file,\n        salt_file,\n        env_file,\n    ) = autogen_secrets_authdb(basedir, interactive=False)\n\n    # read in the secrets file for the secret\n    with open(secrets_file, \"r\") as infd:\n        secret = infd.read().strip(\"\\n\")\n\n    # read in the salts file for the salt\n    with open(salt_file, \"r\") as infd:\n        salt = infd.read().strip(\"\\n\")\n\n    # read the creds file so we can try logging in\n    with open(creds, \"r\") as infd:\n        useremail, password = infd.read().strip(\"\\n\").split()\n\n    # get a temp directory\n    tmpdir = os.path.join(\"/tmp\", \"authnzrv-%s\" % secrets.token_urlsafe(8))\n\n    server_listen = \"127.0.0.1\"\n    server_port = \"18158\"\n\n    # set up the environment\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", authdb_path)\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", basedir)\n    monkeypatch.setenv(\"AUTHNZERVER_CACHEDIR\", tmpdir)\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", server_listen)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", server_port)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", salt)\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"1\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n    monkeypatch.setenv(\"AUTHNZERVER_USERLOCKTRIES\", \"2\")\n    monkeypatch.setenv(\"AUTHNZERVER_USERLOCKTIME\", \"20\")\n    monkeypatch.setenv(\n        \"AUTHNZERVER_RATELIMITS\",\n        \"ipaddr:300;user:360;session:120;apikey:720;burst:150;\"\n        \"user-new:50;user-login:50\",\n    )\n\n    # launch the server subprocess\n    p = subprocess.Popen(\"authnzrv\", shell=True)\n\n    # wait 2.5 seconds for the server to start\n    time.sleep(2.5)\n\n    timing = []\n\n    try:\n\n        #\n        # attempt to login as the superuser several times with the wrong\n        # password\n        #\n        for i in range(4):\n\n            # create a new anonymous session token\n            session_payload = {\n                \"user_id\": 2,\n                \"user_agent\": \"Mozzarella Killerwhale\",\n                \"expires\": datetime.utcnow() + timedelta(hours=1),\n                \"ip_address\": \"1.1.1.1\",\n                \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            }\n\n            request_dict = {\n                \"request\": \"session-new\",\n                \"body\": session_payload,\n                \"reqid\": i,\n                \"client_ipaddr\": \"1.2.3.4\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=1.0,\n            )\n            resp.raise_for_status()\n\n            # decrypt the response\n            session_dict = decrypt_message(resp.text, secret)\n\n            assert session_dict[\"reqid\"] == request_dict[\"reqid\"]\n            assert session_dict[\"success\"] is True\n            assert isinstance(session_dict[\"response\"], dict)\n            assert session_dict[\"response\"][\"session_token\"] is not None\n\n            request_dict = {\n                \"request\": \"user-login\",\n                \"body\": {\n                    \"session_token\": session_dict[\"response\"][\"session_token\"],\n                    \"email\": useremail,\n                    \"password\": \"%s-%i\" % (password, i),\n                },\n                \"reqid\": 10 * i + 10,\n                \"client_ipaddr\": \"1.2.3.4\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            start_login_time = time.monotonic()\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=60.0,\n            )\n            resp.raise_for_status()\n\n            timing.append(time.monotonic() - start_login_time)\n\n            # decrypt the response\n            response_dict = decrypt_message(resp.text, secret)\n\n            assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n            assert response_dict[\"success\"] is False\n            assert isinstance(response_dict[\"response\"], dict)\n            assert response_dict[\"response\"][\"user_id\"] is None\n\n            # for the last attempt, we should get back a \"locked\" account\n            # message\n            if i >= 2:\n\n                assert (\n                    \"Your user account has been locked \"\n                    \"after repeated login failures. \"\n                    \"Try again in an hour or \"\n                    \"contact the server admins.\"\n                ) in response_dict[\"messages\"]\n\n        # wait 30 seconds for the lock time to expire\n        time.sleep(30)\n\n        # now login wih the correct password and see if we can login now\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        }\n\n        request_dict = {\n            \"request\": \"session-new\",\n            \"body\": session_payload,\n            \"reqid\": 1004,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=1.0,\n        )\n        resp.raise_for_status()\n\n        # decrypt the response\n        session_dict = decrypt_message(resp.text, secret)\n\n        assert session_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert session_dict[\"success\"] is True\n        assert isinstance(session_dict[\"response\"], dict)\n        assert session_dict[\"response\"][\"session_token\"] is not None\n\n        request_dict = {\n            \"request\": \"user-login\",\n            \"body\": {\n                \"session_token\": session_dict[\"response\"][\"session_token\"],\n                \"email\": useremail,\n                \"password\": password,\n            },\n            \"reqid\": 1005,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        start_login_time = time.monotonic()\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=60.0,\n        )\n        resp.raise_for_status()\n\n        timing.append(time.monotonic() - start_login_time)\n\n        # decrypt the response\n        response_dict = decrypt_message(resp.text, secret)\n\n        assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert response_dict[\"success\"] is True\n        assert isinstance(response_dict[\"response\"], dict)\n        assert response_dict[\"response\"][\"user_id\"] == 1\n        assert response_dict[\"response\"][\"user_role\"] == \"superuser\"\n\n    finally:\n\n        #\n        # kill the server at the end\n        #\n\n        p.terminate()\n        try:\n            p.communicate(timeout=3.0)\n            p.kill()\n        except Exception:\n            pass", "od": 0}
{"code": "def test_server_invalid_passchecks_with_lock(monkeypatch, tmpdir):\n    \"\"\"This tests if the server responds appropriately to\n    invalid password checks.\n\n    The timing difference between successive failed password checks should\n    increase roughly exponentially. In addition, the user should be locked out\n    of their account for the configured amount of time and unlocked thereafter.\n\n    \"\"\"\n\n    # the basedir will be the pytest provided temporary directory\n    basedir = str(tmpdir)\n\n    # we'll make the auth DB and secrets file first\n    (\n        authdb_path,\n        creds,\n        secrets_file,\n        salt_file,\n        env_file,\n    ) = autogen_secrets_authdb(basedir, interactive=False)\n\n    # read in the secrets file for the secret\n    with open(secrets_file, \"r\") as infd:\n        secret = infd.read().strip(\"\\n\")\n\n    # read in the salts file for the salt\n    with open(salt_file, \"r\") as infd:\n        salt = infd.read().strip(\"\\n\")\n\n    # read the creds file so we can try logging in\n    with open(creds, \"r\") as infd:\n        useremail, password = infd.read().strip(\"\\n\").split()\n\n    # get a temp directory\n    tmpdir = os.path.join(\"/tmp\", \"authnzrv-%s\" % secrets.token_urlsafe(8))\n\n    server_listen = \"127.0.0.1\"\n    server_port = \"18158\"\n\n    # set up the environment\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", authdb_path)\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", basedir)\n    monkeypatch.setenv(\"AUTHNZERVER_CACHEDIR\", tmpdir)\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", server_listen)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", server_port)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", salt)\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"1\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n    monkeypatch.setenv(\"AUTHNZERVER_USERLOCKTRIES\", \"2\")\n    monkeypatch.setenv(\"AUTHNZERVER_USERLOCKTIME\", \"20\")\n    monkeypatch.setenv(\n        \"AUTHNZERVER_RATELIMITS\",\n        \"ipaddr:300;user:360;session:120;apikey:720;burst:150;\"\n        \"user-new:50;user-login:50\",\n    )\n\n    # launch the server subprocess\n    p = subprocess.Popen(\"authnzrv\", shell=True)\n\n    # wait 2.5 seconds for the server to start\n    time.sleep(2.5)\n\n    timing = []\n\n    try:\n\n        #\n        # attempt to login as the superuser several times with the wrong\n        # password\n        #\n        for i in range(4):\n\n            # create a new anonymous session token\n            session_payload = {\n                \"user_id\": 2,\n                \"user_agent\": \"Mozzarella Killerwhale\",\n                \"expires\": datetime.utcnow() + timedelta(hours=1),\n                \"ip_address\": \"1.1.1.1\",\n                \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            }\n\n            request_dict = {\n                \"request\": \"session-new\",\n                \"body\": session_payload,\n                \"reqid\": i,\n                \"client_ipaddr\": \"1.2.3.4\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=1.0,\n            )\n            resp.raise_for_status()\n\n            # decrypt the response\n            session_dict = decrypt_message(resp.text, secret)\n\n            assert session_dict[\"reqid\"] == request_dict[\"reqid\"]\n            assert session_dict[\"success\"] is True\n            assert isinstance(session_dict[\"response\"], dict)\n            assert session_dict[\"response\"][\"session_token\"] is not None\n\n            request_dict = {\n                \"request\": \"user-passcheck-nosession\",\n                \"body\": {\n                    \"email\": useremail,\n                    \"password\": \"%s-%i\" % (password, i),\n                },\n                \"reqid\": 10 * i + 10,\n                \"client_ipaddr\": \"1.2.3.4\",\n            }\n\n            encrypted_request = encrypt_message(request_dict, secret)\n\n            start_login_time = time.monotonic()\n\n            # send the request to the authnzerver\n            resp = requests.post(\n                \"http://%s:%s\" % (server_listen, server_port),\n                data=encrypted_request,\n                timeout=60.0,\n            )\n            resp.raise_for_status()\n\n            timing.append(time.monotonic() - start_login_time)\n\n            # decrypt the response\n            response_dict = decrypt_message(resp.text, secret)\n\n            assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n            assert response_dict[\"success\"] is False\n            assert isinstance(response_dict[\"response\"], dict)\n            assert response_dict[\"response\"][\"user_id\"] is None\n\n            # for the last attempt, we should get back a \"locked\" account\n            # message\n            if i >= 2:\n\n                assert (\n                    \"Your user account has been locked \"\n                    \"after repeated login failures. \"\n                    \"Try again in an hour or \"\n                    \"contact the server admins.\"\n                ) in response_dict[\"messages\"]\n\n        # wait 30 seconds for the lock time to expire\n        time.sleep(30)\n\n        # now login wih the correct password and see if we can login now\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        }\n\n        request_dict = {\n            \"request\": \"session-new\",\n            \"body\": session_payload,\n            \"reqid\": 1004,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=1.0,\n        )\n        resp.raise_for_status()\n\n        # decrypt the response\n        session_dict = decrypt_message(resp.text, secret)\n\n        assert session_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert session_dict[\"success\"] is True\n        assert isinstance(session_dict[\"response\"], dict)\n        assert session_dict[\"response\"][\"session_token\"] is not None\n\n        request_dict = {\n            \"request\": \"user-passcheck-nosession\",\n            \"body\": {\"email\": useremail, \"password\": password},\n            \"reqid\": 1005,\n            \"client_ipaddr\": \"1.2.3.4\",\n        }\n\n        encrypted_request = encrypt_message(request_dict, secret)\n\n        start_login_time = time.monotonic()\n\n        # send the request to the authnzerver\n        resp = requests.post(\n            \"http://%s:%s\" % (server_listen, server_port),\n            data=encrypted_request,\n            timeout=60.0,\n        )\n        resp.raise_for_status()\n\n        timing.append(time.monotonic() - start_login_time)\n\n        # decrypt the response\n        response_dict = decrypt_message(resp.text, secret)\n\n        assert response_dict[\"reqid\"] == request_dict[\"reqid\"]\n        assert response_dict[\"success\"] is True\n        assert isinstance(response_dict[\"response\"], dict)\n        assert response_dict[\"response\"][\"user_id\"] == 1\n        assert response_dict[\"response\"][\"user_role\"] == \"superuser\"\n\n    finally:\n\n        #\n        # kill the server at the end\n        #\n\n        p.terminate()\n        try:\n            p.communicate(timeout=3.0)\n            p.kill()\n        except Exception:\n            pass", "od": 0}
{"code": "def test_staff_access_to_collection(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_staff_access_to_dataset(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_staff_access_to_object(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_staff_access_to_users(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_staff_access_to_sessions(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_staff_access_to_apikeys(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_staff_access_to_preferences(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_login_timing():\n    \"\"\"This tests obfuscating the presence/absence of users based on password\n    checks.\n\n    This may fail randomly if the testing service is under load.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-timing.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-timing.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-timing.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser4@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload,\n        override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser4@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # try logging in now with correct password\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n    )\n\n    # this should fail because we haven't verified our email yet\n    assert login[\"success\"] is False\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # now make a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n\n    # and now try to log in again\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n    )\n\n    assert login[\"success\"] is True\n\n    # basic tests for timing attacks\n\n    # incorrect passwords\n    incorrect_timings = []\n    for _ in range(500):\n\n        # now make a new session token\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        }\n\n        # check creation of session\n        session_token2 = actions.auth_session_new(\n            session_payload,\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n\n        start = time.time()\n        actions.auth_user_login(\n            {\n                \"session_token\": session_token2[\"session_token\"],\n                \"email\": user_payload[\"email\"],\n                \"password\": secrets.token_urlsafe(16),\n                \"pii_salt\": \"super-secret-salt\",\n                \"reqid\": 1,\n            },\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n        end = time.time()\n        incorrect_timings.append(end - start)\n\n    # correct passwords\n    correct_timings = []\n    for _ in range(500):\n\n        # now make a new session token\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        }\n\n        # check creation of session\n        session_token2 = actions.auth_session_new(\n            session_payload,\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n\n        start = time.time()\n        actions.auth_user_login(\n            {\n                \"session_token\": session_token2[\"session_token\"],\n                \"email\": user_payload[\"email\"],\n                \"password\": user_payload[\"password\"],\n                \"pii_salt\": \"super-secret-salt\",\n                \"reqid\": 1,\n            },\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n        end = time.time()\n        correct_timings.append(end - start)\n\n    # wronguser passwords\n    wronguser_timings = []\n    for _ in range(500):\n\n        # now make a new session token\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        }\n\n        # check creation of session\n        session_token2 = actions.auth_session_new(\n            session_payload,\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n\n        start = time.time()\n        actions.auth_user_login(\n            {\n                \"session_token\": session_token2[\"session_token\"],\n                \"email\": secrets.token_urlsafe(16),\n                \"password\": secrets.token_urlsafe(16),\n                \"pii_salt\": \"super-secret-salt\",\n                \"reqid\": 1,\n            },\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n        end = time.time()\n        wronguser_timings.append(end - start)\n\n    # broken requests\n    broken_timings = []\n    for _ in range(500):\n\n        # now make a new session token\n        session_payload = {\n            \"user_id\": 2,\n            \"user_agent\": \"Mozzarella Killerwhale\",\n            \"expires\": datetime.utcnow() + timedelta(hours=1),\n            \"ip_address\": \"1.1.1.1\",\n            \"extra_info_json\": {\"pref_datasets_always_private\": True},\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        }\n\n        # check creation of session\n        session_token2 = actions.auth_session_new(\n            session_payload,\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n\n        start = time.time()\n        actions.auth_user_login(\n            {\n                \"session_token\": \"correcthorsebatterystaple\",\n                \"email\": user_payload[\"email\"],\n                \"password\": user_payload[\"password\"],\n                \"pii_salt\": \"super-secret-salt\",\n                \"reqid\": 1,\n            },\n            override_authdb_path=\"sqlite:///test-timing.authdb.sqlite\",\n        )\n        end = time.time()\n        broken_timings.append(end - start)\n\n    correct_median = statistics.median(correct_timings)\n    incorrect_median = statistics.median(incorrect_timings)\n    broken_median = statistics.median(broken_timings)\n    wronguser_median = statistics.median(wronguser_timings)\n\n    # all timings should match within 10 milliseconds or so\n    assert abs(correct_median - incorrect_median) < 0.01\n    assert abs(correct_median - broken_median) < 0.01\n    assert abs(correct_median - wronguser_median) < 0.01\n\n    try:\n        os.remove(\"test-timing.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-timing.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-timing.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_client(monkeypatch, tmpdir):\n    \"\"\"\n    This tests if the server does rate-limiting correctly.\n\n    \"\"\"\n\n    # the basedir will be the pytest provided temporary directory\n    basedir = str(tmpdir)\n\n    # we'll make the auth DB and secrets file first\n    (\n        authdb_path,\n        creds,\n        secrets_file,\n        salt_file,\n        env_file,\n    ) = autogen_secrets_authdb(basedir, interactive=False)\n\n    # read in the secrets file for the secret\n    with open(secrets_file, \"r\") as infd:\n        secret = infd.read().strip(\"\\n\")\n\n    # read in the salts file for the salt\n    with open(salt_file, \"r\") as infd:\n        salt = infd.read().strip(\"\\n\")\n\n    # read the creds file so we can try logging in\n    with open(creds, \"r\") as infd:\n        useremail, password = infd.read().strip(\"\\n\").split()\n\n    # get a temp directory\n    tmpdir = os.path.join(\"/tmp\", \"authnzrv-%s\" % secrets.token_urlsafe(8))\n\n    server_listen = \"127.0.0.1\"\n    server_port = \"18158\"\n\n    # set up the environment\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", authdb_path)\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", basedir)\n    monkeypatch.setenv(\"AUTHNZERVER_CACHEDIR\", tmpdir)\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", server_listen)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", server_port)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", salt)\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"1\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n\n    # set the session request rate-limit to 120 per 60 seconds\n    monkeypatch.setenv(\n        \"AUTHNZERVER_RATELIMITS\",\n        \"ipaddr:720;user:360;session:120;apikey:720;burst:150\",\n    )\n\n    # launch the server subprocess\n    p = subprocess.Popen(\"authnzrv\", shell=True)\n\n    # wait 2.5 seconds for the server to start\n    time.sleep(2.5)\n\n    #\n    # start tests\n    #\n    try:\n\n        client = Authnzerver(\n            authnzerver_url=f\"http://{server_listen}:{server_port}\",\n            authnzerver_secret=secret,\n        )\n\n        # create a new user\n        resp = client.request(\n            \"user-new\",\n            {\n                \"email\": \"test-user@test.org\",\n                \"password\": \"atYSE6m3bsBL\",\n                \"full_name\": \"New User\",\n                \"client_ipaddr\": \"1.2.3.4\",\n            },\n        )\n        assert resp.success is True\n        assert resp.response[\"user_id\"] == 4\n        assert resp.response[\"send_verification\"] is True\n\n        # edit their info\n        resp = client.request(\n            \"internal-user-edit\",\n            {\n                \"target_userid\": 4,\n                \"client_ipaddr\": \"1.2.3.4\",\n                \"update_dict\": {\n                    \"email_verified\": True,\n                    \"is_active\": True,\n                    \"extra_info\": {\n                        \"provenance\": \"pytest-user\",\n                        \"type\": \"test\",\n                        \"hello\": \"world\",\n                    },\n                },\n            },\n        )\n        assert resp.success is True\n        assert resp.response.get(\"user_info\", None) is not None\n        assert (\n            resp.response[\"user_info\"][\"extra_info\"][\"provenance\"]\n            == \"pytest-user\"\n        )\n        assert resp.response[\"user_info\"][\"extra_info\"][\"type\"] == \"test\"\n        assert resp.response[\"user_info\"][\"extra_info\"][\"hello\"] == \"world\"\n        assert resp.response[\"user_info\"][\"email_verified\"] is True\n        assert resp.response[\"user_info\"][\"is_active\"] is True\n\n    #\n    # kill the server at the end\n    #\n    finally:\n\n        p.terminate()\n        try:\n            p.communicate(timeout=3.0)\n            p.kill()\n        except Exception:\n            pass", "od": 0}
{"code": "def test_check_locked_access_to_collection(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_locked_access_to_dataset(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_locked_access_to_object(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_locked_access_to_users(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_locked_access_to_sessions(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_locked_access_to_apikeys(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_check_locked_access_to_preferences(access, target, expected):\n    \"\"\"\n    This checks user access.\n\n    \"\"\"\n    userid, role, action = access\n    target_name, target_owner, target_visibility, target_sharedwith = target\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_access(\n            permpath,\n            userid=userid,\n            role=role,\n            action=action,\n            target_name=target_name,\n            target_owner=target_owner,\n            target_visibility=target_visibility,\n            target_sharedwith=target_sharedwith,\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_role_limits(role, limit_name, value_to_check, expected):\n    \"\"\"\n    This checks role limits for the default permissions policy.\n\n    \"\"\"\n\n    # load the default permissions model\n    modpath = os.path.abspath(os.path.dirname(__file__))\n    permpath = os.path.abspath(\n        os.path.join(modpath, \"..\", \"default-permissions-model.json\")\n    )\n\n    assert (\n        permissions.load_policy_and_check_limits(\n            permpath, role, limit_name, value_to_check\n        )\n        is expected\n    )", "od": 0}
{"code": "def test_login():\n    \"\"\"\n    This tests if we can log in successfully or fail correctly.\n\n    \"\"\"\n\n    try:\n        os.remove(\"test-login.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-login.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-login.authdb.sqlite-wal\")\n    except Exception:\n        pass\n\n    get_test_authdb()\n    get_public_suffix_list()\n\n    # create the user\n    user_payload = {\n        \"full_name\": \"Test User\",\n        \"email\": \"testuser2@test.org\",\n        \"password\": \"aROwQin9L8nNtPTEMLXd\",\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n    user_created = actions.create_new_user(\n        user_payload, override_authdb_path=\"sqlite:///test-login.authdb.sqlite\"\n    )\n    assert user_created[\"success\"] is True\n    assert user_created[\"user_email\"] == \"testuser2@test.org\"\n    assert (\n        \"User account created. Please verify your email address to log in.\"\n        in user_created[\"messages\"]\n    )\n\n    # create a new session token\n    session_payload = {\n        \"user_id\": 2,\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token1 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n    assert session_token1[\"success\"] is True\n    assert session_token1[\"session_token\"] is not None\n\n    # try logging in now with correct password\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token1[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n\n    # this should fail because we haven't verified our email yet\n    assert login[\"success\"] is False\n\n    # verify our email\n    emailverify = actions.set_user_emailaddr_verified(\n        {\n            \"email\": user_payload[\"email\"],\n            \"user_id\": user_created[\"user_id\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n\n    assert emailverify[\"success\"] is True\n    assert emailverify[\"user_id\"] == user_created[\"user_id\"]\n    assert emailverify[\"is_active\"] is True\n    assert emailverify[\"user_role\"] == \"authenticated\"\n\n    # now make a new session token\n    session_payload = {\n        \"user_id\": emailverify[\"user_id\"],\n        \"user_agent\": \"Mozzarella Killerwhale\",\n        \"expires\": datetime.utcnow() + timedelta(hours=1),\n        \"ip_address\": \"1.1.1.1\",\n        \"extra_info_json\": {\"pref_datasets_always_private\": True},\n        \"pii_salt\": \"super-secret-salt\",\n        \"reqid\": 1,\n    }\n\n    # check creation of session\n    session_token2 = actions.auth_session_new(\n        session_payload,\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n    assert session_token2[\"success\"] is True\n    assert session_token2[\"session_token\"] is not None\n\n    # and now try to log in again\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n\n    assert login[\"success\"] is True\n\n    # try logging in now with the wrong password\n    login = actions.auth_user_login(\n        {\n            \"session_token\": session_token2[\"session_token\"],\n            \"email\": user_payload[\"email\"],\n            \"password\": \"helloworld\",\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n    assert login[\"success\"] is False\n\n    # tests for no session token provided\n    login = actions.auth_user_login(\n        {\n            \"session_token\": \"correcthorsebatterystaple\",\n            \"email\": user_payload[\"email\"],\n            \"password\": user_payload[\"password\"],\n            \"pii_salt\": \"super-secret-salt\",\n            \"reqid\": 1,\n        },\n        override_authdb_path=\"sqlite:///test-login.authdb.sqlite\",\n    )\n    assert login[\"success\"] is False\n\n    try:\n        os.remove(\"test-login.authdb.sqlite\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-login.authdb.sqlite-shm\")\n    except Exception:\n        pass\n    try:\n        os.remove(\"test-login.authdb.sqlite-wal\")\n    except Exception:\n        pass", "od": 0}
{"code": "def test_load_config_from_env_filesecret(monkeypatch, tmpdir):\n\n    # generate the secret files\n    secret_file = generate_secret_file(tmpdir)\n    salt_file = generate_salt_file(tmpdir)\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", \"sqlite:///test/db/path\")\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", \"/test/base/dir\")\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", \"127.0.0.1\")\n    monkeypatch.setenv(\"AUTHNZERVER_PERMISSIONS\", permissions_json)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", \"13431\")\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", secret_file)\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", salt_file)\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"4\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=generated_options.envfile\n    )\n\n    assert loaded_config.authdb == \"sqlite:///test/db/path\"\n    assert loaded_config.basedir == \"/test/base/dir\"\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"127.0.0.1\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 13431\n    assert loaded_config.secret == \"super-secret-secret\"\n    assert loaded_config.piisalt == \"super-secret-salt\"\n\n    assert loaded_config.sessionexpiry == 60\n    assert loaded_config.workers == 4\n\n    # email setup check\n    assert loaded_config.emailserver == \"smtp.test.org\"\n    assert loaded_config.emailport == 25\n    assert loaded_config.emailuser == \"testuser\"\n    assert loaded_config.emailpass == \"testpass\"", "od": 0}
{"code": "def test_load_config_from_env_textsecret(monkeypatch, tmpdir):\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", \"sqlite:///test/db/path\")\n    monkeypatch.setenv(\"AUTHNZERVER_BASEDIR\", \"/test/base/dir\")\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_LISTEN\", \"127.0.0.1\")\n    monkeypatch.setenv(\"AUTHNZERVER_PERMISSIONS\", permissions_json)\n    monkeypatch.setenv(\"AUTHNZERVER_PORT\", \"13431\")\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", \"this is a direct text secret\")\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", \"this is a direct text salt\")\n    monkeypatch.setenv(\"AUTHNZERVER_SESSIONEXPIRY\", \"60\")\n    monkeypatch.setenv(\"AUTHNZERVER_WORKERS\", \"4\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILSERVER\", \"smtp.test.org\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPORT\", \"25\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILUSER\", \"testuser\")\n    monkeypatch.setenv(\"AUTHNZERVER_EMAILPASS\", \"testpass\")\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=generated_options.envfile\n    )\n\n    assert loaded_config.authdb == \"sqlite:///test/db/path\"\n    assert loaded_config.basedir == \"/test/base/dir\"\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"127.0.0.1\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 13431\n    assert loaded_config.secret == \"this is a direct text secret\"\n    assert loaded_config.piisalt == \"this is a direct text salt\"\n\n    assert loaded_config.sessionexpiry == 60\n    assert loaded_config.workers == 4\n\n    # email setup check\n    assert loaded_config.emailserver == \"smtp.test.org\"\n    assert loaded_config.emailport == 25\n    assert loaded_config.emailuser == \"testuser\"\n    assert loaded_config.emailpass == \"testpass\"", "od": 0}
{"code": "def test_load_config_from_options(monkeypatch, tmpdir):\n\n    # generate the secret files\n    secret_file = generate_secret_file(tmpdir)\n    salt_file = generate_salt_file(tmpdir)\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    generated_options.authdb = \"sqlite:///path/to/auth-db-opt\"\n    generated_options.basedir = \"/path/to/basedir-opt\"\n    generated_options.listen = \"192.168.1.1\"\n    generated_options.port = 15000\n    generated_options.sessionexpiry = 7\n    generated_options.workers = 8\n\n    generated_options.permissions = permissions_json\n    generated_options.secret = secret_file\n    generated_options.piisalt = salt_file\n\n    generated_options.emailserver = \"smtp.test.org\"\n    generated_options.emailport = 25\n    generated_options.emailuser = \"me\"\n    generated_options.emailpass = \"them\"\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=None\n    )\n\n    assert loaded_config.authdb == \"sqlite:///path/to/auth-db-opt\"\n    assert loaded_config.basedir == \"/path/to/basedir-opt\"\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"192.168.1.1\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 15000\n    assert loaded_config.secret == \"super-secret-secret\"\n    assert loaded_config.piisalt == \"super-secret-salt\"\n\n    assert loaded_config.sessionexpiry == 7\n    assert loaded_config.workers == 8\n\n    # email setup check\n    assert loaded_config.emailserver == generated_options.emailserver\n    assert loaded_config.emailport == generated_options.emailport\n    assert loaded_config.emailuser == generated_options.emailuser\n    assert loaded_config.emailpass == generated_options.emailpass", "od": 0}
{"code": "def test_load_config_from_envfile_filesecret(monkeypatch, tmpdir):\n\n    # generate the secret files\n    secret_file = generate_secret_file(tmpdir)\n    salt_file = generate_salt_file(tmpdir)\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    # generate the envfile\n    generated_envfile = generate_envfile(\n        tmpdir,\n        authdb=\"sqlite:///path/to/authdb-envfile\",\n        basedir=\"/path/to/basedir-envfile\",\n        debugmode=0,\n        listen=\"10.0.0.10\",\n        permissions=permissions_json,\n        port=5005,\n        secret=secret_file,\n        piisalt=salt_file,\n        sessionexpiry=25,\n        workers=1,\n        emailserver=\"smtp.test.org\",\n        emailport=25,\n        emailuser=\"testuser\",\n        emailpass=\"testpass\",\n    )\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=generated_envfile\n    )\n\n    assert loaded_config.authdb == \"sqlite:///path/to/authdb-envfile\"\n    assert loaded_config.basedir == \"/path/to/basedir-envfile\"\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"10.0.0.10\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 5005\n    assert loaded_config.secret == \"super-secret-secret\"\n    assert loaded_config.piisalt == \"super-secret-salt\"\n\n    assert loaded_config.sessionexpiry == 25\n    assert loaded_config.workers == 1\n\n    # email setup check\n    assert loaded_config.emailserver == \"smtp.test.org\"\n    assert loaded_config.emailport == 25\n    assert loaded_config.emailuser == \"testuser\"\n    assert loaded_config.emailpass == \"testpass\"", "od": 0}
{"code": "def test_load_config_from_envfile_textsecret(monkeypatch, tmpdir):\n\n    # generate the secrets\n    secret = \"this is a direct secret bit\"\n    piisalt = \"this is a direct secret salt\"\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    # generate the envfile\n    generated_envfile = generate_envfile(\n        tmpdir,\n        authdb=\"sqlite:///path/to/authdb-envfile\",\n        basedir=\"/path/to/basedir-envfile\",\n        debugmode=0,\n        listen=\"10.0.0.10\",\n        permissions=permissions_json,\n        port=5005,\n        secret=secret,\n        piisalt=piisalt,\n        sessionexpiry=25,\n        workers=1,\n        emailserver=\"smtp.test.org\",\n        emailport=25,\n        emailuser=\"testuser\",\n        emailpass=\"testpass\",\n    )\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=generated_envfile\n    )\n\n    assert loaded_config.authdb == \"sqlite:///path/to/authdb-envfile\"\n    assert loaded_config.basedir == \"/path/to/basedir-envfile\"\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"10.0.0.10\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 5005\n    assert loaded_config.secret == \"this is a direct secret bit\"\n    assert loaded_config.piisalt == \"this is a direct secret salt\"\n\n    assert loaded_config.sessionexpiry == 25\n    assert loaded_config.workers == 1\n\n    # email setup check\n    assert loaded_config.emailserver == \"smtp.test.org\"\n    assert loaded_config.emailport == 25\n    assert loaded_config.emailuser == \"testuser\"\n    assert loaded_config.emailpass == \"testpass\"", "od": 0}
{"code": "def test_load_config_env_and_defaults(monkeypatch, tmpdir):\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    monkeypatch.setenv(\"AUTHNZERVER_AUTHDB\", \"sqlite:///test/db/path\")\n    monkeypatch.setenv(\"AUTHNZERVER_DEBUGMODE\", \"0\")\n    monkeypatch.setenv(\"AUTHNZERVER_PERMISSIONS\", permissions_json)\n    monkeypatch.setenv(\"AUTHNZERVER_SECRET\", \"this is a direct text secret\")\n    monkeypatch.setenv(\"AUTHNZERVER_PIISALT\", \"this is a direct text salt\")\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=generated_options.envfile\n    )\n\n    assert loaded_config.authdb == \"sqlite:///test/db/path\"\n    assert loaded_config.basedir == os.getcwd()\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"127.0.0.1\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 13431\n    assert loaded_config.secret == \"this is a direct text secret\"\n    assert loaded_config.piisalt == \"this is a direct text salt\"\n\n    assert loaded_config.sessionexpiry == 30\n    assert loaded_config.workers == 4\n\n    # email setup check\n    assert loaded_config.emailserver == \"localhost\"\n    assert loaded_config.emailport == 25\n    assert loaded_config.emailuser == getpass.getuser()\n    assert loaded_config.emailpass == \"\"", "od": 0}
{"code": "def test_load_config_options_and_defaults(monkeypatch, tmpdir):\n\n    # generate the secret file\n    secret_file = generate_secret_file(tmpdir)\n\n    # generate the salt file\n    salt_file = generate_salt_file(tmpdir)\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    # generate the tornado options object\n    generated_options = generate_options()\n\n    generated_options.authdb = \"sqlite:///path/to/auth-db-opt\"\n    generated_options.listen = \"192.168.1.1\"\n    generated_options.port = 4002\n    generated_options.permissions = permissions_json\n    generated_options.secret = secret_file\n    generated_options.piisalt = salt_file\n\n    # load the config items now\n    loaded_config = confload.load_config(\n        confvars.CONF, generated_options, envfile=None\n    )\n\n    assert loaded_config.authdb == \"sqlite:///path/to/auth-db-opt\"\n    assert loaded_config.basedir == os.getcwd()\n    assert loaded_config.debugmode == 0\n    assert loaded_config.listen == \"192.168.1.1\"\n\n    # check if the permission model was loaded correctly\n    loaded_permissions = load_permissions_json(loaded_config.permissions)\n    assert isinstance(loaded_permissions, dict)\n    assert loaded_permissions[\"roles\"] == {\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    }\n\n    assert loaded_config.port == 4002\n    assert loaded_config.secret == \"super-secret-secret\"\n    assert loaded_config.piisalt == \"super-secret-salt\"\n\n    assert loaded_config.sessionexpiry == 30\n    assert loaded_config.workers == 4\n\n    # email setup check\n    assert loaded_config.emailserver == \"localhost\"\n    assert loaded_config.emailport == 25\n    assert loaded_config.emailuser == getpass.getuser()\n    assert loaded_config.emailpass == \"\"", "od": 0}
{"code": "def test_item_from_file(tmpdir):\n    \"\"\"\n    This tests if the config can be loaded from env + a file.\n\n    \"\"\"\n\n    # generate the secret files\n    secret_file = generate_secret_file(tmpdir)\n\n    # generate the permissions JSON\n    permissions_json = generate_permissions_json(tmpdir)\n\n    #\n    # 1. test we can load the secret file\n    #\n    loaded_item = confload.item_from_file(secret_file, \"string\")\n    assert loaded_item == \"super-secret-secret\"\n\n    #\n    # 2. test we can load an entire JSON\n    #\n    loaded_item = confload.item_from_file(permissions_json, \"json\")\n    assert isinstance(loaded_item, dict)\n    assert loaded_item[\"roles\"] == [\n        \"superuser\",\n        \"staff\",\n        \"authenticated\",\n        \"anonymous\",\n        \"locked\",\n    ]\n\n    #\n    # 3. test we can load a specific item inside a JSON\n    #\n    loaded_item = confload.item_from_file(\n        permissions_json,\n        (\n            \"json\",\n            \"role_policy.staff.allowed_actions_for_other.unlisted._arr_2\",\n        ),\n    )\n    assert loaded_item == \"delete\"", "od": 0}
{"code": "def test_item_from_url(monkeypatch, requests_mock):\n    \"\"\"\n    This tests if the config can be loaded from env + remote URLs.\n\n    \"\"\"\n\n    # set the env\n    monkeypatch.setenv(\"GCP_APIKEY\", \"super-secret-token\")\n    monkeypatch.setenv(\"GCP_PROJECTID\", \"abcproj\")\n\n    #\n    # 0. mock the URL bits\n    #\n\n    # GET URL\n    # NOTE: the z-access here should technically be z:access\n    # but request-mock=1.9.1 quotes the ':' character differently\n    # from actual requests, so the URL doesn't match and the assert fails\n    # see: https://github.com/jamielennox/requests-mock/pull/167\n    get_url = (\n        \"https://secretmanager.googleapis.com/v1/\"\n        \"projects/abcproj/secrets/abc/versions/z-access\"\n    )\n    get_expect_headers = {\n        \"Authorization\": \"Bearer super-secret-token\",\n        \"Content-Type\": \"application/json\",\n        \"x-goog-user-project\": \"abcproj\",\n    }\n    get_response = \"this-should-be-base64-but-whatever\"\n\n    requests_mock.get(\n        get_url, request_headers=get_expect_headers, text=get_response\n    )\n\n    #\n    # 1. test requests itself works fine with the mocked bits\n    #\n\n    resp = requests.get(\n        get_url,\n        headers=get_expect_headers,\n    )\n    assert resp.text == get_response\n    resp.close()\n\n    #\n    # 2. now test if the item_from_url function works fine with a string\n    #\n    send_headers = {\n        \"Authorization\": \"Bearer [[GCP_APIKEY]]\",\n        \"Content-Type\": \"application/json\",\n        \"x-goog-user-project\": \"[[GCP_PROJECTID]]\",\n    }\n\n    url_spec = (\n        \"http\",\n        {\n            \"method\": \"get\",\n            \"headers\": send_headers,\n            \"data\": None,\n            \"timeout\": 5.0,\n        },\n        \"string\",\n    )\n\n    loaded_item = confload.item_from_url(\n        get_url,\n        url_spec,\n        os.environ,\n    )\n\n    assert loaded_item == get_response\n\n    #\n    # 3. now test if the item_from_url function works fine with a JSON item\n    #\n\n    get_url = (\n        \"https://secretmanager.googleapis.com/v1/\"\n        \"projects/abcproj/secrets/abc/versions/z-access\"\n    )\n    get_expect_headers = {\n        \"Authorization\": \"Bearer super-secret-token\",\n        \"Content-Type\": \"application/json\",\n        \"x-goog-user-project\": \"abcproj\",\n    }\n    get_response = {\n        \"secret\": \"very-yes\",\n        \"testbit\": {\"available\": [\"maybe\", \"yes\", \"no\"]},\n    }\n\n    requests_mock.get(\n        get_url, request_headers=get_expect_headers, json=get_response\n    )\n    send_headers = {\n        \"Authorization\": \"Bearer [[GCP_APIKEY]]\",\n        \"Content-Type\": \"application/json\",\n        \"x-goog-user-project\": \"[[GCP_PROJECTID]]\",\n    }\n\n    url_spec = (\n        \"http\",\n        {\n            \"method\": \"get\",\n            \"headers\": send_headers,\n            \"data\": None,\n            \"timeout\": 5.0,\n        },\n        \"json\",\n        \"testbit.available._arr_2\",\n    )\n\n    loaded_item = confload.item_from_url(\n        get_url,\n        url_spec,\n        os.environ,\n    )\n\n    assert loaded_item == \"no\"", "od": 0}
{"code": "def test_get_conf_item_postprocess(monkeypatch, requests_mock, tmpdir):\n    \"\"\"Tests if the item can be loaded and post-processed by a custom function.\"\"\"\n\n    #\n    # 0. mock the URL bits\n    #\n\n    # GET URL\n    get_url = (\n        \"https://secretmanager.googleapis.com/v1/\"\n        \"projects/abcproj/secrets/abc/versions/z-access\"\n    )\n    get_expect_headers = {\n        \"Authorization\": \"Bearer super-secret-token\",\n        \"Content-Type\": \"application/json\",\n        \"x-goog-user-project\": \"abcproj\",\n    }\n    get_response = {\n        \"payload\": {\n            \"data\": (base64.b64encode(b\"hello-world-im-secret\")).decode(\n                \"utf-8\"\n            )\n        }\n    }\n\n    requests_mock.get(\n        get_url, request_headers=get_expect_headers, json=get_response\n    )\n\n    #\n    # 1. write the postproc function to the file\n    #\n    function_file = os.path.abspath(str(tmpdir.join(\"proc_module.py\")))\n\n    with open(function_file, \"w\") as outfd:\n        outfd.write(\n            \"\"\"\nimport base64\n\ndef custom_b64decode(input):\n    return base64.b64decode(input.encode('utf-8')).decode('utf-8')\n\"\"\"\n        )\n\n    #\n    # 2. set up the env and config dict\n    #\n\n    monkeypatch.setenv(\"GCP_SECMAN_URL\", get_url)\n    monkeypatch.setenv(\"GCP_AUTH_TOKEN\", \"super-secret-token\")\n\n    readable_from_file = (\n        \"http\",\n        {\n            \"method\": \"get\",\n            \"headers\": {\n                \"Authorization\": \"Bearer [[GCP_AUTH_TOKEN]]\",\n                \"Content-Type\": \"application/json\",\n                \"x-goog-user-project\": \"abcproj\",\n            },\n            \"data\": None,\n            \"timeout\": 5.0,\n        },\n        \"json\",\n        \"payload.data\",\n    )\n\n    # set up the config_dict\n    conf_dict = {\n        \"secret\": {\n            \"env\": \"GCP_SECMAN_URL\",\n            \"cmdline\": \"secret\",\n            \"type\": str,\n            \"default\": None,\n            \"help\": (\n                \"The shared secret key used to secure \"\n                \"communications between authnzerver and \"\n                \"any frontend servers.\"\n            ),\n            \"readable_from_file\": readable_from_file,\n            \"postprocess_value\": \"%s::custom_b64decode\" % function_file,\n        }\n    }\n\n    #\n    # 4. try the process\n    #\n    conf_item = confload.get_conf_item(\n        conf_dict[\"secret\"][\"env\"],\n        os.environ,\n        None,\n        options_key=None,\n        vartype=conf_dict[\"secret\"][\"type\"],\n        default=conf_dict[\"secret\"][\"default\"],\n        readable_from_file=conf_dict[\"secret\"][\"readable_from_file\"],\n        postprocess_value=conf_dict[\"secret\"][\"postprocess_value\"],\n    )\n\n    assert conf_item == \"hello-world-im-secret\"", "od": 0}
{"code": "def test_manual_context():\n    Breathe.add_commands(\n        CommandContext(\"test\"),\n        {\"pizza\": DoNothing(),\n        \"curry\": DoNothing(),\n        }\n    )\n    # Fails because the rule isn't enabled yet\n    with pytest.raises(MimicFailure):\n        engine.mimic([\"pizza\", \"pizza\"])\n    engine.mimic([\"enable\", \"test\"])\n    engine.mimic([\"pizza\", \"curry\", \"pizza\"])", "od": 0}
{"code": "def test_manual_context_noccr():\n    Breathe.add_commands(\n        CommandContext(\"test\") | AppContext(\"italy\"),\n        {\"spaghetti\": DoNothing()},\n        ccr=False\n    )\n    engine.mimic([\"enable\", \"test\"])\n    engine.mimic([\"spaghetti\"])\n    engine.mimic([\"disable\", \"test\"])\n    with pytest.raises(MimicFailure):\n        engine.mimic([\"spaghetti\"])\n        engine.mimic([\"pizza\", \"curry\"])\n    engine.mimic([\"spaghetti\"], executable=\"italy\")", "od": 0}
{"code": "def test_negated_context():\n    Breathe.add_commands(\n        ~(CommandContext(\"america\") | AppContext(\"england\")),\n        {\"steak\": DoNothing(),\n        }\n    )\n    engine.mimic([\"steak\"])\n    with pytest.raises(MimicFailure):\n        engine.mimic([\"steak\"], executable=\"england\")\n    engine.mimic([\"enable\", \"america\"])\n    with pytest.raises(MimicFailure):\n        engine.mimic([\"steak\"])", "od": 0}
{"code": "def test_clear():\n    Breathe.clear()", "od": 0}
{"code": "def test_loading_failure():\n    test_clear()\n    with open(file_path, \"w\") as f:\n        f.write(\"\"\"\nfrom breathe import Breathe\nfrom ..testutils import DoNothing\n\nBreathe.add_commands(,,,\n    None,\n    {\n        \"apple\": DoNothing(),\n    }\n)\n\"\"\"\n        )\n    modules = {\n        \"tests\": {\n            \"my_grammar\": [\"fruit\"],\n        }\n    }\n    Breathe.load_modules(modules)\n    assert len(Breathe.modules) == 1\n    assert len(Breathe.core_commands) == 0", "od": 1}
{"code": "def test_loading():\n    with open(file_path, \"w\") as f:\n        f.write(\"\"\"\nfrom breathe import Breathe\nfrom ..testutils import DoNothing\n\nBreathe.add_commands(\n    None,\n    {\n        \"apple\": DoNothing(),\n    }\n)\n\"\"\"\n        )\n    engine.mimic(\"rebuild everything test\")\n    engine.mimic(\"apple\")", "od": 1}
{"code": "def test_reloading():\n    with open(file_path, \"w\") as f:\n        f.write(\"\"\"\nfrom breathe import Breathe\nfrom ..testutils import DoNothing\n\nBreathe.add_commands(\n    None,\n    {\n        \"parsnip\": DoNothing(),\n    }\n)\n\"\"\"\n        )\n    # I have no idea why this is necessary, it's a total hack\n    if PY2:\n        os.remove(file_path + \"c\")\n    engine.mimic(\"rebuild everything test\")\n    with pytest.raises(MimicFailure):\n        engine.mimic(\"apple\")\n    engine.mimic(\"parsnip\")\n    assert len(Breathe.modules) == 1", "od": 1}
{"code": "def test_clear():\n    Breathe.clear()\n    Breathe.modules = []", "od": 0}
{"code": "def test_global_extras():\n    Breathe.add_global_extras(Dictation(\"text\"))\n    assert len(Breathe.global_extras) == 1\n    assert \"text\" in Breathe.global_extras\n    Breathe.add_global_extras([Choice(\"abc\", {\"def\": \"ghi\"})])\n    # Check that this is overridden\n    Breathe.add_global_extras(IntegerRef(\"n\", 1, 2, 1))", "od": 0}
{"code": "def test_core_commands():\n    Breathe.add_commands(\n        None,\n        {\n            \"test one\": DoNothing(),\n            \"test two\": DoNothing(),\n            \"test three\": DoNothing(),\n            \"banana [<n>]\": DoNothing() * Repeat(\"n\"),\n        },\n        [IntegerRef(\"n\", 1, 10, 1)],\n    )\n    engine.mimic([\"test\", \"three\", \"test\", \"two\", \"banana\", \"five\"])", "od": 1}
{"code": "def test_context_commands():\n    Breathe.add_commands(\n        AppContext(\"notepad\"),\n        {\"test [<num>]\": lambda num: DoNothing().execute()},\n        [Choice(\"num\", {\"four\": \"4\", \"five\": \"5\", \"six\": \"6\"})],\n        {\"num\": \"\"},\n    )\n    with pytest.raises(MimicFailure):\n        engine.mimic([\"test\", \"three\", \"test\", \"four\"])\n    engine.mimic([\"test\", \"three\", \"test\", \"four\"], executable=\"notepad\")", "od": 1}
{"code": "def test_noccr_commands():\n    Breathe.add_commands(\n        AppContext(\"firefox\"),\n        {\"dictation <text>\": DoNothing(), \"testing static\": DoNothing()},\n        ccr=False,\n    )\n    engine.mimic([\"testing\", \"static\"], executable=\"firefox\")\n    with pytest.raises(MimicFailure):\n        engine.mimic([\"dictation\", \"TESTING\"])\n        engine.mimic([\"testing\", \"static\", \"testing\", \"static\"], executable=\"firefox\")\n    engine.mimic([\"dictation\", \"TESTING\"], executable=\"firefox\")", "od": 1}
{"code": "def test_grammar_numbers():\n    engine.mimic([\"test\", \"three\"])\n    # Ensure that we are not adding more grammars than necessary\n    assert len(engine.grammars) == 4", "od": 0}
{"code": "def test_nomapping_commands():\n    Breathe.add_commands(AppContext(\"code.exe\"), {})", "od": 0}
{"code": "def test_invalid():\n    Breathe.add_commands(\n        AppContext(\"code.exe\"),\n        {\n            \"test that <nonexistent_extra>\": DoNothing(),\n            1: DoNothing(),\n        },\n    )\n    assert len(Breathe.contexts) == 1\n    assert len(Breathe.context_commands) == 1", "od": 1}
{"code": "def test_kaldi_weight_passthrough():\n    Breathe.add_commands(\n        None,\n        {\n            \"test weight\": DoNothing(),\n        },\n        weight=10.0,\n    )\n    assert Breathe.core_commands[-1].weight == 10.0", "od": 0}
{"code": "def test_clear():\n    Breathe.clear()", "od": 0}
{"code": "def test_top_level_command():\n    Breathe.add_commands(None, {\"orange\": DoNothing(), \"grapefruit\": DoNothing()})\n    Breathe.add_commands(\n        AppContext(\"notepad\"), {\"lemon\": DoNothing(), \"banana\": DoNothing()}\n    )\n    Breathe.add_commands(\n        AppContext(\"notepad\"),\n        {\n            \"fruit from <sequence1> and [<sequence2>] [<n>]\": DoNothing()\n            + Exec(\"sequence1\")\n            + DoNothing()\n            + Exec(\"sequence2\")* Repeat(\"n\")\n        },\n        extras=[CommandsRef(\"sequence1\"), CommandsRef(\"sequence2\", 2), IntegerRef(\"n\", 1, 10, 1)],\n        top_level=True,\n    )", "od": 0}
{"code": "def test_top_level_command2():\n    Breathe.add_commands(\n        AppContext(title=\"chrome\"), {\"pear\": DoNothing(), \"grape\": DoNothing()}\n    )", "od": 0}
{"code": "def test_global_top_level():\n    Breathe.add_commands(\n        None,\n        {\n            \"<sequence1> are preferable to <sequence2>\": DoNothing()\n            + Exec(\"sequence1\")\n            + DoNothing()\n            + Exec(\"sequence2\")\n        },\n        extras=[CommandsRef(\"sequence1\"), CommandsRef(\"sequence2\", 3)],\n        top_level=True,\n    )", "od": 0}
{"code": "def test_recognition():\n    engine.mimic(\"lemon\", executable=\"notepad\")\n    engine.mimic(\"fruit from lemon banana orange and five\", executable=\"notepad\")\n\n    engine.mimic(\n        \"fruit from pear banana orange and grapefruit\",\n        executable=\"notepad\",\n        title=\"chrome\",\n    )\n    with pytest.raises(MimicFailure):\n        engine.mimic(\n            \"fruit from pear banana orange and grapefruit\", executable=\"notepad\"\n        )\n\n    engine.mimic(\"orange grapefruit are preferable to grapefruit\")\n    engine.mimic(\"orange grapefruit are preferable to lemon banana\", executable=\"notepad\")\n    assert len(Breathe.top_level_commands) == 2", "od": 0}
{"code": "def test_top_level_command_failure():\n    Breathe.add_commands(\n        AppContext(\"china\"),\n        {\n            \"not marked top level <sequence1> and <sequence2> [<n>]\": DoNothing()\n            + Exec(\"sequence1\")\n            + DoNothing()\n            + Exec(\"sequence2\")* Repeat(\"n\")\n        },\n        extras=[CommandsRef(\"sequence1\"), CommandsRef(\"sequence2\", 2), IntegerRef(\"n\", 1, 10, 1)],\n        top_level=False,\n    )\n    assert len(Breathe.top_level_commands) == 2", "od": 0}
{"code": "def test_clear():\n    Breathe.clear()", "od": 0}
{"code": "def test_base_url(self):\n\t\tself.assertEqual(model.factory.base_url, 'http://data.getty.edu/provenance/')", "od": 0}
{"code": "def test_base_dir(self):\n\t\tself.assertEqual(model.factory.base_dir, 'tests/provenance_base_dir')", "od": 0}
{"code": "def test_default_lang(self):\n\t\tself.assertEqual(model.factory.default_lang, 'en')", "od": 0}
{"code": "def test_set_debug_stream(self):\n\t\tstrm = open('err_output', 'w')\n\t\tmodel.factory.set_debug_stream(strm)\n\t\tself.assertEqual(model.factory.log_stream, strm)", "od": 0}
{"code": "def test_set_debug(self):\n\t\tmodel.factory.set_debug('error_on_warning')\n\t\tself.assertEqual(model.factory.debug_level, 'error_on_warning')\n\t\tself.assertRaises(model.ConfigurationError, model.factory.set_debug, 'xxx')\n\t\tself.assertRaises(model.MetadataError, model.factory.maybe_warn, \"test\")", "od": 0}
{"code": "def test_load_context(self):\n\t\tself.assertRaises(model.ConfigurationError, model.factory.load_context, \n\t\t\t\"foo\", {\"foo\":\"does_not_exist.txt\"})\n\t\tmodel.factory.load_context(\"foo\", {\"foo\":\"tests/test_context.json\"})\n\t\tself.assertEqual(model.factory.context_json, {\"@context\":{\"id\":\"@id\"}})\n\t\tself.assertRaises(model.ConfigurationError, model.factory.load_context, \"\", {})", "od": 0}
{"code": "def test_pickle(self):\n\t\tmodel.factory.log_stream = sys.stderr\n\t\tsrlz = pickle.dumps(model.factory)\n\t\tnewfac = pickle.loads(srlz)\n\t\tself.assertTrue(model.factory.log_stream is newfac.log_stream)", "od": 0}
{"code": "def test_broken_unicode(self):\n\t\tmodel.factory.debug_level = \"error_on_warning\"\n\t\ttry:\n\t\t\tbadval = b\"\\xFF\\xFE\\x02\"\n\t\texcept:\n\t\t\tbadval = \"\\xFF\\xFE\\x02\"\n\t\tbadjs = {\"_label\": badval}\n\t\tself.assertRaises(model.MetadataError, model.factory._buildString,\n\t\t\tjs=badjs)", "od": 0}
{"code": "def test_toJSON(self):\n\t\t# model.factory.context_uri = 'http://lod.getty.edu/context.json'\n\t\texpect = OrderedDict([\n\t\t\t('@context', model.factory.context_uri),\n\t\t\t('id', u'http://lod.example.org/museum/InformationObject/collection'), \n\t\t\t('type', 'InformationObject'), ('_label', 'Test Object')])\n\t\toutj = model.factory.toJSON(self.collection)\n\t\tself.assertEqual(expect, outj)", "od": 1}
{"code": "def test_toJSON_fast(self):\n\t\tmodel.factory.json_serializer = \"fast\"\n\t\texpect = {'@context': model.factory.context_uri, \n\t\t\t'id': 'http://lod.example.org/museum/InformationObject/collection', \n\t\t\t'type': 'InformationObject', \n\t\t\t'_label': 'Test Object'}\n\t\toutj = model.factory.toJSON(self.collection)\n\t\tself.assertEqual(expect, outj)\n\t\tmodel.factory.json_serializer = \"normal\"", "od": 1}
{"code": "def test_toJSON_normal(self):\n\t\texpect = OrderedDict([(u'@context', model.factory.context_uri), \n\t\t\t(u'@id', u'http://lod.example.org/museum/Person/1'), (u'@type', u'crm:E21_Person'),\n\t\t\t('rdfs:label', 'Test Person')])\n\t\tmodel.factory.full_names = True\n\t\tp = model.Person(\"1\")\n\t\tp._label = \"Test Person\"\n\t\toutj = model.factory.toJSON(p)\n\t\tself.assertEqual(expect, outj)\n\t\t# reset\n\t\tmodel.factory.full_names = False", "od": 0}
{"code": "def test_toString(self):\n\t\texpect = u'{\"@context\":\"'+model.factory.context_uri+'\",\"id\":\"http://lod.example.org/museum/InformationObject/collection\",\"type\":\"InformationObject\",\"_label\":\"Test Object\"}'\n\t\touts = model.factory.toString(self.collection)\n\t\tself.assertEqual(expect, outs)", "od": 1}
{"code": "def test_toString_fast(self):\n\t\t# Should only be trusted in python 3\n\t\tif sys.version_info.major >= 3 and sys.version_info.minor >= 6:\n\t\t\texpect = u'{\"@context\":\"'+model.factory.context_uri+'\",\"id\":\"http://lod.example.org/museum/InformationObject/collection\",\"type\":\"InformationObject\",\"_label\":\"Test Object\"}'\n\t\t\tmodel.factory.json_serializer = \"fast\"\t\t\n\t\t\touts = model.factory.toString(self.collection)\n\t\t\tmodel.factory.json_serializer = \"normal\"\n\t\t\tself.assertEqual(expect, outs)\n\t\telse:\n\t\t\tprint(\"Skipping toString_fast test in Python 2.x\")", "od": 1}
{"code": "def test_toFile(self):\n\t\tself.assertRaises(model.ConfigurationError, model.factory.toFile, self.collection)\n\t\t# Test auto filename determination\n\t\tmodel.factory.base_dir = 'tests'\n\t\tmodel.factory.toFile(self.collection)\n\t\tself.assertTrue(os.path.isfile('tests/InformationObject/collection.json'))\n\t\t# Test explicit filename setting\n\t\tmodel.factory.toFile(self.collection, filename='tests/fishbat.bar')\n\t\tself.assertTrue(os.path.isfile('tests/fishbat.bar'))\n\t\t# Tidy up\n\t\tshutil.rmtree('tests/InformationObject')", "od": 0}
{"code": "def test_breadth(self):\n\t\tx = model.TransferOfCustody()\n\t\te = model.Activity()\n\t\tfr = model.Group()\n\t\tto = model.Group()\n\t\tw = model.HumanMadeObject()\n\t\tfr._label = \"From\"\n\t\tto._label = \"To\"\n\t\tx.transferred_custody_of = w\n\t\tx.transferred_custody_from = fr\n\t\tx.transferred_custody_to = to\n\t\te.used_specific_object = w\n\t\te.carried_out_by = to\n\t\tw.current_owner = fr\n\t\tx.specific_purpose = e\n\t\tjs = model.factory.toJSON(x)\n\t\t# Okay ... if we're breadth first, then custody_from is a resource\n\t\t# And now it's the first in the list\n\t\tself.assertTrue(isinstance(js['transferred_custody_from'][0], OrderedDict))", "od": 1}
{"code": "def test_string_list(self):\n\t\tx = model.Activity()\n\t\tx._label = [\"Label 1\", \"Label 2\"]\n\t\tjs = model.factory.toJSON(x)\n\t\tself.assertTrue(js['_label'] == x._label)", "od": 1}
{"code": "def test_external(self):\n\t\tx = model.ExternalResource(ident=\"1\")\n\t\tmodel.factory.elasticsearch_compatible = 1\n\t\tjs = x._toJSON(done=None)\n\t\tself.assertTrue(type(js) == dict)\n\t\tmodel.factory.elasticsearch_compatible = 0\n\t\tjs = x._toJSON(done=None)\n\t\t# testing unicode in 2, str in 3 :(\n\t\tself.assertTrue(type(js) != dict)", "od": 0}
{"code": "def test_recursion(self):\n\t\tx = model.Activity()\n\t\tx.part = x\n\t\tjs = model.factory.toJSON(x)\n\t\t# If our recursion checks have regressed, this will barf right here\n\t\tself.assertTrue(1)", "od": 1}
{"code": "def test_pipe_scoped(self):\n\t\tx = model.Activity()\n\t\ty = model.Activity()\n\t\tx.part = y\n\t\tmodel.factory.pipe_scoped_contexts = True\n\t\tjs = model.factory.toJSON(x)\n\t\tself.assertTrue('part|crm:P9_consists_of' in js)\n\t\tmodel.factory.pipe_scoped_contexts = False\n\t\tjs = model.factory.toJSON(x)\t\t\n\t\tself.assertTrue('part|crm:P9_consists_of' not in js)\t\t\n\t\tself.assertTrue('part' in js)", "od": 1}
{"code": "def test_collapse_json(self):\n\t\tmodel.factory.auto_id_type = \"uuid\"\n\t\tmodel.factory.base_url = \"http://lod.example.org/museum/\"\n\t\tmodel.factory.context_uri = \"https://linked.art/ns/v1/linked-art.json\"\n\t\tp = model.Person()\n\t\tp.classified_as = model.Type(ident=\"http://example.org/Type\", label=\"Test\")\n\t\tres1 = model.factory.toString(p, compact=False, collapse=60) # all new lines\n\t\tres2 = model.factory.toString(p, compact=False, collapse=120) # compact list of type\n\t\tself.assertEqual(len(res1.splitlines()), 12)\n\t\tself.assertEqual(len(res2.splitlines()), 6)", "od": 1}
{"code": "def test_production_mode(self):\n\n\t\t# model.factory.production_mode()\n\t\t# Can't unset the cached hierarchy\n\t\t# and it causes the test for the hierarchy to fail\n\t\tmodel.factory.validate_profile = False\n\t\tmodel.factory.validate_properties = False\n\t\tmodel.factory.validate_range = False\n\t\tmodel.factory.validate_multiplicity = False\n\n\t\tp = model.Person()\n\t\tp.identified_by = model.Name(value=\"abc\")\n\t\tp.part = model.HumanMadeObject()\n\t\tjs = model.factory.toJSON(p)\n\n\t\tmodel.factory.production_mode(state=False)", "od": 1}
{"code": "def test_ordering(self):\n\t\tp = model.Person(label=\"Person\")\n\t\tp.classified_as = model.Type(ident=\"type-uri\")\n\t\tp.referred_to_by = model.LinguisticObject(content=\"text\")\n\t\tp.dimension = model.Dimension(value=1)\n\n\t\toutstr = model.factory.toString(p)\n\t\tlbl = outstr.index(\"_label\")\n\t\tclsf = outstr.index(\"classified_as\")\n\t\tr2b = outstr.index(\"referred_to_by\")\n\t\tdim = outstr.index(\"dimension\")\n\t\tself.assertTrue(lbl < clsf)\n\t\tself.assertTrue(clsf < r2b)\n\t\tself.assertTrue(r2b < dim)", "od": 1}
{"code": "def test_process_tsv(self):\n\t\texpect = {u'subs': [u'E84_Information_Carrier'], u'label': u'Human-Made Object', u'className': u'HumanMadeObject', \n\t\tu'subOf': u'E19_Physical_Object|E24_Physical_Human-Made_Thing', u'props': [], u'class': None, u'okay': u'1'}\n\t\tfn = 'cromulent/data/crm_vocab.tsv'\n\t\tvocabData = model.process_tsv(fn)\n\t\tman_made = vocabData['E22_Human-Made_Object']\n\t\tdel man_made['desc']  # too long and volatile\n\t\t# check subs specifically - could be coming from an extension\n\t\tif man_made['subs'] != expect['subs']:\n\t\t\tdel man_made['subs']\n\t\t\tdel expect['subs']\n\t\tself.assertEqual(expect, man_made)", "od": 0}
{"code": "def test_build_classes(self):\n\t\ttsv = \"\\nClassName_full\\tclass\\tClassName_py\\tClass Label\\tClass Description\\t\\t1\\t\\n\"\n\t\tfh = open('tests/temp.tsv', 'w')\n\t\tfh.write(tsv)\n\t\tfh.close()\n\t\tmodel.build_classes(\"tests/temp.tsv\", \"ClassName_full\")\n\t\tfrom cromulent.model import ClassName_py\n\t\tself.assertEqual('Class Description', ClassName_py.__doc__)\n\t\tos.remove('tests/temp.tsv')", "od": 0}
{"code": "def test_build_class(self):\n\t\ttsv = \"\\nClassName_full\\tclass\\tClassName_py2\\tClass Label\\tClass Description\\t\\t1\\t\\n\"\n\t\tfh = open('tests/temp.tsv', 'w')\n\t\tfh.write(tsv)\n\t\tfh.close()\n\t\tvocabData = model.process_tsv('tests/temp.tsv')\n\t\tmodel.build_class('ClassName_full', model.BaseResource, vocabData)\n\t\tfrom cromulent.model import ClassName_py2\n\t\tself.assertEqual('Class Description', ClassName_py2.__doc__)\n\t\tos.remove('tests/temp.tsv')", "od": 0}
{"code": "def test_bad_autoid(self):\n\t\tmodel.factory.auto_assign_id = True\n\t\tmodel.factory.auto_id_type = \"broken\"\n\t\tself.assertRaises(model.ConfigurationError, model.factory.generate_id,\n\t\t\t\"irrelevant\")", "od": 0}
{"code": "def test_int(self):\n\t\tmodel.factory.auto_assign_id = True\n\t\tmodel.factory.auto_id_type = \"int\"\n\t\tp = model.Person()\n\t\tp2 = model.Activity()\n\t\tself.assertEqual(int(p.id[-1]), int(p2.id[-1])-1)", "od": 0}
{"code": "def test_int_per_type(self):\n\t\tmodel.factory.auto_assign_id = True\n\t\tmodel.factory.auto_id_type = \"int-per-type\"\n\t\tp = model.Person()\n\t\tp2 = model.Person()\n\t\tself.assertEqual(int(p.id[-1]), int(p2.id[-1])-1)\n\t\tp3 = model.Activity()\n\t\tself.assertEqual(int(p.id[-1]), int(p3.id[-1]))", "od": 0}
{"code": "def test_int_per_segment(self):\n\t\tmodel.factory.auto_assign_id = True\n\t\tmodel.factory._auto_id_segments = {}\n\t\tmodel.factory.auto_id_type = \"int-per-segment\"\n\t\tmodel.Activity._uri_segment = model.Person._uri_segment\n\t\tp = model.Person()\n\t\tp2 = model.Activity()\n\t\tself.assertEqual(int(p.id[-1]), int(p2.id[-1])-1)\t\t\n\t\tp3 = model.TimeSpan()\n\t\tself.assertEqual(int(p.id[-1]), int(p3.id[-1]))", "od": 0}
{"code": "def test_uuid(self):\n\t\tmodel.factory.auto_assign_id = True\n\t\tmodel.factory.auto_id_type = \"uuid\"\n\t\tp = model.Person()\n\t\tself.assertTrue(p.id.startswith('urn:uuid:'))", "od": 0}
{"code": "def test_prefixes(self):\n\n\t\tmodel.factory.prefixes = {'fish':'http://example.org/ns/'}\n\t\tp3 = model.Person('fish:3')\n\t\tself.assertEqual(p3.id, 'fish:3')\n\t\tself.assertEqual(p3._full_id, 'http://example.org/ns/3')\n\n\t\tmodel.factory.prefixes = {}\n\t\tp4 = model.Person('fish:4')\n\t\tself.assertTrue(p4.id.startswith(model.factory.base_url))", "od": 0}
{"code": "def test_other_uris(self):\n\t\tp1 = model.Person(ident=\"tag:some-info-about-person\")\n\t\tself.assertEqual(p1.id, \"tag:some-info-about-person\")\n\t\tp2 = model.Person(ident=\"info:ulan/500012345\")\n\t\tself.assertEqual(p2.id, \"info:ulan/500012345\")\n\t\tp3 = model.Person(ident=\"some:random:thing:with:colons\")\n\t\tself.assertFalse(p3.id == \"some:random:thing:with:colons\")", "od": 0}
{"code": "def test_no_ident(self):\n\n\t\tmodel.factory.auto_assign_id = True\n\t\tp1 = model.Person()\t# auto assigned\t \n\t\tp2 = model.Person(ident=None) # auto assigned\n\t\tp3 = model.Person(ident=\"\") # bnode explicitly\n\n\t\tself.assertTrue(p1.id.startswith('http'))\n\t\tself.assertTrue(p2.id.startswith('http'))\n\t\tself.assertEqual(p3.id, '')\n\n\t\tmodel.factory.auto_assign_id = False\n\t\tp4 = model.Person() # bnode is default\n\t\tp5 = model.Person(ident=None) # bnode is default\n\t\tp6 = model.Person(ident=\"\") # bnode explicitly\n\n\t\tself.assertEqual(p4.id, '')\n\t\tself.assertEqual(p5.id, '')\n\t\tself.assertEqual(p6.id, '')", "od": 1}
{"code": "def test_init(self):\n\t\tself.assertEqual(self.artist.id, 'http://lod.example.org/museum/Person/00001')\n\t\tself.assertEqual(self.artist._type, 'crm:E21_Person')\n\t\tself.assertEqual(self.artist.type, 'Person')\n\t\tself.assertEqual(self.artist._label, 'Jane Doe')\n\t\tself.assertFalse(hasattr(self.artist, 'value'))\n\t\tself.assertFalse(hasattr(self.artist, 'has_type'))", "od": 1}
{"code": "def test_check_prop(self):\n\t\tdesc = self.artist._check_prop('_label', 'Jane Doe\\'s Bio')\n\t\tself.assertEqual(desc, 1)\n\t\tparent = self.artist._check_prop('parent_of', self.son)\n\t\tself.assertEqual(parent, 2)", "od": 0}
{"code": "def test_list_all_props(self):\n\t\tprops = self.artist.list_all_props()\n\t\tprops.sort()\n\t\tself.assertEqual(props[-1], 'witnessed')\n\t\tself.assertTrue('_label' in props)\n\t\tself.assertTrue('identified_by' in props)", "od": 0}
{"code": "def test_list_my_props(self):\n\t\tp1 = model.Person()\n\t\tp1.classified_as = model.Type()\n\t\tprops = p1.list_my_props()\n\t\tself.assertEqual(set(props), set(['classified_as', 'id']))\n\t\tprops = p1.list_my_props(filter=model.Type)\n\t\tself.assertEqual(props, ['classified_as'])", "od": 1}
{"code": "def test_allows_multiple(self):\n\t\tp = model.Person()\n\t\tself.assertTrue(p.allows_multiple('classified_as'))\n\t\tself.assertFalse(p.allows_multiple('born'))\n\t\tself.assertRaises(model.DataError, p.allows_multiple, 'fish')", "od": 1}
{"code": "def test_check_reference(self):\n\t\tself.assertTrue(self.artist._check_reference('http'))\n\t\tself.assertFalse(self.artist._check_reference('xxx'))\n\t\tself.assertTrue(self.artist._check_reference({'id': 'xxx'}))\n\t\tself.assertFalse(self.artist._check_reference({'xxx': 'yyy'}))\n\t\tself.assertTrue(self.artist._check_reference(self.son))\n\t\tself.assertTrue(self.artist._check_reference(['http']))\n\t\tself.assertFalse(self.artist._check_reference(['xxx', 'yyy']))\n\t\tself.assertTrue(self.artist._check_reference(model.Person))", "od": 0}
{"code": "def test_multiplicity(self):\n\t\tmodel.factory.process_multiplicity = True\n\t\twho = model.Actor()\n\t\tmmo = model.HumanMadeObject()\n\t\tprod = model.Production()\n\t\tmmo.produced_by = prod\n\t\twho.current_owner_of = mmo\n\t\tmmo.current_owner = who\n\t\tself.assertEqual(mmo.current_owner, [who])\n\t\tself.assertEqual(who.current_owner_of, [mmo])\t\t\n\t\tself.assertEqual(mmo.produced_by, prod)", "od": 1}
{"code": "def test_init_params(self):\n\t\tp1 = model.Person(ident=\"urn:uuid:1234\")\n\t\tself.assertEqual(p1.id, \"urn:uuid:1234\")\n\t\tp2 = model.Person(ident=\"http://schema.org/Foo\")\n\t\tself.assertEqual(p2.id, \"schema:Foo\")\n\t\tp3 = model.Name(content=\"Test\")\n\t\tself.assertEqual(p3.content, \"Test\")\n\t\tc = model.MonetaryAmount(value=10)\n\t\tself.assertEqual(c.value, 10)\n\t\tn = model.Name(value=\"Rob\")\n\t\tself.assertEqual(n.content, \"Rob\")\n\t\ti = model.Identifier(content=\"xyz123\")\n\t\tself.assertEqual(i.content, \"xyz123\")\n\t\ti2 = model.Identifier(value=\"abc\")\n\t\tself.assertEqual(i2.content, \"abc\")", "od": 1}
{"code": "def test_dir(self):\n\t\tprops = dir(self.artist)\n\t\tself.assertTrue('identified_by' in props)", "od": 0}
{"code": "def test_cache_hierarchy(self):\n\t\to = model.HumanMadeObject()\n\t\tself.assertEqual(o._all_properties, {})\n\t\tmodel.factory.cache_hierarchy()\n\t\tself.assertTrue(len(o._all_properties) > 50)", "od": 1}
{"code": "def test_set_magic_resource(self):\n\t\tartist = model.Person('00001', 'Jane Doe')\n\t\tson = model.Person('00002', 'John Doe')\n\t\tdaughter = model.Person('00002', 'Jenny Doe')\n\t\tson2 = model.Person('00002', 'Jim Doe')\n\t\tartist._set_magic_resource('parent_of', son)\n\t\tself.assertEqual(artist.parent_of, [son])\n\t\tartist._set_magic_resource('parent_of', daughter)\n\t\ttry:\n\t\t\tself.assertIn(son, artist.parent_of)\n\t\t\tself.assertIn(daughter, artist.parent_of)\n\t\texcept:\n\t\t\t# 2.6 doesn't have assertIn\n\t\t\tself.assertTrue(son in artist.parent_of)\n\t\t\tself.assertTrue(daughter in artist.parent_of)\n\n\t\tartist._set_magic_resource('parent_of', son2)\n\t\ttry:\n\t\t\tself.assertIn(son, artist.parent_of)\n\t\t\tself.assertIn(daughter, artist.parent_of)\n\t\t\tself.assertIn(son2, artist.parent_of)\n\t\texcept:\n\t\t\tself.assertTrue(son in artist.parent_of)\n\t\t\tself.assertTrue(daughter in artist.parent_of)\n\t\t\tself.assertTrue(son2 in artist.parent_of)", "od": 0}
{"code": "def test_set_magic_resource_inverse(self):\n\t\tmodel.factory.materialize_inverses = True\n\t\tartist = model.Person('00001', 'Jane Doe')\n\t\tson = model.Person('00002', 'John Doe')\n\t\tartist._set_magic_resource('parent_of', son)\n\t\tself.assertEqual(son.parent, [artist])\n\t\tmodel.factory.materialize_inverses = False", "od": 0}
{"code": "def test_validate_profile_off(self):\n\t\tmodel.factory.validate_profile = False\n\t\tia = model.IdentifierAssignment()\n\t\t# If it's not turned off this should raise\n\t\tmodel.factory.validate_profile = True\n\t\tself.assertRaises(model.ProfileError, model.IdentifierAssignment)\t\t\n\t\tp1 = model.Person()\n\t\tself.assertRaises(model.ProfileError, p1.__setattr__, 'documented_in', \"foo\")", "od": 1}
{"code": "def test_validation_unknown(self):\n\t\tmodel.factory.validate_properties = True\n\t\tartist = model.Person('00001', 'Jane Doe')\t\t\n\t\tself.assertRaises(model.DataError, artist.__setattr__, 'unknown_property', 1)", "od": 0}
{"code": "def test_validation_wrong_type(self):\n\t\tmodel.factory.validate_properties = True\n\t\tartist = model.Person('00001', 'Jane Doe')\t\n\t\tself.assertRaises(model.DataError, artist.__setattr__, 'parent_of', 'Bad Value')", "od": 0}
{"code": "def test_validation_off(self):\n\t\tmodel.factory.validate_properties = False\n\t\tartist = model.Person('00001', 'Jane Doe')\t\t\n\t\tartist.unknown_property = 1\n\t\tself.assertEqual(artist.unknown_property, 1)\n\t\tmodel.factory.validate_properties = True", "od": 0}
{"code": "def test_validate_multiplicity(self):\n\t\tmodel.factory.validate_multiplicity = True\n\t\twho = model.Person()\n\t\tb1 = model.Birth()\n\t\twho.born = b1\n\t\tb2 = model.Birth()\n\t\tself.assertRaises(model.ProfileError, who.__setattr__, 'born', b2)\n\t\tmodel.factory.validate_multiplicity = False\n\t\twho.born = b2\n\t\tself.assertEqual(who.born, [b1, b2])", "od": 1}
{"code": "def test_not_multiple_instance(self):\n\t\twho = model.Person()\n\t\tn = model.Name(content=\"Test\")\n\t\twho.identified_by = n\n\n\t\tmodel.factory.multiple_instances_per_property = \"error\"\n\t\tself.assertRaises(model.DataError, who.__setattr__, 'identified_by', n)\n\t\tself.assertEqual(who.identified_by, [n])\n\n\t\tmodel.factory.multiple_instances_per_property = \"drop\"\n\t\twho.identified_by = n\n\t\tself.assertEqual(who.identified_by, [n,n])\t\t\n\t\t# and check that only serialized once\n\t\tjs = model.factory.toJSON(who)\n\t\tself.assertEqual(len(js['identified_by']), 1)\n\n\t\tmodel.factory.multiple_instances_per_property = \"allow\"\n\t\tjs = model.factory.toJSON(who)\n\t\tself.assertEqual(len(js['identified_by']), 2)", "od": 1}
{"code": "def test_eq_ident(self):\n\t\tself.assertEqual(self.artist, self.artist)\n\t\tself.assertEqual(self.son, model.Person('00002', 'John Doe'))\n\t\tself.assertEqual(self.son2, model.Person('00002', 'Jim Doe'))\n\t\tself.assertEqual(self.daughter, model.Person('00002', 'Jenny Doe'))", "od": 0}
{"code": "def test_eq_value(self):\n\t\tself.assertEqual(self.artist, model.Person('00001', 'Jane Doe'))\n\t\tself.assertEqual(self.son, self.son)\n\t\tself.assertEqual(self.son2, self.son2)\n\t\tself.assertEqual(self.daughter, self.daughter)", "od": 0}
{"code": "def test_in_value(self):\n\t\tpeople = (\n\t\t\tmodel.Person('00001', 'Jane Doe'), # artist\n\t\t\tmodel.Person('00002', 'Jim Doe')   # son2\n\t\t)\n\t\tself.assertIn(self.artist, people)\n\t\tself.assertNotIn(self.son, people)\n\t\tself.assertNotIn(self.daughter, people)\n\t\tself.assertIn(self.son2, people)", "od": 0}
{"code": "def test_neq(self):\n\t\tself.assertNotEqual(self.artist, self.son)\n\t\tself.assertNotEqual(self.artist, model.Person('00001', 'Jane')) # label differs\n\t\tself.assertNotEqual(self.artist, self.daughter)\n\t\tself.assertNotEqual(self.artist, self.son2)\n\t\tself.assertNotEqual(self.son, self.daughter)\n\t\tself.assertNotEqual(self.son, self.son2)\n\t\tself.assertNotEqual(self.daughter, self.son2)", "od": 0}
{"code": "def test_equality(self):\n\t\tfrom cromulent.model import factory\n\t\tplace1 = self.nation('Belgium', 'http://vocab.getty.edu/aat/300128207')\n\t\tplace2 = self.nation('Belgium', 'http://vocab.getty.edu/aat/300128207')\n\t\tself.assertEqual(place1, place2)", "od": 0}
{"code": "def test_read(self):\n\t\tself.assertRaises(DataError, self.reader.read, \"\")\n\t\tself.assertRaises(DataError, self.reader.read, \"This is not JSON\")\n\t\tself.assertRaises(DataError, self.reader.read, \"{}\")\n\n\t\twhostr = '{\"type\": \"Person\", \"_label\": \"me\"}'\n\t\tself.assertTrue(isinstance(self.reader.read(whostr), Person))\n\n\t\twhostr = '{\"@context\": \"fishbat\", \"type\": \"Person\", \"_label\": \"me\"}'\n\t\tself.assertTrue(isinstance(self.reader.read(whostr), Person))\n\n\t\tlevelstr = '{\"type\": \"Person\", \"parent_of\": {\"type\": \"Person\", \"_label\": \"child\"}}'\n\t\tself.assertTrue(isinstance(self.reader.read(levelstr).parent_of[0], Person))\n\n\t\tbasestr = '{\"_label\": \"base\"}'\n\t\tself.assertTrue(isinstance(self.reader.read(basestr), BaseResource))\n\n\t\tunknown = '{\"type\":\"FishBat\"}'\n\t\tself.assertRaises(DataError, self.reader.read, unknown)\n\n\t\tunknown2 = '{\"type\":\"Person\", \"fishbat\": \"bob\"}'\n\t\tself.assertRaises(DataError, self.reader.read, unknown)", "od": 0}
{"code": "def test_attrib_assign(self):\n\t\tvocab.add_attribute_assignment_check()\n\n\t\tdata = \"\"\"\n\t\t{\n\t\t  \"id\": \"https://linked.art/example/activity/12\", \n\t\t  \"type\": \"AttributeAssignment\", \n\t\t  \"assigned\": {\n\t\t    \"id\": \"https://linked.art/example/name/10\", \n\t\t\t\"type\": \"Name\", \n\t\t    \"content\": \"Exhibition Specific Name\"\n\t\t  }, \n\t\t  \"assigned_property\": \"identified_by\", \n\t\t  \"assigned_to\": {\n\t\t    \"id\": \"https://linked.art/example/object/12\", \n\t\t    \"type\": \"HumanMadeObject\", \n\t\t    \"_label\": \"Real Painting Name\"\n\t\t  }\n\t\t}\n\t\t\"\"\"\n\t\td = self.reader.read(data)\n\t\tself.assertTrue(isinstance(d, AttributeAssignment))", "od": 0}
{"code": "def test_vocab_collision(self):\n\t\t# Test that the algorithm picks the right vocab instance\n\t\t# if multiple have the same AAT term but different base class\n\n\t\tdata = \"\"\"\n        {\n          \"type\": \"LinguisticObject\",\n          \"_label\": \"Sale recorded in catalog: B-267 0003 (1817) (record number 22947)\",\n\t      \"part_of\": [\n            {\n              \"type\": \"LinguisticObject\",\n              \"_label\": \"Sale Catalog B-267\",\n              \"classified_as\": [\n                {\n                  \"id\": \"http://vocab.getty.edu/aat/300026068\",\n                  \"type\": \"Type\",\n                  \"_label\": \"Auction Catalog\"\n                }\n              ]\n            }\n          ]\n        }\n        \"\"\"\n\t\td = self.reader.read(data)\n\t\tself.assertTrue(isinstance(d.part_of[0], vocab.AuctionCatalogText))", "od": 0}
{"code": "def test_destruction(self):\n\t\texpect = OrderedDict([('id', u'http://lod.example.org/museum/Activity/1'), \n\t\t\t('type', ['Destruction', 'Activity']), ('_label', \"Test Destruction\")])\n\t\tmi.DestructionActivity._okayToUse = 1\n\t\tda = mi.DestructionActivity(\"1\")\n\t\tda._label = \"Test Destruction\"\n\t\tfactory.context_uri = \"\"\n\t\tdajs = factory.toJSON(da)\n\t\tself.assertEqual(dajs, expect)", "od": 0}
{"code": "def test_extract_simple(self):\n\t\te = extract_monetary_amount({\n\t\t\t'price': '10.0',\n\t\t\t'currency': 'pounds'\n\t\t})\n\t\tself.assertEqual(e.type, 'MonetaryAmount')\n\t\tself.assertEqual(e._label, '10.00 pounds')\n\t\tself.assertEqual(e.value, 10)\n\t\tc = e.currency\n\t\tself.assertEqual(c.type, 'Currency')\n\t\tself.assertEqual(c._label, 'British Pounds')", "od": 0}
{"code": "def test_extract_comma_separated(self):\n\t\te = extract_monetary_amount({\n\t\t\t'price': '1,280.5',\n\t\t\t'currency': 'pounds'\n\t\t})\n\t\tself.assertEqual(e.type, 'MonetaryAmount')\n\t\tself.assertEqual(e._label, '1,280.50 pounds')\n\t\tself.assertEqual(e.value, 1280.50)\n\t\tc = e.currency\n\t\tself.assertEqual(c.type, 'Currency')\n\t\tself.assertEqual(c._label, 'British Pounds')", "od": 0}
{"code": "def test_extract_label_digits(self):\n\t\te = extract_monetary_amount({\n\t\t\t'price': '1,280.5',\n\t\t\t'currency': 'pounds'\n\t\t}, truncate_label_digits=4)\n\t\tself.assertEqual(e.type, 'MonetaryAmount')\n\t\tself.assertEqual(e._label, '1,280.5000 pounds')\n\t\tself.assertEqual(e.value, 1280.50)\n\t\tc = e.currency\n\t\tself.assertEqual(c.type, 'Currency')\n\t\tself.assertEqual(c._label, 'British Pounds')", "od": 0}
{"code": "def test_extract_multiple_comma_separated(self):\n\t\te = extract_monetary_amount({\n\t\t\t'price': '1,310,720.5',\n\t\t\t'currency': 'pounds'\n\t\t})\n\t\tself.assertEqual(e.type, 'MonetaryAmount')\n\t\tself.assertEqual(e._label, '1,310,720.50 pounds')\n\t\tself.assertEqual(e.value, 1310720.5)\n\t\tc = e.currency\n\t\tself.assertEqual(c.type, 'Currency')\n\t\tself.assertEqual(c._label, 'British Pounds')", "od": 0}
{"code": "def test_extract_est(self):\n\t\te = extract_monetary_amount({\n\t\t\t'est_price': '12.0',\n\t\t\t'currency': 'pounds'\n\t\t})\n\t\tself.assertEqual(e.value, 12)\n\t\tc = e.currency\n\t\tself.assertEqual(e.classified_as[0]._label, 'Estimated Price')\n\t\tself.assertEqual(e.currency._label, 'British Pounds')", "od": 0}
{"code": "def test_extract_start(self):\n\t\te = extract_monetary_amount({\n\t\t\t'start_price': '8.5',\n\t\t\t'currency': 'pounds'\n\t\t})\n\t\tself.assertEqual(e.value, 8.5)\n\t\tc = e.currency\n\t\tself.assertEqual(e.classified_as[0]._label, 'Starting Price')\n\t\tself.assertEqual(e.currency._label, 'British Pounds')", "od": 0}
{"code": "def test_extract_custom_currency_key(self):\n\t\td = {\n\t\t\t'price': '7',\n\t\t\t'currency': 'zzz'\n\t\t}\n\t\twith self.assertRaises(AttributeError):\n\t\t\te = extract_monetary_amount(d)\n\t\t\tself.assertEqual(e.currency._label, 'Custom Currency')\n\t\t\n\t\te = extract_monetary_amount(d, currency_mapping=CUSTOM_MAPPING)\n\t\tself.assertEqual(e.value, 7)\n\t\tself.assertEqual(e.currency._label, 'US Dollars')", "od": 0}
{"code": "def test_extract_custom_currency_instance(self):\n\t\td = {\n\t\t\t'price': '7',\n\t\t\t'currency': 'xxx'\n\t\t}\n\t\twith self.assertRaises(AttributeError):\n\t\t\te = extract_monetary_amount(d)\n\t\t\tself.assertEqual(e.currency._label, 'Custom Currency')\n\t\t\n\t\te = extract_monetary_amount(d, currency_mapping=CUSTOM_MAPPING)\n\t\tself.assertEqual(e.value, 7)\n\t\tself.assertEqual(e.currency._label, 'My Dollars')", "od": 0}
{"code": "def test_extract_price_with_citation(self):\n\t\td = {\n\t\t\t'price': '7',\n\t\t\t'currency': 'pounds',\n\t\t\t'citation': 'crom test suite'\n\t\t}\n\t\te = extract_monetary_amount(d, add_citations=True)\n\t\tself.assertEqual(e.value, 7)\n\t\tself.assertEqual(e.currency._label, 'British Pounds')\n\t\tself.assertEqual(e.referred_to_by[0].content, 'crom test suite')", "od": 0}
{"code": "def test_class(self):\n\t\tvocab.register_aat_class(\"TestObject1\", {\"parent\": model.HumanMadeObject, \"id\": \"1\", \"label\": \"example 1\"})\n\t\tfrom cromulent.vocab import TestObject1\n\t\tself.assertEqual(TestObject1._classification[0].id, 'http://vocab.getty.edu/aat/1')", "od": 0}
{"code": "def test_instance(self):\n\t\tvocab.register_instance(\"TestMaterial2\", {\"parent\": model.Material, \"id\": \"2\", \"label\": \"example 2\"})\n\t\tself.assertTrue('TestMaterial2' in vocab.instances)\n\t\ttm2 = vocab.instances['TestMaterial2']\n\t\tself.assertEqual(tm2.id, \"http://vocab.getty.edu/aat/2\")", "od": 0}
{"code": "def test_metatype(self):\n\t\tvocab.register_instance(\"example\", {\"parent\": model.Type, \"id\": \"3\", \"label\": \"example type\"}) \n\t\tvocab.register_aat_class(\"TestObject2\", \n\t\t\t{\"parent\": model.HumanMadeObject, \"id\": \"4\", \"label\": \"example typed object\", \"metatype\": \"example\"})\n\t\tfrom cromulent.vocab import TestObject2\n\t\tself.assertEqual(TestObject2._classification[0].classified_as[0].id, 'http://vocab.getty.edu/aat/3')", "od": 0}
{"code": "def test_multitype(self):\n\t\tfrom cromulent.vocab import make_multitype_obj, Painting, Drawing\n\t\tinst = make_multitype_obj(Painting, Drawing)\n\t\tself.assertTrue(isinstance(inst, Painting))\n\t\tself.assertTrue(len(inst.classified_as) == 2)\n\t\tself.assertTrue(inst.classified_as[1].id == \"http://vocab.getty.edu/aat/300033973\")\n\n\t\tfrom cromulent.model import HumanMadeObject\n\n\t\tinst = make_multitype_obj(HumanMadeObject, Painting)\n\t\tself.assertTrue(len(inst.classified_as) == 1)\n\t\tself.assertTrue(inst.classified_as[0].id == \"http://vocab.getty.edu/aat/300033618\")", "od": 0}
{"code": "def test_conceptual_parts(self):\n\t\tr = model.Right()\n\t\tr2 = model.Right()\n\t\tself.assertRaises(model.DataError, r.__setattr__, 'part', r2)\n\t\tr.c_part = r2\n\t\tself.assertTrue(r2 in r.c_part)\n\n\t\tvocab.conceptual_only_parts()\n\t\tr3 = model.Right()\n\t\tr4 = model.Right()\n\t\tr3.part = r4\n\t\tself.assertTrue(r4 in r3.c_part)\n\t\tself.assertTrue(\"part\" in model.factory.toJSON(r3))\n\t\tself.assertTrue(r4 in r3.part)", "od": 0}
{"code": "def test_art_setter(self):\n\t\tp = model.HumanMadeObject(\"a\", art=1)\n\t\tp._label = \"a\"\n\t\tpj = p._toJSON(done={})\n\t\tself.assertFalse(pj.get('classified_as', None))\n\t\tvocab.add_art_setter()\n\t\tp2 = vocab.Painting(\"b\", art=1)\n\t\tp2j = p2._toJSON(done={})", "od": 0}
{"code": "def test_aa_check(self):\n\n\t\t# Make sure that some other test hasn't set it\n\t\ttry:\n\t\t\tdel model.AttributeAssignment.set_assigned_property\n\t\texcept:\n\t\t\tpass\n\n\t\tt = model.Type()\n\t\taa = model.AttributeAssignment()\n\t\t# First check that aa accepts a type\n\t\taa.assigned_property = t\n\t\t# And will not accept a string\n\t\tself.assertRaises(model.DataError, aa.__setattr__, \"assigned_property\", \"classified_as\")\n\n\t\t# Check we can set anything to assigned / assigned_to\n\t\taa.assigned_property = None\n\t\taa.assigned = aa\n\t\taa.assigned_to = aa\n\t\tself.assertEqual(aa.assigned, aa)\n\t\tself.assertEqual(aa.assigned_to, aa)\n\n\t\tvocab.add_attribute_assignment_check()\n\n\t\t# This should fail right now as can't classify as an AA\n\t\tself.assertRaises(model.DataError, aa.__setattr__, \"assigned_property\", \"classified_as\")\n\t\taa.assigned = None\n\t\taa.assigned_to = None\n\t\taa.assigned = t\n\t\taa.assigned_to = t\n\t\taa.assigned_property = \"classified_as\"\n\t\tself.assertEqual(aa.assigned_property, 'classified_as')", "od": 0}
{"code": "def test_boundary_setter(self):\n\t\tvocab.add_linked_art_boundary_check()\n\t\tp = model.Person()\n\t\tp2 = model.Person()\n\t\tn = model.Name()\n\t\tn.content = \"Test\"\n\t\tp2.identified_by = n\n\t\tp.exact_match = p2\n\t\t# Now, Test should not appear in the resulting JSON of p\n\t\tfactory.linked_art_boundaries = True\n\t\tjs = factory.toJSON(p)\n\t\tself.assertTrue(not 'identified_by' in js['exact_match'][0])\n\t\tfactory.linked_art_boundaries = False\n\t\tjs = factory.toJSON(p)\n\t\tself.assertTrue('identified_by' in js['exact_match'][0])", "od": 0}
{"code": "def test_procurement_boundary(self):\n\t\tvocab.add_linked_art_boundary_check()\n\t\ta = model.Activity()\n\t\tp = vocab.ProvenanceEntry()\n\t\ta.caused = p\n\t\tjs = factory.toJSON(a)\n\t\tself.assertTrue(not 'classified_as' in js['caused'][0])", "od": 0}
{"code": "def test_linguistic_object_boundary(self):\n\t\tvocab.add_linked_art_boundary_check()\n\t\tjrnl = vocab.JournalText(label=\"journal\")\n\t\tissue = vocab.IssueText(label=\"issue\")\n\t\tissue.part_of = jrnl\n\t\tissue.referred_to_by = vocab.MaterialStatement(content=\"Statement\")\n\n\t\tjs = factory.toJSON(issue)\n\t\t# Have not embedded journal in issue\n\t\tself.assertTrue(not 'classified_as' in js['part_of'][0])\n\t\t# Have embedded statement in issue\n\t\tself.assertTrue('content' in js['referred_to_by'][0])\n\t\tself.assertTrue('type' in js['referred_to_by'][0]['classified_as'][0]['classified_as'][0])", "od": 0}
{"code": "def test_parse_simple_dimensions(self):\n\t\t'''\n\t\tTest the documented formats that `cromulent.extract.parse_simple_dimensions` can parse\n\t\tand ensure that it returns the expected data.\n\t\t'''\n\t\ttests = {\n\t\t\t\"3'\": [Dimension(3, 'feet', None)],\n\t\t\t'3 feet': [Dimension(3, 'feet', None)],\n\t\t\t'3 foot': [Dimension(3, 'feet', None)],\n\t\t\t'3 ft': [Dimension(3, 'feet', None)],\n\t\t\t'3 ft.': [Dimension(3, 'feet', None)],\n\t\t\t'2\"': [Dimension(2, 'inches', None)],\n\t\t\t'2 in': [Dimension(2, 'inches', None)],\n\t\t\t'2 in.': [Dimension(2, 'inches', None)],\n\t\t\t'2 inch': [Dimension(2, 'inches', None)],\n\t\t\t'2 inches': [Dimension(2, 'inches', None)],\n\t\t\t'2 duymen': [Dimension(2, 'inches', None)],\n\t\t\t'2 d.': [Dimension(2, 'inches', None)],\n\t\t\t'2 d': [Dimension(2, 'inches', None)],\n\t\t\t'''2'8\"''': [Dimension(2, 'feet', None), Dimension(8, 'inches', None)],\n\t\t\t'4cm': [Dimension(4, 'cm', None)],\n\t\t\t'2 pieds 3 pouces': [Dimension(2, 'fr_feet', None), Dimension(3, 'fr_inches', None)],\n\t\t\t'1 pied 7 pouces': [Dimension(1, 'fr_feet', None), Dimension(7, 'fr_inches', None)],\n\t\t\t'8 pouce': [Dimension(8, 'fr_inches', None)],\n\t\t\t'8 pouces': [Dimension(8, 'fr_inches', None)],\n\t\t\t'8 1/2 pouces': [Dimension(8.5, 'fr_inches', None)],\n\t\t\t'8 1/4 pouces': [Dimension(8.25, 'fr_inches', None)],\n\t\t\t'8 1/8 pouces': [Dimension(8.125, 'fr_inches', None)],\n\t\t\t'1': [Dimension(1, None, None)],\n\t\t\t\n\t\t\t# values without a unit that follow values with a unit stay in the same system but using the next-finer unit\n\t\t\t'2 pieds 3': [Dimension(2, 'fr_feet', None), Dimension(3, 'fr_inches', None)],\n\t\t\t\"1' 3\": [Dimension(1, 'feet', None), Dimension(3, 'inches', None)],\n\t\t}\n\n\t\tfor value, expected in tests.items():\n\t\t\tdims = cromulent.extract.parse_simple_dimensions(value)\n\t\t\tif expected is not None:\n\t\t\t\tself.assertIsInstance(dims, list)\n\t\t\t\tself.assertEqual(dims, expected, msg='dimensions: %r' % (value,))\n\t\t\telse:\n\t\t\t\tself.assertIsNone(dims)", "od": 0}
{"code": "def test_dimension_cleaner(self):\n\t\t'''\n\t\tTest the documented formats that `cromulent.extract.dimensions_cleaner` can parse\n\t\tand ensure that it returns the expected data.\n\t\t'''\n\t\ttests = {\n\t\t\t'''2 in by 1 in''': ([Dimension(2, 'inches', None)], [Dimension(1, 'inches', None)]),\n\t\t\t'''2'2\"h x 2'8\"w''': ([Dimension(2, 'feet', 'height'), Dimension(2, 'inches', 'height')], [Dimension(2, 'feet', 'width'), Dimension(8, 'inches', 'width')]),\n\t\t\t'''1'3\"x4cm h''': ([Dimension(1, 'feet', None), Dimension(3, 'inches', None)], [Dimension(4, 'cm', 'height')]),\n\t\t\t'''1'3\" by 4\"''': ([Dimension(1, 'feet', None), Dimension(3, 'inches', None)], [Dimension(4, 'inches', None)]),\n\t\t\t'Haut 14 pouces, large 10 pouces': ([Dimension(14, 'fr_inches', 'height')], [Dimension(10, 'fr_inches', 'width')]),\n\t\t\t'Haut. 48 pouces, large 68 pouces': ([Dimension(48, 'fr_inches', 'height')], [Dimension(68, 'fr_inches', 'width')]),\n\t\t\t'1 by 4': ([Dimension(1, None, None)], [Dimension(4, None, None)]),\n\t\t\t'Hoog. 6 v., breed 3 v': ([Dimension(6, 'feet', 'height')], [Dimension(3, 'feet', 'width')]),\n\t\t\t'Breedt 6 v., hoog 3 v': ([Dimension(6, 'feet', 'width')], [Dimension(3, 'feet', 'height')]),\n\t\t\t'20 cm x 24,5 cm': ([Dimension(20, 'cm', None)], [Dimension(24.5, 'cm', None)]),\n\t\t\t'2 w by 5 h': ([Dimension(2, None, 'width')], [Dimension(5, None, 'height')]),\n\t\t\t'Hauteur 1 pied 4 pouces, largeur 1 pied 1/2 pouc.': ([Dimension(1, 'fr_feet', 'height'), Dimension(value=4, unit='fr_inches', which='height')], [Dimension(1, 'fr_feet', 'width'), Dimension(value=0.5, unit='fr_inches', which='width')]),\n\t\t\t'h.73 pouces 4 lignes, l.50 pouces': ([Dimension(value=73, unit='fr_inches', which='height'), Dimension(value=4, unit='ligne', which='height')], [Dimension(value=50, unit='fr_inches', which='width')]),\n\t\t\t'haut. 5 pouc. larg. 5 pouc. 4 linges': ([Dimension(value=5, unit='fr_inches', which='height')], [Dimension(value=5, unit='fr_inches', which='width'), Dimension(value=4, unit='ligne', which='width')]),\n\t\t\t'haut. 9 pouc. 4 lignes larg. 10 pouc. 4 linges': ([Dimension(value=9, unit='fr_inches', which='height'), Dimension(value=4, unit='ligne', which='height')], [Dimension(value=10, unit='fr_inches', which='width'), Dimension(value=4, unit='ligne', which='width')]),\n\t\t\t'h 38 cm, w 27 cm': ([Dimension(38, 'cm', 'height')], [Dimension(27, 'cm', 'width')]),\n\t\t\t\"hauteur 9 pouces, largeur 7\": ([Dimension(value=9, unit='fr_inches', which='height')], [Dimension(value=7, unit=None, which='width')]),\n\t\t}\n\n\t\tfor value, expected in tests.items():\n\t\t\tdims = cromulent.extract.dimensions_cleaner(value)\n\t\t\tif expected is not None:\n\t\t\t\tself.assertIsInstance(dims, tuple)\n# \t\t\t\tprint('===== got:')\n# \t\t\t\tpprint.pprint(dims)\n# \t\t\t\tprint('----- expected:')\n# \t\t\t\tpprint.pprint(expected)\n# \t\t\t\tprint('=====')\n\t\t\t\tself.assertEqual(dims, expected, msg='dimensions: %r' % (value,))\n\t\t\telse:\n\t\t\t\tself.assertIsNone(dims)", "od": 0}
{"code": "def test_extract_physical_dimensions(self):\n\t\t'''\n\t\tTest the documented formats that `cromulent.extract.extract_physical_dimensions`\n\t\tcan parse and ensure that it returns the expected data.\n\t\t'''\n\t\ttests = {}\n\t\th9l7_height = cromulent.vocab.Height(ident='', content=9.0)\n\t\th9l7_height.identified_by = cromulent.model.Name(ident='', content='9 French inches')\n\t\th9l7_height.unit = cromulent.vocab.instances.get('fr_inches')\n\t\th9l7_width = cromulent.vocab.Width(ident='', content=7.0)\n\t\ttests[\"hauteur 9 pouces, largeur 7\"] = [h9l7_height, h9l7_width]\n\n\t\tfor value, expected_dims in tests.items():\n\t\t\tdims = list(cromulent.extract.extract_physical_dimensions(value))\n\t\t\tfor got, expected in zip(dims, expected_dims):\n\t\t\t\tself.assertEqual(got.value, expected.value)\n\t\t\t\tself.assertEqual(got.type, expected.type)\n\n\t\t\t\tif suppress is None:\n\t\t\t\t\t# Python 2.7\n\t\t\t\t\tif hasattr(expected, 'unit'):\n\t\t\t\t\t\tself.assertEqual(got.unit, expected.unit)\t\t\t\t\t\t\n\t\t\t\t\tif hasattr(expected, 'classified_as'):\n\t\t\t\t\t\tself.assertEqual(got.classified_as, expected.classified_as)\t\t\t\t\t\t\n\t\t\t\t\tif hasattr(expected, 'identified_by'):\n\t\t\t\t\t\tself.assertEqual(got.identified_by, expected.identified_by)\t\t\t\t\t\t\n\t\t\t\telse:\t\t\t\n\t\t\t\t\twith suppress(AttributeError):\n\t\t\t\t\t\tself.assertEqual(got.unit, expected.unit)\n\t\t\t\t\twith suppress(AttributeError):\n\t\t\t\t\t\tself.assertEqual(got.classified_as, expected.classified_as)\n\t\t\t\t\twith suppress(AttributeError):\n\t\t\t\t\t\tself.assertEqual(got.identified_by, expected.identified_by)", "od": 0}
{"code": "def test_extract_physical_dimensions_with_default(self):\n\t\t'''\n\t\tTest the documented formats that `cromulent.extract.extract_physical_dimensions`\n\t\tcan parse, specifying a default unit, and ensure that it returns the expected data.\n\t\t'''\n\t\ttests = {}\n\t\th9l7_height = cromulent.vocab.Height(ident='', content=9.0)\n\t\th9l7_height.identified_by = cromulent.model.Name(ident='', content='9 French inches')\n\t\th9l7_height.unit = cromulent.vocab.instances.get('fr_inches')\n\t\th9l7_width = cromulent.vocab.Width(ident='', content=7.0)\n\t\th9l7_width.unit = cromulent.vocab.instances.get('inches')\n\t\ttests[\"hauteur 9 pouces, largeur 7\"] = [h9l7_height, h9l7_width]\n\n\t\tfor value, expected_dims in tests.items():\n\t\t\tdims = list(cromulent.extract.extract_physical_dimensions(value, default_unit='inches'))\n\t\t\tfor got, expected in zip(dims, expected_dims):\n\t\t\t\tself.assertEqual(got.value, expected.value)\n\t\t\t\tself.assertEqual(got.type, expected.type)\n\t\t\t\tself.assertEqual(got.unit, expected.unit)", "od": 0}
{"code": "def test_normalize_dimension(self):\n\t\ttests = {\n\t\t\t'1 ft, 2 in': ('1 foot, 2 inches', Dimension(value=14, unit='inches', which=None)),\n\t\t\t'8 1/2 pouces': ('8.5 French inches', Dimension(value=8.5, unit='fr_inches', which=None)),\n\t\t\t'1 pied 7 pouces': ('1 French foot, 7 French inches', Dimension(value=19, unit='fr_inches', which=None)),\n\t\t\t'2 pied 1/2 pouces': ('2 French feet, 0.5 French inches', Dimension(value=24.5, unit='fr_inches', which=None)),\n\t\t\t'1 pied 3 pouce. 3 linges': ('1 French foot, 3 French inches, 3 lignes', Dimension(value=15.25, unit='fr_inches', which=None)),\n\t\t\t\"4' 8\": ('4 feet, 8 inches', Dimension(value=56, unit='inches', which=None)),\n\t\t\t\"1 pied 2\": ('1 French foot, 2 French inches', Dimension(value=14, unit='fr_inches', which=None)),\n\t\t}\n\t\tfor value, expected in tests.items():\n\t\t\telabel, edim = expected\n\t\t\tdims = cromulent.extract.parse_simple_dimensions(value)\n\t\t\tdim, label = normalized_dimension_object(dims)\n\t\t\tself.assertEqual(label, elabel)\n\t\t\tself.assertEqual(dim, edim)", "od": 0}
{"code": "def test_add_classification(self):\n\t\tamnt = model.MonetaryAmount(ident='')\n\t\tamnt.value = 7.0\n\t\tself.assertNotIn('Asking Price', factory.toString(amnt))\n\t\tvocab.add_classification(amnt, vocab.AskingPrice)\n\t\tself.assertIn('Asking Price', factory.toString(amnt))", "od": 0}
{"code": "def test_get_entity_from_token_or_tablename(self, MockEntityModelThree, mock_decoded_token_three, MockAOuthModel):\n\n        self.config.entity_models = [MockEntityModelThree]\n        entity = Entity(self.config)\n        assert entity.get_entity_from_token_or_tablename(mock_decoded_token_three) == [(1, 'joe')]\n\n        self.config.entity_models = [MockAOuthModel]\n        self.config.google_oauth = self.oauth_options\n        entity = Entity(self.config)\n        entity.oauth_entity_key = \"email\"\n        assert entity.get_entity_from_token_or_tablename(tablename=\"oauth_tablename\") == [(1, 'joe')]", "od": 0}
{"code": "def test_get_entity_from_token_multiple(self, MockEntityModel, MockEntityModelTwo, MockAOuthModel, mock_decoded_token_two):\n\n        self.config.entity_models = [MockEntityModel, MockAOuthModel, MockEntityModelTwo]\n        entity = Entity(self.config)\n        assert entity.get_entity_from_token_or_tablename(mock_decoded_token_two) == [(1, 'joe')]\n\n        self.config.entity_models = [MockEntityModel, MockAOuthModel, MockEntityModelTwo]\n        self.config.google_oauth = self.oauth_options\n        entity = Entity(self.config)\n        entity.oauth_entity_key = \"email\"\n        assert entity.get_entity_from_token_or_tablename(tablename=\"oauth_tablename\") == [(1, 'joe')]", "od": 0}
{"code": "def test_get_attr_name(self, MockEntityModel, mock_decoded_token):\n\n        self.config.entity_models = [MockEntityModel]\n\n        entity = Entity(self.config)\n        entity.get_entity_from_token_or_tablename(mock_decoded_token)\n\n        result = entity.get_attr_name()\n\n        assert result == \"id\"", "od": 0}
{"code": "def test_get_attr_name(self, request_client):\n        from tests.fixtures.models import TeacherModel\n        from tests.fixtures.main_fixture import db\n        teacher = TeacherModel(name=\"joe\")\n        db.session.add(teacher)\n        db.session.commit()\n        rv = request_client.post(\"/api/v1/test_entity\")\n        assert \"200\" in str(rv.status)\n        assert \"token\" in str(rv.get_json())\n\n        token = rv.get_json()[\"token\"]\n\n        decoded_token = jwt.decode(\n                token,\n                \"__TEST_SECRET__\",\n                algorithms=\"HS256\"\n            )\n\n        assert decoded_token[\"table_name\"] == \"teachers\"\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {token}\",\n        }\n        rv_get = request_client.get(\"/api/v1/test_entity\", headers=headers)\n\n        assert \"200\" in str(rv_get.status)\n        assert \"token\" in str(rv_get.get_json())\n        assert rv_get.get_json()[\"data\"] == {\"teacher_id\": 1, \"name\": \"joe\"}\n\n        token_two = rv_get.get_json()[\"token\"]\n\n        decoded_token_two = jwt.decode(\n                token_two,\n                \"__TEST_SECRET__\",\n                algorithms=\"HS256\"\n            )\n\n        assert decoded_token_two[\"table_name\"] == \"teachers\"", "od": 0}
{"code": "def test_before_middleware(self, monkeypatch, TestMockEntity, MockAOuthModel, mock_token, http_requests):\n        app = Flask(__name__)\n\n        @app.route(\"/test\", methods=[\"GET\"])\n        def fc_one():\n            return \"/test\"\n        # Manually set the primary key\n        entity = TestMockEntity(id=1, user_name=\"joe\")\n        oauth_entity = MockAOuthModel(id=1, email=\"jaco@gmail.com\")\n        after_oauth = TestMockEntity(id=1, user_name=\"terry\")\n\n        ctx = app.test_request_context(\"/test\")\n        ctx.push()\n\n        assert entity.user_name == \"joe\"\n        assert entity.id == 1\n        assert oauth_entity.id == 1\n        assert oauth_entity.email == \"jaco@gmail.com\"\n        assert after_oauth.user_name == \"terry\"\n        assert after_oauth.id == 1\n\n        config = Config()\n        config.init_config(self.app_config, google_oauth=self.oauth_options)\n\n        config.entity_models = [TestMockEntity, MockAOuthModel]\n        entity = Entity(config)\n        google = Google(http_requests(oauth_urls))\n        google.init(**config.google_oauth)\n        routing = Routing()\n        routing.init(app, config, entity, google)\n\n        with ctx:\n            # token from args\n            monkeypatch.setattr(\"flask.request.args\", MockArgs(mock_token))\n            entity.clean_up()\n            assert routing.entity.entity_key == None\n            assert routing.entity.tablename == None\n            routing.before_middleware()\n            assert ctx.g.test_entities == [(1, 'joe')]\n\n        with ctx:\n            # token from OAuth headers - X-Auth-Token\n            monkeypatch.setattr(\"flask.request.args\", {})\n            monkeypatch.setattr(\"flask.request.headers\", MockArgs(mock_token, True))\n            entity.clean_up()\n            assert routing.entity.oauth_entity_key == None\n            assert routing.entity.tablename == None\n        #     routing.before_middleware()\n        #     assert ctx.g.oauth_tablename == [(1, 'jaco@gmail.com')]\n\n        # with ctx:\n        #     # token from oauth headers\n        #     monkeypatch.setattr(\"flask.request.args\", {})\n        #     monkeypatch.setattr(\"flask.request.headers\", MockArgs(\"<access_token>\", \"X-Auth-Token\"))\n        #     entity.clean_up()\n        #     assert routing.entity.entity_key == None\n        #     assert routing.entity.oauth_entity_key == None\n        #     assert routing.entity.tablename == None\n        #     routing.before_middleware()\n        #     assert ctx.g.oauth_tablename == [(1, \"jaco@gmail.com\")]\n\n        # Fixes bug - \"entity key state gets stale between requests #171\"\n        # https://github.com/joegasewicz/flask-jwt-router/issues/171\n        with ctx:\n            monkeypatch.setattr(\"flask.request.headers\", MockArgs(\"<after_token>\", \"Authorization\"))\n            entity.clean_up()\n            assert routing.entity.entity_key == None\n            assert routing.entity.oauth_entity_key == None\n            assert routing.entity.tablename == None", "od": 0}
{"code": "def test_jwt_route(self, jwt_router_client, entity_model, expected):\n        rv = jwt_router_client.get(\"/test\")\n        assert expected in str(rv.status)", "od": 1}
{"code": "def test_api_named_routes(self, request_client):\n        rv = request_client.get(\"/api/v1/test\")\n        assert \"200\" in str(rv.status)", "od": 0}
{"code": "def test_sub_paths(self, request_client):\n        rv = request_client.get(\"/api/v1/bananas/sub\")\n        assert \"200\" in str(rv.status)\n        assert rv.get_json()[\"data\"] == \"sub\"\n\n        rv = request_client.get(\"/api/v1/test/sub_two\")\n        assert \"401\" in str(rv.status)", "od": 0}
{"code": "def test_dynamic_params(self, request_client):\n        rv = request_client.put(\"/api/v1/apples/sub/1\")\n        assert \"200\" in str(rv.status)\n\n        rv = request_client.get(\"/api/v1/apples/sub/\")\n        assert \"404\" in str(rv.status)\n\n        rv = request_client.get(\"/api/v1/apples/sub/hello\")\n        assert \"404\" in str(rv.status)", "od": 0}
{"code": "def test_static_routes(self, request_client):\n        \"\"\"\n        Tests if the static path is handled both by default and\n        if the path is past to the static_folder kwarg\n        \"\"\"\n        rv = request_client.get(\"/static/images/Group.jpg\")\n        assert \"200\" in str(rv.status)\n\n        rv = request_client.get(\"/\")\n        assert \"200\" in str(rv.status)", "od": 0}
{"code": "def test_static_client(self, test_client_static):\n        rv = test_client_static.get(\"/static_copy/images/Group.jpg\")\n        assert \"200\" in str(rv.status)", "od": 0}
{"code": "def test_ignored_routes(self, request_client):\n        rv = request_client.get(\"/ignore\")\n        assert \"200\" in str(rv.status)", "od": 0}
{"code": "def test_ignored_route_path(self, request_client):\n        rv = request_client.get(\"/\")\n        assert \"200\" in str(rv.status)", "od": 0}
{"code": "def test_handle_pre_flight_request(self, request_client):\n        rv = request_client.options(\"/\")\n        assert \"200\" in str(rv.status)", "od": 0}
{"code": "def test_routing_with_google_create_test_headers(self, request_client, MockAOuthModel, google_oauth_user):\n        email = \"test_one@oauth.com\"\n        test_user = MockAOuthModel(email=\"test_one@oauth.com\")\n        google = jwt_routes.get_strategy(\"GoogleTestUtil\")\n        assert google.test_metadata == {}\n        # Pure stateless test with no db\n        oauth_headers = google.create_test_headers(email=email, entity=test_user)\n\n        assert google.test_metadata[email] == {\"email\": email, \"entity\": test_user, \"scope\": \"function\"}\n        assert oauth_headers == {'X-Auth-Token': f'Bearer {email}'}\n        #\n        rv = request_client.get(\"/api/v1/test_google_oauth\", headers=oauth_headers)\n        assert \"200\" in str(rv.status)\n        assert email == rv.get_json()[\"email\"]\n        assert google.test_metadata == {}\n        #\n        # # Tests with side effects to db\n        oauth_headers = google.create_test_headers(email=google_oauth_user.email)\n        #\n        assert google.test_metadata[email] == {\"email\": email, \"entity\": None, \"scope\": \"function\"}\n        assert oauth_headers == {'X-Auth-Token': f'Bearer {email}'}\n        #\n        rv = request_client.get(\"/api/v1/test_google_oauth\", headers=oauth_headers)\n        assert \"200\" in str(rv.status)\n        assert email == rv.get_json()[\"email\"]\n        assert google.test_metadata == {}", "od": 0}
{"code": "def test_routing_with_google_create_headers_scope(self, request_client, MockAOuthModel, google_oauth_user):\n        email = \"test_one@oauth.com\"\n        test_user = MockAOuthModel(email=\"test_one@oauth.com\")\n        test_metadata = {\"email\": email, \"entity\": test_user, \"scope\": \"application\"}\n        google = jwt_routes.get_strategy(\"GoogleTestUtil\")\n        assert google.test_metadata == {}\n        # Pure stateless test with no db\n        oauth_headers = google.create_test_headers(email=email, entity=test_user, scope=\"application\")\n\n        assert google.test_metadata[email] == test_metadata\n        assert oauth_headers == {'X-Auth-Token': f'Bearer {email}'}\n\n        rv = request_client.get(\"/api/v1/test_google_oauth\", headers=oauth_headers)\n        assert \"200\" in str(rv.status)\n        assert email == rv.get_json()[\"email\"]\n        assert google.test_metadata[email] == test_metadata", "od": 0}
{"code": "def test_init_config(self, MockEntityModel):\n        config = Config()\n\n        config.init_config(\n            self.config,\n            entity_models=[MockEntityModel],\n            google_oauth=self.oauth_options,\n        )\n\n        assert config.whitelist_routes == self.WHITE_LIST_ROUTES\n        assert config.ignored_routes == self.IGNORED_ROUTES\n        assert config.entity_models == [MockEntityModel]\n        assert config.entity_key == \"user_id\"\n        assert config.api_name == \"api/v1\"\n        assert config.expire_days == 6\n        assert hasattr(config, \"oauth_entity\")\n        assert hasattr(config, \"oauth_entity\")\n        assert config.google_oauth[\"client_id\"] == \"<CLIENT_ID>\"\n        assert config.google_oauth[\"client_secret\"] == \"<CLIENT_SECRET>\"\n        assert config.google_oauth[\"redirect_uri\"] == \"http://localhost:3000\"\n        assert config.google_oauth[\"tablename\"] == \"users\"\n        assert config.google_oauth[\"email_field\"] == \"email\"\n        assert config.google_oauth[\"expires_in\"] == 3600\n\n        config_two = {**self.config, \"ENTITY_MODELS\": [MockEntityModel]}\n        config.init_config(config_two)\n\n        assert config.entity_models == [MockEntityModel]", "od": 0}
{"code": "def test_init_app(self, MockEntityModel, MockAOuthModel):\n        jwt = JwtRoutes(self.app, entity_models=[MockEntityModel])\n        assert jwt.config.entity_models[0] == MockEntityModel\n        assert jwt.app == self.app\n        assert jwt.config.expire_days == 8\n\n        jwt = JwtRoutes()\n        jwt.init_app(self.app, entity_models=[MockEntityModel])\n        assert jwt.config.entity_models[0] == MockEntityModel\n        assert jwt.app == self.app\n        assert jwt.config.expire_days == 8\n\n        jwt = JwtRoutes(self.app)\n        jwt.init_app(entity_models=[MockEntityModel])\n        assert jwt.config.entity_models[0] == MockEntityModel\n        assert jwt.app == self.app\n        assert jwt.config.expire_days == 8\n\n        jwt = JwtRoutes(entity_models=[MockEntityModel])\n        jwt.init_app(self.app)\n        assert jwt.config.entity_models[0] == MockEntityModel\n        assert jwt.app == self.app\n        assert jwt.config.expire_days == 8\n\n        self.app.config[\"ENTITY_MODELS\"] = [MockEntityModel]\n        jwt = JwtRoutes()\n        jwt.init_app(self.app)\n        assert jwt.config.entity_models[0] == MockEntityModel\n        assert jwt.app == self.app\n        assert jwt.config.expire_days == 8\n\n        self.app.config[\"ENTITY_MODELS\"] = [MockEntityModel, MockAOuthModel]\n        jwt = JwtRoutes()\n        jwt.init_app(self.app, google_oauth=self.oauth_options, strategies=[GoogleTestUtil])\n        assert jwt.config.entity_models[1] == MockAOuthModel\n        assert jwt.config.google_oauth[\"client_id\"] == \"<CLIENT_ID>\"\n        assert jwt.config.google_oauth[\"client_secret\"] == \"<CLIENT_SECRET>\"\n        assert jwt.config.google_oauth[\"redirect_uri\"] == \"http://localhost:3000\"\n        assert jwt.config.google_oauth[\"tablename\"] == \"users\"\n        assert jwt.config.google_oauth[\"email_field\"] == \"email\"\n        assert jwt.config.google_oauth[\"expires_in\"] == 3600\n\n        self.app.config[\"ENTITY_MODELS\"] = [MockEntityModel, MockAOuthModel]\n        jwt = JwtRoutes(self.app, google_oauth=self.oauth_options, strategies=[GoogleTestUtil])\n        jwt.init_app()\n        assert jwt.config.entity_models[1] == MockAOuthModel\n        assert jwt.config.google_oauth[\"client_id\"] == \"<CLIENT_ID>\"\n        assert jwt.config.google_oauth[\"client_secret\"] == \"<CLIENT_SECRET>\"\n        assert jwt.config.google_oauth[\"redirect_uri\"] == \"http://localhost:3000\"\n        assert jwt.config.google_oauth[\"tablename\"] == \"users\"\n        assert jwt.config.google_oauth[\"email_field\"] == \"email\"\n        assert jwt.config.google_oauth[\"expires_in\"] == 3600", "od": 0}
{"code": "def test_get_secret_key(self):\n        class App:\n            config = {\n                \"SECRET_KEY\": \"__TEST_SECRET__\",\n                \"JWT_EXPIRE_DAYS\": 3,\n            }\n\n            def before_request(self, t):\n                pass\n\n        app = App()\n        flask_jwt_router = JwtRoutes(app)\n\n        result = flask_jwt_router.config.secret_key\n        assert result == \"__TEST_SECRET__\"\n        assert flask_jwt_router.config.expire_days == 3\n        assert flask_jwt_router.exp == 3\n\n        class App:\n            config = {\n                \"SECRET_KEY\": \"__TEST_SECRET__\",\n                \"JWT_EXPIRE_DAYS\": 99,\n            }\n\n            def before_request(self, t):\n                pass\n\n        app = App()\n        flask_jwt_router_two = JwtRoutes(app)\n        result_two = flask_jwt_router_two.config.secret_key\n        assert result_two == \"__TEST_SECRET__\"\n        assert flask_jwt_router_two.config.expire_days == 99\n        assert flask_jwt_router_two.exp == 99", "od": 0}
{"code": "def test_set_exp(self):\n        flask_jwt_router = JwtRoutes()\n        flask_jwt_router.set_exp(expire_days=10)\n        assert flask_jwt_router.exp == 10\n        flask_jwt_router.set_exp()\n        assert flask_jwt_router.exp == 30", "od": 0}
{"code": "def test_get_entity_id(self):\n\n        flask_jwt_router = JwtRoutes()\n        result = flask_jwt_router.get_entity_id(entity_id=1)\n        assert result == 1\n        result_two = flask_jwt_router.get_entity_id()\n        assert result_two is None", "od": 0}
{"code": "def test_get_app_config(self):\n        white_list = [(\"POST\", \"/test\")]\n        class App:\n            config = {\n                \"SECRET_KEY\": \"__TEST_SECRET__\",\n                \"WHITE_LIST_ROUTES\": white_list\n            }\n        app = App()\n        flask_jwt_router = JwtRoutes()\n        config = flask_jwt_router.get_app_config(app)\n        assert config[\"WHITE_LIST_ROUTES\"] == white_list", "od": 0}
{"code": "def test_create_token(self):\n        class App:\n            config = {\n                \"SECRET_KEY\": \"__TEST_SECRET__\"\n            }\n            def before_request(self, t):\n                pass\n        app = App()\n        flask_jwt_router = JwtRoutes(app)\n\n        with pytest.raises(KeyError, match=r\"create_token.+\") as excinfo:\n            token = flask_jwt_router.create_token(entity_id=1)", "od": 0}
{"code": "def test_set_expire_days(self):\n        jwt = JwtRoutes()\n        self.app.config[\"JWT_EXPIRE_DAYS\"] = 99\n        jwt.init_app(self.app)\n        assert jwt.config.expire_days == 99\n        assert jwt.exp == 99\n        jwt.set_exp(expire_days=22)\n        assert jwt.exp == 22", "od": 0}
{"code": "def test_get_strategy(self):\n        jwt = JwtRoutes()\n        jwt.init_app(self.app, google_oauth=self.oauth_options, strategies=[GoogleTestUtil])\n        strategy = jwt.get_strategy(\"GoogleTestUtil\")\n        assert isinstance(strategy, GoogleTestUtil)", "od": 0}
{"code": "def test_rule_without_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_without_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_without_fix\", self.TEST_INPUT)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 1)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 0)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 16)\n        self.assertEqual(reporter.messages[0].message, \"trailing whitespace\")\n        self.assertEqual(reporter.messages[0].code, \"trailing-whitespace\")", "od": 1}
{"code": "def test_rule_with_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_fix\", self.TEST_INPUT)\n\n        self.assertEqual(lines, self.FIXED_INPUT)", "od": 1}
{"code": "def test_rule_without_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_without_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_without_fix\", self.TEST_INPUT)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 1)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 0)\n        self.assertEqual(reporter.messages[0].message, \"lower or mixed case built-in type\")\n        self.assertEqual(reporter.messages[0].code, \"wrong-case-type\")", "od": 1}
{"code": "def test_rule_with_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_fix\", self.TEST_INPUT)\n\n        self.assertEqual(lines, self.FIXED_INPUT)", "od": 1}
{"code": "def test_rule_without_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_without_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_without_fix\", self.TEST_INPUT)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 3)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT)\n\n        self.assertEqual(reporter.messages[0].line_number, 1)\n        self.assertEqual(reporter.messages[0].column, 6)\n        self.assertEqual(reporter.messages[0].message, \"wrong indentation (found 6 spaces, exptected 3)\")\n        self.assertEqual(reporter.messages[0].code, \"bad-indentation\")\n\n        self.assertEqual(reporter.messages[1].line_number, 4)\n        self.assertEqual(reporter.messages[1].column, 3)\n        self.assertEqual(reporter.messages[1].message, \"wrong indentation (found 3 spaces, exptected 0)\")\n        self.assertEqual(reporter.messages[1].code, \"bad-indented-inline-form\")\n\n        self.assertEqual(reporter.messages[2].line_number, 5)\n        self.assertEqual(reporter.messages[2].column, 3)\n        self.assertEqual(reporter.messages[2].message, \"wrong indentation (found 3 spaces, exptected 0)\")\n        self.assertEqual(reporter.messages[2].code, \"bad-indented-inline-form\")", "od": 1}
{"code": "def test_rule_with_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_fix\", self.TEST_INPUT)\n\n        self.assertEqual(lines, self.FIXED_INPUT)", "od": 1}
{"code": "def test_rule_without_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_without_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_without_fix\", self.TEST_INPUT)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 1)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 0)\n        self.assertEqual(reporter.messages[0].message, \"complete open task (This is a open task)\")\n        self.assertEqual(reporter.messages[0].code, \"open-task\")", "od": 1}
{"code": "def test_rule_with_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_fix\", self.TEST_INPUT)\n\n        self.assertEqual(lines, self.TEST_INPUT)", "od": 1}
{"code": "def test_rule_without_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_without_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_without_fix\", self.TEST_INPUT)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 1)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 0)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 3)\n        self.assertEqual(reporter.messages[0].message, \"superfluous whitespace\")\n        self.assertEqual(reporter.messages[0].code, \"superfluous-whitespace\")", "od": 1}
{"code": "def test_rule_with_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_fix\", self.TEST_INPUT)\n\n        self.assertEqual(lines, self.FIXED_INPUT)", "od": 1}
{"code": "def test_rule_with_spaces_allowed(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_with_spaces_allowed\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        config.INDENT_CHAR = \" \"\n        config.DISABLE = [\"bad-indentation\"]\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_with_spaces_allowed\", self.TEST_INPUT_WITH_TABS)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 1)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT_WITH_TABS)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 0)\n        self.assertEqual(reporter.messages[0].message, \"line contains tab(s)\")\n        self.assertEqual(reporter.messages[0].code, \"mixed-indentation\")", "od": 0}
{"code": "def test_rule_with_tabs_allowed(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_with_tabs_allowed\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        config.INDENT_CHAR = \"\\t\"\n        config.DISABLE = [\"bad-indentation\"]\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_with_tabs_allowed\", self.TEST_INPUT_WITH_SPACES)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 1)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT_WITH_SPACES)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 0)\n        self.assertEqual(reporter.messages[0].message, \"line contains tab(s)\")\n        self.assertEqual(reporter.messages[0].code, \"mixed-indentation\")", "od": 0}
{"code": "def test_rule_with_tabs_allowed_and_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_tabs_allowed_and_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        config.INDENT_CHAR = \"\\t\"\n        config.INDENT_SIZE = 1\n        config.DISABLE = [\"bad-indentation\"]\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_tabs_allowed_and_fix\", self.TEST_INPUT_WITH_SPACES)\n\n        self.assertEqual(lines, self.TEST_RESULT_WITH_TABS)", "od": 0}
{"code": "def test_rule_with_spaces_allowed_and_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_spaces_allowed_and_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        config.INDENT_CHAR = \" \"\n        config.INDENT_SIZE = 3\n        config.DISABLE = [\"bad-indentation\"]\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_spaces_allowed_and_fix\", self.TEST_INPUT_WITH_TABS)\n\n        self.assertEqual(lines, self.TEST_RESULT_WITH_SPACES)", "od": 0}
{"code": "def test_rule_without_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"test_rule_without_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, reporter = linter.lint_lines(\"test_rule_without_fix\", self.TEST_INPUT)\n\n        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)\n        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)\n        self.assertEqual(reporter.found_issues[Category.WARNING], 1)\n        self.assertEqual(reporter.found_issues[Category.ERROR], 0)\n        self.assertEqual(reporter.found_issues[Category.FATAL], 0)\n\n        self.assertEqual(lines, self.TEST_INPUT)\n\n        self.assertEqual(reporter.messages[0].line_number, 0)\n        self.assertEqual(reporter.messages[0].column, 0)\n        self.assertEqual(reporter.messages[0].message, \"lower or mixed case keyword\")\n        self.assertEqual(reporter.messages[0].code, \"wrong-case-keyword\")", "od": 1}
{"code": "def test_rule_with_fix(self):\n        cli_args = _create_arg_parser().parse_args([\"--fix\", \"test_rule_with_fix\"])\n        reload(config)\n        config.REPORTER = MemoryReporter\n        linter = Linter(cli_args, config)\n        lines, _ = linter.lint_lines(\"test_rule_with_fix\", self.TEST_INPUT)\n\n        self.assertEqual(lines, self.FIXED_INPUT)", "od": 1}
{"code": "def test_should_not_generate(self):\n        \"\"\" Should not generate when PYAUTODOC environ is not exists. \"\"\"\n        del os.environ['PYAUTODOC']\n\n        res = self.client.get('/')\n        self.assertEqual(res.status_code, 200)\n\n        return res", "od": 0}
{"code": "def test_not_generated(self):\n        \"\"\" Document file should not generated. \"\"\"\n        ret = os.path.exists(os.path.join(var_path, 'test_generate.md'))\n        self.assertFalse(ret)", "od": 0}
{"code": "def test_parse_response(self):\n        \"\"\" Should parse requests response. \"\"\"\n        params = {'message': 'foo'}\n        headers = {'content-type': 'application/json'}\n        req = self.create_request(url='http://localhost:5000/',\n                                  method='POST',\n                                  data=params,\n                                  headers=headers)\n\n        res = self.send(req, params, 'data/post.json')\n        self.autodoc.parse('POST /', res)\n\n        var = {\n            'describe': 'POST /',\n            'describe_separators': '======',\n            'target_url': 'http://localhost:5000/',\n            'status_code': 200,\n            'request': 'POST /',\n            'response_body': '{\\n  \"response\": \"create\"\\n}',\n            'response_content_type': 'application/json',\n            'params': '{\\n  \"message\": \"foo\"\\n}'\n        }\n        for k, v in iteritems(self.autodoc.vars[0]):\n            self.assertEqual(v, var[k])\n\n        self.autodoc.clear()", "od": 1}
{"code": "def test_parse_responses(self):\n        \"\"\" Should stack responses. \"\"\"\n        headers = {'content-type': 'application/json'}\n        req = self.create_request(url='http://localhost:5000/',\n                                  method='GET',\n                                  headers=headers)\n\n        res = self.send(req, '', 'data/get.json')\n        self.autodoc.parse('GET /', res)\n        self.autodoc.parse('GET /', res)\n        var = {\n            'response_content_type': 'application/json',\n            'response_body': '{\\n  \"response\": \"index\"\\n}',\n            'describe': 'GET /',\n            'request': 'GET /',\n            'params': '',\n            'status_code': 200,\n            'target_url': 'http://localhost:5000/',\n            'describe_separators': '====='\n        }\n        vars = [var, var]\n        self.assertEqual(self.autodoc.vars, vars)\n        self.autodoc.clear()", "od": 1}
{"code": "def test_clear_responses(self):\n        \"\"\" Should clear stacked WebTest responses. \"\"\"\n        headers = {'content-type': 'application/json'}\n        req = self.create_request(url='http://localhost:5000/',\n                                  method='GET',\n                                  headers=headers)\n\n        res = self.send(req, '', 'data/get.json')\n\n        self.autodoc.parse('GET /', res)\n        self.autodoc.parse('GET /', res)\n        self.autodoc.clear()\n        self.assertEqual(self.autodoc.vars, [])", "od": 0}
{"code": "def test_create_document(self):\n        \"\"\" Should create reST document. \"\"\"\n        headers = {'content-type': 'application/json'}\n        req = self.create_request(url='http://localhost:5000/',\n                                  method='GET',\n                                  headers=headers)\n\n        res = self.send(req, '', 'data/get.json')\n\n        self.autodoc.parse('GET /', res)\n        self.autodoc.create_document(os.path.join(self.root_path,\n                                                  'var/test_autodoc.rst'))\n        self.assertTrue(os.path.exists(os.path.join(self.root_path,\n                                                    'var/test_autodoc.rst')))\n        self.autodoc.clear()", "od": 1}
{"code": "def test_create_markdown_document(self):\n        \"\"\" Should create markdown document. \"\"\"\n        headers = {'content-type': 'application/json'}\n        req = self.create_request(url='http://localhost:5000/',\n                                  method='GET',\n                                  headers=headers)\n        res = self.send(req, '', 'data/get.json')\n\n        self.autodoc.parse('GET /', res)\n        self.autodoc.template_path = os.path.join(self.root_path,\n                                                  'templates/markdown.md')\n        output = os.path.join(self.root_path, 'var/test_autodoc.md')\n        self.autodoc.create_document(output)\n        ret = os.path.exists(output)\n        self.assertTrue(ret)\n        self.autodoc.clear()", "od": 0}
{"code": "def test_should_change_separators(self):\n        \"\"\" Should change separators. \"\"\"\n        headers = {'content-type': 'application/json'}\n        req = self.create_request(url='http://localhost:5000/',\n                                  method='GET',\n                                  headers=headers)\n        res = self.send(req, '', 'data/get.json')\n\n        self.autodoc.separators = '*'\n        self.autodoc.parse('GET /', res)\n        var = {\n            'response_content_type': 'application/json',\n            'response_body': '{\\n  \"response\": \"index\"\\n}',\n            'describe': 'GET /',\n            'request': 'GET /',\n            'params': '',\n            'status_code': 200,\n            'target_url': 'http://localhost:5000/',\n            'describe_separators': '*****'\n        }\n        for k, v in iteritems(self.autodoc.vars[0]):\n            self.assertEqual(v, var[k])\n\n        self.autodoc.clear()", "od": 1}
{"code": "def test_parse_response(self):\n        \"\"\" Should parse WebTest response. \"\"\"\n        res = self.client.post_json('/', params={'message': 'foo'})\n        autodoc.parse('POST /', res)\n\n        var = {\n            'describe': 'POST /',\n            'describe_separators': '======',\n            'target_url': 'http://localhost:80',\n            'status_code': 200,\n            'request': 'POST /',\n            'response_body': '{\\n  \"response\": \"create\"\\n}',\n            'response_content_type': 'application/json',\n            'params': '{\\n  \"message\": \"foo\"\\n}'\n        }\n        for k, v in iteritems(autodoc.vars[0]):\n            self.assertEqual(v, var[k])\n\n        autodoc.clear()", "od": 1}
{"code": "def test_parse_responses(self):\n        \"\"\" Should stack responses. \"\"\"\n        res = self.client.get('/')\n        autodoc.parse('GET /', res)\n        autodoc.parse('GET /', res)\n        var = {\n            'response_content_type': 'application/json',\n            'response_body': '{\\n  \"response\": \"index\"\\n}',\n            'describe': 'GET /',\n            'request': 'GET /',\n            'params': '',\n            'status_code': 200,\n            'target_url': 'http://localhost:80',\n            'describe_separators': '====='\n        }\n        vars = [var, var]\n        self.assertEqual(autodoc.vars, vars)\n        autodoc.clear()", "od": 1}
{"code": "def test_clear_responses(self):\n        \"\"\" Should clear stacked WebTest responses. \"\"\"\n        res = self.client.get('/')\n        autodoc.parse('GET /', res)\n        autodoc.parse('GET /', res)\n        autodoc.clear()\n        self.assertEqual(autodoc.vars, [])", "od": 0}
{"code": "def test_create_document(self):\n        \"\"\" Should create reST document. \"\"\"\n        res = self.client.get('/')\n        autodoc.parse('GET /', res)\n        autodoc.create_document(os.path.join(self.root_path,\n                                             'var/test_autodoc.rst'))\n        self.assertTrue(os.path.exists(os.path.join(self.root_path,\n                                                    'var/test_autodoc.rst')))\n        autodoc.clear()", "od": 1}
{"code": "def test_create_markdown_document(self):\n        \"\"\" Should create markdown document. \"\"\"\n        res = self.client.get('/')\n        autodoc.parse('GET /', res)\n        autodoc.template_path = os.path.join(self.root_path,\n                                             'templates/markdown.md')\n        output = os.path.join(self.root_path, 'var/test_autodoc.md')\n        autodoc.create_document(output)\n        ret = os.path.exists(output)\n        self.assertTrue(ret)\n        autodoc.clear()", "od": 0}
{"code": "def test_should_change_separators(self):\n        \"\"\" Should change separators. \"\"\"\n        res = self.client.get('/')\n        autodoc.separators = '*'\n        autodoc.parse('GET /', res)\n        var = {\n            'response_content_type': 'application/json',\n            'response_body': '{\\n  \"response\": \"index\"\\n}',\n            'describe': 'GET /',\n            'request': 'GET /',\n            'params': '',\n            'status_code': 200,\n            'target_url': 'http://localhost:80',\n            'describe_separators': '*****'\n        }\n        for k, v in iteritems(autodoc.vars[0]):\n            self.assertEqual(v, var[k])\n\n        autodoc.clear()", "od": 1}
{"code": "def test_should_parse_get_request_result(self):\n        \"\"\" Should parse WebTest GET response. \"\"\"\n        WebTestResponse = self._getTarget()\n        res = self.client.get('/')\n        ret = WebTestResponse().parse(res)\n        var = {\n            'status_code': 200,\n            'response_body': '{\\n  \"response\": \"index\"\\n}',\n            'response_content_type': 'application/json',\n            'request': 'GET /',\n            'params': '',\n            'target_url': 'http://localhost:80'\n        }\n        self.assertEqual(ret, var)", "od": 0}
{"code": "def test_should_parse_post_request_result(self):\n        \"\"\" Should parse WebTest POST response. \"\"\"\n        WebTestResponse = self._getTarget()\n        res = self.client.post_json('/', params={'message': 'foo'})\n        ret = WebTestResponse().parse(res)\n        var = {\n            'target_url': 'http://localhost:80',\n            'status_code': 200,\n            'request': 'POST /',\n            'response_body': '{\\n  \"response\": \"create\"\\n}',\n            'response_content_type': 'application/json',\n            'params': '{\\n  \"message\": \"foo\"\\n}'\n        }\n        self.assertEqual(ret, var)", "od": 0}
{"code": "def test_get_dbs(self, mock_sp, client: DbsModule):\n        mock_sp.return_value = DbMock('get_dbs')\n\n        response = client.get_dbs()\n\n        assert len(response) == 2", "od": 0}
{"code": "def test_create_db(self, mock_sp, client: DbsModule, shared):\n        mock_sp.return_value = DbMock('get_db')\n        db_data = DbMock.create_db()['data']\n\n        response = client.create_db(**db_data)\n\n        assert response.name == db_data['name']\n        shared['db'] = response", "od": 0}
{"code": "def test_get_db(self, mock_sp, client: DbsModule, shared):\n        db = shared['db']\n        mock_sp.return_value = DbMock('get_db')\n\n        response = client.get_db(db.id)\n\n        assert response.id == db.id\n        assert response.appid == db.appid\n        assert response.serverid == db.serverid", "od": 1}
{"code": "def test_fail_create_db(self, mock_sp, client: DbsModule):\n        with pytest.raises(ValidationError):\n            client.create_db()  # no params error\n\n            client.create_db(appid='app',\n                             name='database!',  # name contains invalid characters\n                             user={})\n\n            client.create_db(appid='app',\n                             name='database',\n                             user={\n                                 'name': 'superlongnameshouldbeinvalid',  # invalid username\n                                 'password': 'BaOWYl3IjMc4raBe'\n                             })\n\n            client.create_db(appid='app',\n                             name='database',\n                             user={\n                                 'name': 'username',\n                                 'password': 'passwd',  # invalid password\n                             })\n\n            client.create_db(appid='app',\n                             name='database',\n                             user={\n                                 'name': 'username',\n                                 'password': 'BaOWYl3IjMc4raBe',\n                                 'hello': 'extraparam'  # extra invalid param\n                             })", "od": 0}
{"code": "def test_update_db(self, mock_sp, client: DbsModule, shared):\n        db = shared['db']\n\n        with pytest.raises(ValidationError):\n            client.update_db(db.id)  # no params error\n\n            client.update_db(db.id, user={})  # invalid user schema\n\n            client.update_db(db.id,\n                             user={\n                                 'name': 'superlongnameshouldbeinvalid',  # invalid username\n                                 'password': 'BaOWYl3IjMc4raBe'\n                             })\n\n            client.update_db(db.id,\n                             user={\n                                 'name': 'username',\n                                 'password': 'passw',  # invalid password\n                             })\n\n            client.update_db(db.id,\n                             user={\n                                 'name': 'username',\n                                 'password': 'BaOWYl3IjMc4raBe',\n                                 'hello': 'extraparam'  # extra invalid param\n                             })\n\n        new_user = {\n            'name': 'jerry',\n            'password': 'BaOWYl3IjMc4raBe'\n        }\n\n        mock_sp.return_value = DbMock('update_db')\n        client.update_db(db.id, user=new_user)\n\n        mock_sp.return_value = DbMock('update_db')\n\n        response = client.get_db(shared['db'].id)\n\n        assert response.user['name'] == new_user['name']", "od": 1}
{"code": "def test_create_app(self, mock_sp, client: AppsModule, shared):\n        mock_sp.return_value = AppMock('get_app')\n        app_data = AppMock.create_app()['data']\n\n        response = client.create_app(**app_data)\n        assert response.name == app_data['name']\n        shared['app'] = response", "od": 0}
{"code": "def test_get_app(self, mock_sp, client: AppsModule, shared):\n        mock_sp.return_value = AppMock('get_app')\n        app = shared['app']\n\n        response = client.get_app(app.id)\n        assert response.id == app.id", "od": 1}
{"code": "def test_app_create_validation(self, mock_sp, client: AppsModule):\n        with pytest.raises(ValidationError):\n            client.create_app()  # no parameters\n\n            client.create_app(**AppMock.create_app(), unknown_param='should trigger error')  # unknown parameters\n\n            client.create_app(name='app',\n                              sysuserid='userid',\n                              runtime='php7.1',\n                              domains='should trigger error')  # invalid parameter type\n\n            client.create_app(name='app',\n                              sysuserid='userid',\n                              runtime='php7.1',\n                              domains=['website.com', 'www.website.com'],\n                              wordpress={})  # invalid worpdress fields\n\n            client.create_app(name='app',\n                              sysuserid='userid',\n                              runtime='php7.1',\n                              domains=['website.com', 'www.website.com'],\n                              wordpress={\n                                  'site_title': 'Awesome site',\n                                  'admin_user': 'admin',\n                                  'admin_password': 'fail',  # should fail because of invalid password\n                                  'admin_email': 'admin@website.com'\n                              })\n\n        mock_sp.return_value = AppMock('')\n        client.create_app(name='app',\n                          sysuserid='userid',\n                          runtime='php7.1',\n                          domains=['website.com', 'www.website.com'],\n                          wordpress={\n                              'site_title': 'Awesome site',\n                              'admin_user': 'admin',\n                              'admin_password': 'shouldnotfail',\n                              'admin_email': 'admin@website.com'\n                          })", "od": 0}
{"code": "def test_update_app_validation(self, mock_sp, client: AppsModule, shared):\n        app = shared['app']  # type: AppModel\n\n        with pytest.raises(ValidationError):\n            client.update_app(app.id, domains=\"website.com\")  # invalid parameter type\n\n        mock_sp.return_value = AppMock('update_app')\n        response = client.update_app(app.id, domains=['www.myshop.com', 'myshop.com'], runtime='php7.1')\n\n        assert response.id == app.id\n        assert response.runtime == 'php7.2'", "od": 1}
{"code": "def test_add_ssl(self, mock_sp, client: AppsModule, shared):\n        app = shared['app']  # type: AppModel\n\n        with pytest.raises(ValidationError):\n            client.add_ssl(app.id)  # missing params\n\n            client.add_ssl(app.id, key=123, cert='sslcert', cacerts='sslcacert')  # invalid parameter type\n\n        mock_sp.return_value = AppMock('add_ssl')\n        response = client.add_ssl(app.id, key='sslkey', cert='sslcert', cacerts=None)\n\n        assert response.key == 'sslkey'\n        assert response.cert == 'sslcert'\n\n        app.ssl = response", "od": 1}
{"code": "def test_enable_force_ssl(self, mock_sp, client: AppsModule, shared):\n        app = shared['app']  # type: AppModel\n\n        with pytest.raises(ValidationError):\n            client.set_force_ssl(app.id)\n\n            client.set_force_ssl(app.id, force=\"yes\")  # invalid parameter type\n\n        mock_sp.return_value = AppMock('set_force_ssl')\n        response = client.set_force_ssl(app.id, force=True)\n\n        assert response.key == app.ssl.key\n        assert response.force is True", "od": 0}
{"code": "def test_verbose(self, optimizer, capsys):\n        \"\"\"Test verbose run\"\"\"\n        optm, params = optimizer\n        opt = optm(**params)\n        opt.optimize(fx.sphere, iters=100)\n        out = capsys.readouterr().err\n        count = len(re.findall(r\"pyswarms\", out))\n        assert count > 0", "od": 0}
{"code": "def test_silent(self, optimizer, capsys):\n        \"\"\"Test silent run\"\"\"\n        optm, params = optimizer\n        opt = optm(**params)\n        opt.optimize(fx.sphere, iters=100, verbose=False)\n        out = capsys.readouterr()\n        assert out.err == \"\"\n        assert out.out == \"\"", "od": 0}
{"code": "def test_train_history(self, optimizer_history, history, expected_shape):\n        \"\"\"Test if training histories are of expected shape\"\"\"\n        opt = vars(optimizer_history)\n        assert np.array(opt[history]).shape == expected_shape", "od": 0}
{"code": "def test_reset_default_values(self, optimizer_reset):\n        \"\"\"Test if best cost and best pos are set properly when the reset()\n        method is called\"\"\"\n        assert optimizer_reset.swarm.best_cost == np.inf\n        assert set(optimizer_reset.swarm.best_pos) == set(np.array([]))", "od": 0}
{"code": "def test_ftol_effect(self, options, optimizer):\n        \"\"\"Test if setting the ftol breaks the optimization process\"\"\"\n        opt = optimizer(10, 2, options=options, ftol=1e-1)\n        opt.optimize(sphere, 2000)\n        assert np.array(opt.cost_history).shape != (2000,)", "od": 1}
{"code": "def test_parallel_evaluation(self, obj_without_args, optimizer, options):\n        \"\"\"Test if parallelization breaks the optimization process\"\"\"\n        import multiprocessing\n\n        opt = optimizer(100, 2, options=options)\n        opt.optimize(\n            obj_without_args, 2000, n_processes=multiprocessing.cpu_count()\n        )\n        assert np.array(opt.cost_history).shape == (2000,)", "od": 0}
{"code": "def test_obj_with_kwargs(self, obj_with_args, optimizer, options):\n        \"\"\"Test if kwargs are passed properly in objfunc\"\"\"\n        x_max = 10 * np.ones(2)\n        x_min = -1 * x_max\n        bounds = (x_min, x_max)\n        opt = optimizer(100, 2, options=options, bounds=bounds)\n        cost, pos = opt.optimize(obj_with_args, 1000, a=1, b=100)\n        assert np.isclose(cost, 0, rtol=1e-03)\n        assert np.isclose(pos[0], 1.0, rtol=1e-03)\n        assert np.isclose(pos[1], 1.0, rtol=1e-03)", "od": 0}
{"code": "def test_obj_unnecessary_kwargs(\n        self, obj_without_args, optimizer, options\n    ):\n        \"\"\"Test if error is raised given unnecessary kwargs\"\"\"\n        x_max = 10 * np.ones(2)\n        x_min = -1 * x_max\n        bounds = (x_min, x_max)\n        opt = optimizer(100, 2, options=options, bounds=bounds)\n        with pytest.raises(TypeError):\n            # kwargs `a` should not be supplied\n            cost, pos = opt.optimize(obj_without_args, 1000, a=1)", "od": 0}
{"code": "def test_obj_missing_kwargs(self, obj_with_args, optimizer, options):\n        \"\"\"Test if error is raised with incomplete kwargs\"\"\"\n        x_max = 10 * np.ones(2)\n        x_min = -1 * x_max\n        bounds = (x_min, x_max)\n        opt = optimizer(100, 2, options=options, bounds=bounds)\n        with pytest.raises(TypeError):\n            # kwargs `b` is missing here\n            cost, pos = opt.optimize(obj_with_args, 1000, a=1)", "od": 0}
{"code": "def test_obj_incorrect_kwargs(self, obj_with_args, optimizer, options):\n        \"\"\"Test if error is raised with wrong kwargs\"\"\"\n        x_max = 10 * np.ones(2)\n        x_min = -1 * x_max\n        bounds = (x_min, x_max)\n        opt = optimizer(100, 2, options=options, bounds=bounds)\n        with pytest.raises(TypeError):\n            # Wrong kwargs\n            cost, pos = opt.optimize(obj_with_args, 1000, c=1, d=100)", "od": 0}
{"code": "def test_global_correct_pos(self, options):\n        \"\"\" Test to check global optimiser returns the correct position corresponding to the best cost \"\"\"\n        opt = GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n        cost, pos = opt.optimize(sphere, iters=5)\n        # find best pos from history\n        min_cost_idx = np.argmin(opt.cost_history)\n        min_pos_idx = np.argmin(sphere(opt.pos_history[min_cost_idx]))\n        assert np.array_equal(opt.pos_history[min_cost_idx][min_pos_idx], pos)", "od": 0}
{"code": "def test_local_correct_pos(self, options):\n        \"\"\" Test to check local optimiser returns the correct position corresponding to the best cost \"\"\"\n        opt = LocalBestPSO(n_particles=10, dimensions=2, options=options)\n        cost, pos = opt.optimize(sphere, iters=5)\n        # find best pos from history\n        min_cost_idx = np.argmin(opt.cost_history)\n        min_pos_idx = np.argmin(sphere(opt.pos_history[min_cost_idx]))\n        assert np.array_equal(opt.pos_history[min_cost_idx][min_pos_idx], pos)", "od": 0}
{"code": "def test_no_ftol(self, optimizer):\n        \"\"\"Test complete run\"\"\"\n        optm, params = optimizer\n        opt = optm(**params)\n        opt.optimize(objective_function, iters=iterations, **kwargs)\n        assert len(opt.cost_history) == iterations", "od": 1}
{"code": "def test_ftol_effect(self, optimizer):\n        \"\"\"Test early stopping with ftol\"\"\"\n        optm, params = optimizer\n        params[\"ftol\"] = 0.01\n        opt = optm(**params)\n        opt.optimize(objective_function, iters=iterations, **kwargs)\n        assert len(opt.cost_history) <= iterations", "od": 1}
{"code": "def test_ftol_iter_assertion(self, optimizer):\n        \"\"\"Assert ftol_iter type and value\"\"\"\n        with pytest.raises(AssertionError):\n            optm, params = optimizer\n            params[\"ftol_iter\"] = 0\n            opt = optm(**params)", "od": 0}
{"code": "def test_ftol_iter_effect(self, optimizer):\n        \"\"\"Test early stopping with ftol and ftol_iter;\n        must run for a minimum of ftol_iter iterations\"\"\"\n        optm, params = optimizer\n        params[\"ftol_iter\"] = 50\n        opt = optm(**params)\n        opt.optimize(objective_function, iters=iterations, **kwargs)\n        assert len(opt.cost_history) >= opt.ftol_iter", "od": 0}
{"code": "def test_binary_correct_pos(self, options):\n        \"\"\"Test to check binary optimiser returns the correct position\n        corresponding to the best cost\"\"\"\n        opt = BinaryPSO(10, 2, options=options)\n        cost, pos = opt.optimize(sphere, 10)\n        # find best pos from history\n        min_cost_idx = np.argmin(opt.cost_history)\n        min_pos_idx = np.argmin(sphere(opt.pos_history[min_cost_idx]))\n        assert np.array_equal(opt.pos_history[min_cost_idx][min_pos_idx], pos)", "od": 0}
{"code": "def test_obj_with_kwargs(self, obj_with_args, optimizer, options):\n        \"\"\"Test if kwargs are passed properly in objfunc\"\"\"\n        opt = optimizer(100, 2, options=options)\n        cost, pos = opt.optimize(obj_with_args, 1000, a=1, b=100)\n        assert np.isclose(cost, 0, rtol=1e-03)\n        assert np.isclose(pos[0], 1.0, rtol=1e-03)\n        assert np.isclose(pos[1], 1.0, rtol=1e-03)", "od": 0}
{"code": "def test_obj_unnecessary_kwargs(\n        self, obj_without_args, optimizer, options\n    ):\n        \"\"\"Test if error is raised given unnecessary kwargs\"\"\"\n        opt = optimizer(100, 2, options=options)\n        with pytest.raises(TypeError):\n            # kwargs `a` should not be supplied\n            cost, pos = opt.optimize(obj_without_args, 1000, a=1)", "od": 0}
{"code": "def test_obj_missing_kwargs(self, obj_with_args, optimizer, options):\n        \"\"\"Test if error is raised with incomplete kwargs\"\"\"\n        opt = optimizer(100, 2, options=options)\n        with pytest.raises(TypeError):\n            # kwargs `b` is missing here\n            cost, pos = opt.optimize(obj_with_args, 1000, a=1)", "od": 0}
{"code": "def test_obj_incorrect_kwargs(self, obj_with_args, optimizer, options):\n        \"\"\"Test if error is raised with wrong kwargs\"\"\"\n        opt = optimizer(100, 2, options=options)\n        with pytest.raises(TypeError):\n            # Wrong kwargs\n            cost, pos = opt.optimize(obj_with_args, 1000, c=1, d=100)", "od": 0}
{"code": "def test_ftol_effect(self, optimizer):\n        \"\"\"Test if setting the ftol breaks the optimization process\"\"\"\n        # Set optimizer tolerance\n        optimizer.ftol = 1e-1\n        optimizer.optimize(sphere, 2000)\n        assert np.array(optimizer.cost_history).shape != (2000,)", "od": 1}
{"code": "def test_parallel_evaluation(self, obj_without_args, optimizer):\n        \"\"\"Test if parallelization breaks the optimization process\"\"\"\n        import multiprocessing\n\n        optimizer.optimize(\n            obj_without_args, 2000, n_processes=multiprocessing.cpu_count()\n        )\n        assert np.array(optimizer.cost_history).shape == (2000,)", "od": 0}
{"code": "def test_obj_with_kwargs(self, obj_with_args, optimizer):\n        \"\"\"Test if kwargs are passed properly in objfunc\"\"\"\n        cost, pos = optimizer.optimize(obj_with_args, 1000, a=1, b=100)\n        assert np.isclose(cost, 0, rtol=1e-03)\n        assert np.isclose(pos[0], 1.0, rtol=1e-03)\n        assert np.isclose(pos[1], 1.0, rtol=1e-03)", "od": 0}
{"code": "def test_obj_unnecessary_kwargs(self, obj_without_args, optimizer):\n        \"\"\"Test if error is raised given unnecessary kwargs\"\"\"\n        with pytest.raises(TypeError):\n            # kwargs `a` should not be supplied\n            cost, pos = optimizer.optimize(obj_without_args, 1000, a=1)", "od": 0}
{"code": "def test_obj_missing_kwargs(self, obj_with_args, optimizer):\n        \"\"\"Test if error is raised with incomplete kwargs\"\"\"\n        with pytest.raises(TypeError):\n            # kwargs `b` is missing here\n            cost, pos = optimizer.optimize(obj_with_args, 1000, a=1)", "od": 0}
{"code": "def test_obj_incorrect_kwargs(self, obj_with_args, optimizer):\n        \"\"\"Test if error is raised with wrong kwargs\"\"\"\n        with pytest.raises(TypeError):\n            # Wrong kwargs\n            cost, pos = optimizer.optimize(obj_with_args, 1000, c=1, d=100)", "od": 0}
{"code": "def test_general_correct_pos(self, options, optimizer):\n        \"\"\" Test to check general optimiser returns the correct position corresponding to the best cost \"\"\"\n        cost, pos = optimizer.optimize(sphere, iters=5)\n        # find best pos from history\n        min_cost_idx = np.argmin(optimizer.cost_history)\n        min_pos_idx = np.argmin(sphere(optimizer.pos_history[min_cost_idx]))\n        assert np.array_equal(\n            optimizer.pos_history[min_cost_idx][min_pos_idx], pos\n        )", "od": 0}
{"code": "def test_ftol_iter_effect(self, optimizer):\n        \"\"\"Test if setting the ftol breaks the optimization process after the set number of iterations\"\"\"\n        # Set optimizer tolerance\n        optimizer.ftol = 1e-1\n        optimizer.ftol_iter = 5\n        optimizer.optimize(sphere, 2000)\n        assert np.array(optimizer.cost_history).shape[0] >= optimizer.ftol_iter", "od": 0}
{"code": "def test_creating_event_without_user_id_throws(self):\n        with self.assertRaises(SecureNativeInvalidOptionsException):\n            event_options = EventOptions(EventTypes.LOG_IN, None)\n            options = SecureNativeOptions()\n\n            SDKEvent(event_options, options)", "od": 0}
{"code": "def test_creating_event_without_event_type_throws(self):\n        with self.assertRaises(SecureNativeInvalidOptionsException):\n            event_options = EventOptions(None, \"1234\")\n            options = SecureNativeOptions()\n\n            SDKEvent(event_options, options)", "od": 0}
{"code": "def test_parse_config_file_correctly(self):\n        self.clean_settings()\n        config = {\n            \"SECURENATIVE_API_KEY\": \"SOME_API_KEY\",\n            \"SECURENATIVE_APP_NAME\": \"SOME_APP_NAME\",\n            \"SECURENATIVE_API_URL\": \"SOME_API_URL\",\n            \"SECURENATIVE_INTERVAL\": \"1000\",\n            \"SECURENATIVE_HEARTBEAT_INTERVAL\": \"5000\",\n            \"SECURENATIVE_MAX_EVENTS\": \"100\",\n            \"SECURENATIVE_TIMEOUT\": \"1500\",\n            \"SECURENATIVE_AUTO_SEND\": \"True\",\n            \"SECURENATIVE_DISABLE\": \"False\",\n            \"SECURENATIVE_LOG_LEVEL\": \"Critical\",\n            \"SECURENATIVE_FAILOVER_STRATEGY\": \"fail-closed\",\n            \"SECURENATIVE_PROXY_HEADERS\": \"CF-Connecting-IP,Some-Random-Ip\",\n            \"SECURENATIVE_PII_HEADERS\": \"authentication,api_key\",\n            \"SECURENATIVE_PII_REGEX_PATTERN\": \"/auth/i\"\n        }\n\n        self.create_ini_file(config)\n        options = ConfigurationManager.load_config(None)\n\n        self.assertIsNotNone(options)\n        self.assertEqual(options.api_key, \"SOME_API_KEY\")\n        self.assertEqual(options.api_url, \"SOME_API_URL\")\n        self.assertEqual(options.auto_send, \"True\")\n        self.assertEqual(options.disable, \"False\")\n        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_CLOSED.value)\n        self.assertEqual(options.interval, \"1000\")\n        self.assertEqual(options.log_level, \"Critical\")\n        self.assertEqual(options.max_events, \"100\")\n        self.assertEqual(options.timeout, \"1500\")\n        self.assertEqual(options.pii_regex_pattern, \"/auth/i\")\n        self.assertEqual(options.proxy_headers, [\"CF-Connecting-IP\", \"Some-Random-Ip\"])\n        self.assertEqual(options.pii_headers, [\"authentication\", \"api_key\"])", "od": 1}
{"code": "def test_ignore_unknown_config_in_properties_file(self):\n        self.clean_settings()\n        config = {\n            \"SECURENATIVE_TIMEOUT\": \"1500\",\n            \"SECURENATIVE_UNKNOWN_KEY\": \"SOME_UNKNOWN_KEY\"\n        }\n\n        self.create_ini_file(config)\n        options = ConfigurationManager.load_config(None)\n\n        self.assertIsNotNone(options)\n        self.assertEqual(options.timeout, \"1500\")", "od": 1}
{"code": "def test_handle_invalid_config_file(self):\n        self.clean_settings()\n        config = {\"bla\": \"bla\"}\n\n        self.create_ini_file(config)\n        options = ConfigurationManager.load_config(None)\n\n        self.assertIsNotNone(options)", "od": 0}
{"code": "def test_load_default_config(self):\n        self.clean_settings()\n        options = ConfigurationManager.load_config(None)\n\n        self.assertIsNotNone(options)\n        self.assertIsNone(options.api_key)\n        self.assertEqual(options.api_url, \"https://api.securenative.com/collector/api/v1\")\n        self.assertEqual(str(options.interval), \"1000\")\n        self.assertEqual(options.timeout, \"1500\")\n        self.assertEqual(str(options.max_events), \"1000\")\n        self.assertEqual(str(options.auto_send), \"True\")\n        self.assertEqual(str(options.disable), \"False\")\n        self.assertEqual(options.log_level, \"CRITICAL\")\n        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_OPEN.value)\n        self.assertEqual(len(options.proxy_headers), 0)", "od": 1}
{"code": "def test_get_config_from_env_variables(self):\n        self.clean_settings()\n\n        os.environ[\"SECURENATIVE_API_KEY\"] = \"SOME_ENV_API_KEY\"\n        os.environ[\"SECURENATIVE_API_URL\"] = \"SOME_API_URL\"\n        os.environ[\"SECURENATIVE_INTERVAL\"] = \"6000\"\n        os.environ[\"SECURENATIVE_MAX_EVENTS\"] = \"700\"\n        os.environ[\"SECURENATIVE_TIMEOUT\"] = \"1700\"\n        os.environ[\"SECURENATIVE_AUTO_SEND\"] = \"False\"\n        os.environ[\"SECURENATIVE_DISABLE\"] = \"True\"\n        os.environ[\"SECURENATIVE_LOG_LEVEL\"] = \"Debug\"\n        os.environ[\"SECURENATIVE_FAILOVER_STRATEGY\"] = \"fail-closed\"\n        os.environ[\"SECURENATIVE_PROXY_HEADERS\"] = \"CF-Connecting-IP\"\n\n        options = ConfigurationManager.load_config(None)\n\n        self.assertEqual(options.api_key, \"SOME_ENV_API_KEY\")\n        self.assertEqual(options.api_url, \"SOME_API_URL\")\n        self.assertEqual(options.interval, \"6000\")\n        self.assertEqual(options.timeout, \"1700\")\n        self.assertEqual(options.max_events, \"700\")\n        self.assertEqual(options.auto_send, \"False\")\n        self.assertEqual(options.disable, \"True\")\n        self.assertEqual(options.log_level, \"Debug\")\n        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_CLOSED.value)\n        self.assertEqual(options.proxy_headers, \"CF-Connecting-IP\")", "od": 1}
{"code": "def test_default_values_for_invalid_enum_config_props(self):\n        self.clean_settings()\n        config = {\n            \"SECURENATIVE_FAILOVER_STRATEGY\": \"fail-something\"\n        }\n\n        self.create_ini_file(config)\n        options = ConfigurationManager.load_config(None)\n\n        self.assertIsNotNone(options)\n        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_OPEN.value)", "od": 1}
{"code": "def test_create_context_from_request(self):\n        with requests_mock.Mocker(real_http=True) as request:\n            request.server_name = \"www.securenative.com\"\n            request.request_uri = \"/login\"\n            request.query_string = \"param1=value1&param2=value2\"\n            request.method = \"Post\"\n            request.url = \"www.securenative.com\"\n            request.request_uri = \"/login/param1=value1&param2=value2\"\n            request.META = {\n                \"REMOTE_ADDR\": \"51.68.201.122\"\n            }\n            request.headers = {\n                \"x-securenative\": \"71532c1fad2c7f56118f7969e401f3cf080239140d208e7934e6a530818c37e544a0c2330a487bcc6fe4f662a57f265a3ed9f37871e80529128a5e4f2ca02db0fb975ded401398f698f19bb0cafd68a239c6caff99f6f105286ab695eaf3477365bdef524f5d70d9be1d1d474506b433aed05d7ed9a435eeca357de57817b37c638b6bb417ffb101eaf856987615a77a\"}\n\n            context = SecureNativeContext.from_http_request(request, None)\n\n            self.assertEqual(context.client_token,\n                             \"71532c1fad2c7f56118f7969e401f3cf080239140d208e7934e6a530818c37e544a0c2330a487bcc6fe4f662a57f265a3ed9f37871e80529128a5e4f2ca02db0fb975ded401398f698f19bb0cafd68a239c6caff99f6f105286ab695eaf3477365bdef524f5d70d9be1d1d474506b433aed05d7ed9a435eeca357de57817b37c638b6bb417ffb101eaf856987615a77a\")\n            self.assertEqual(context.ip, \"51.68.201.122\")\n            self.assertEqual(context.method, \"Post\")\n            self.assertEqual(context.url, \"www.securenative.com\")\n            self.assertEqual(context.remote_ip, \"\")\n            self.assertEqual(context.headers, {\n                \"x-securenative\": \"71532c1fad2c7f56118f7969e401f3cf080239140d208e7934e6a530818c37e544a0c2330a487bcc6fe4f662a57f265a3ed9f37871e80529128a5e4f2ca02db0fb975ded401398f698f19bb0cafd68a239c6caff99f6f105286ab695eaf3477365bdef524f5d70d9be1d1d474506b433aed05d7ed9a435eeca357de57817b37c638b6bb417ffb101eaf856987615a77a\"})\n            self.assertIsNone(context.body)", "od": 0}
{"code": "def test_create_context_from_request_with_cookie(self):\n        with requests_mock.Mocker(real_http=True) as request:\n            request.server_name = \"www.securenative.com\"\n            request.request_uri = \"/login\"\n            request.query_string = \"param1=value1&param2=value2\"\n            request.method = \"Post\"\n            request.url = \"www.securenative.com\"\n            request.request_uri = \"/login/param1=value1&param2=value2\"\n            request.META = {\n                \"REMOTE_ADDR\": \"51.68.201.122\"\n            }\n            request.cookies = {\"_sn\":\n                                   \"71532c1fad2c7f56118f7969e401f3cf080239140d208e7934e6a530818c37e544a0c2330a487bcc6fe4f662a57f265a3ed9f37871e80529128a5e4f2ca02db0fb975ded401398f698f19bb0cafd68a239c6caff99f6f105286ab695eaf3477365bdef524f5d70d9be1d1d474506b433aed05d7ed9a435eeca357de57817b37c638b6bb417ffb101eaf856987615a77a\"}\n\n            context = SecureNativeContext.from_http_request(request, None)\n\n            self.assertEqual(context.client_token,\n                             \"71532c1fad2c7f56118f7969e401f3cf080239140d208e7934e6a530818c37e544a0c2330a487bcc6fe4f662a57f265a3ed9f37871e80529128a5e4f2ca02db0fb975ded401398f698f19bb0cafd68a239c6caff99f6f105286ab695eaf3477365bdef524f5d70d9be1d1d474506b433aed05d7ed9a435eeca357de57817b37c638b6bb417ffb101eaf856987615a77a\")\n            self.assertEqual(context.ip, \"51.68.201.122\")\n            self.assertEqual(context.method, \"Post\")\n            self.assertEqual(context.url, \"www.securenative.com\")\n            self.assertEqual(context.remote_ip, \"\")\n            self.assertIsNone(context.body)", "od": 0}
{"code": "def test_create_default_context_builder(self):\n        context = SecureNativeContext()\n\n        self.assertIsNone(context.client_token)\n        self.assertIsNone(context.ip)\n        self.assertIsNone(context.method)\n        self.assertIsNone(context.url)\n        self.assertIsNone(context.remote_ip)\n        self.assertIsNone(context.headers)\n        self.assertIsNone(context.body)", "od": 0}
{"code": "def test_create_custom_context_with_context_builder(self):\n        context = SecureNativeContext(\"SECRET_TOKEN\", \"10.0.0.0\", \"10.0.0.1\", {\"header1\": \"value1\"}, \"/some-url\", \"Get\",\n                                      \"{ \\\"name\\\": \\\"YOUR_NAME\\\" }\")\n\n        self.assertEqual(context.url, \"/some-url\")\n        self.assertEqual(context.client_token, \"SECRET_TOKEN\")\n        self.assertEqual(context.ip, \"10.0.0.0\")\n        self.assertEqual(context.body, \"{ \\\"name\\\": \\\"YOUR_NAME\\\" }\")\n        self.assertEqual(context.method, \"Get\")\n        self.assertEqual(context.remote_ip, \"10.0.0.1\")\n        self.assertEqual(context.headers, {\"header1\": \"value1\"})", "od": 0}
{"code": "def test_should_make_simple_post_call(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\", auto_send=True, interval=10,\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/track\",\n                      json={\"event\": \"SOME_EVENT_NAME\"}, status=200)\n        client = SecureNativeHttpClient(options)\n        payload = \"{\\\"event\\\": \\\"SOME_EVENT_NAME\\\"}\"\n\n        res = client.post(\"track\", payload)\n\n        self.assertEqual(res.ok, True)\n        self.assertEqual(res.status_code, 200)\n        self.assertEqual(res.text, payload)", "od": 0}
{"code": "def test_should_successfully_send_sync_event_with_status_code_200(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\",\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        res_body = \"{\\\"data\\\": true}\"\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/some-path/to-api\",\n                      json=json.loads(res_body), status=200)\n        event_manager = EventManager(options)\n\n        data = event_manager.send_sync(self.event, \"some-path/to-api\")\n        self.assertEqual(res_body, data.text)", "od": 0}
{"code": "def test_should_send_sync_event_and_fail_when_status_code_401(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\",\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/some-path/to-api\",\n                      json={}, status=401)\n        event_manager = EventManager(options)\n\n        res = event_manager.send_sync(self.event, \"some-path/to-api\")\n\n        self.assertEqual(res.status_code, 401)", "od": 0}
{"code": "def test_should_send_sync_event_and_fail_when_status_code_500(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\",\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/some-path/to-api\",\n                      json={}, status=500)\n        event_manager = EventManager(options)\n\n        res = event_manager.send_sync(self.event, \"some-path/to-api\")\n\n        self.assertEqual(res.status_code, 500)", "od": 0}
{"code": "def test_verify_request_payload(self):\n        signature = \"c4574c1748064735513697750c6223ff36b03ae3b85b160ce8788557d01e1d9d1c9cd942074323ee0061d3dcc8c94359c5acfa6eee8e2da095b3967b1a88ab73\"\n        payload = \"{\\\"id\\\":\\\"4a9157ffbd18cfbd73a57298\\\",\\\"type\\\":\\\"security-action\\\",\\\"flow\\\":{\\\"id\\\":\\\"62298c73a9bb433fbd1f75984a9157fd\\\",\\\"name\\\":\\\"Block user that violates geo velocity\\\"},\\\"userId\\\":\\\"73a9bb433fbd1f75984a9157\\\",\\\"userTraits\\\":{\\\"name\\\":\\\"John Doe\\\",\\\"email\\\":\\\"john.doe@gmail.com\\\"},\\\"request\\\":{\\\"ip\\\":\\\"10.0.0.0\\\",\\\"fp\\\":\\\"9bb433fb984a9157d1f7598\\\"},\\\"action\\\":\\\"block\\\",\\\"properties\\\":{\\\"type\\\":\\\"customer\\\"},\\\"timestamp\\\":\\\"2020-02-23T22:28:55.387Z\\\"}\"\n        secret_key = \"B00C42DAD33EAC6F6572DA756EA4915349C0A4F6\"\n\n        result = SignatureUtils.is_valid_signature(secret_key, payload, signature)\n        self.assertTrue(result)", "od": 0}
{"code": "def test_verify_request_empty_signature(self):\n        result = SignatureUtils.is_valid_signature(\"\", \"\", \"B00C42DAD33EAC6F6572DA756EA4915349C0A4F6\")\n        self.assertFalse(result)", "od": 0}
{"code": "def test_is_ip_address_valid_ipv4(self):\n        valid_ipv4 = \"172.16.254.1\"\n        self.assertTrue(IpUtils.is_ip_address(valid_ipv4))", "od": 0}
{"code": "def test_is_ip_address_valid_ipv6(self):\n        valid_ipv6 = \"2001:db8:1234:0000:0000:0000:0000:0000\"\n        self.assertTrue(IpUtils.is_ip_address(valid_ipv6))", "od": 0}
{"code": "def test_is_ip_address_invalid_ipv4(self):\n        invalid_ipv4 = \"172.16.2541\"\n        self.assertFalse(IpUtils.is_ip_address(invalid_ipv4))", "od": 0}
{"code": "def test_is_ip_address_invalid_ipv6(self):\n        invalid_ipv6 = \"2001:db8:1234:0000\"\n        self.assertFalse(IpUtils.is_ip_address(invalid_ipv6))", "od": 0}
{"code": "def test_is_valid_public_ip(self):\n        ip = \"64.71.222.37\"\n        self.assertTrue(IpUtils.is_valid_public_ip(ip))", "od": 0}
{"code": "def test_is_not_valid_public_ip(self):\n        ip = \"10.0.0.0\"\n        self.assertFalse(IpUtils.is_valid_public_ip(ip))", "od": 0}
{"code": "def test_is_valid_loopback_ip(self):\n        ip = \"127.0.0.1\"\n        self.assertTrue(IpUtils.is_loop_back(ip))", "od": 0}
{"code": "def test_to_timestamp(self):\n        iso_8601_date = \"2020-05-20T15:07:13Z\"\n        result = DateUtils.to_timestamp(iso_8601_date)\n\n        self.assertEqual(datetime.strptime(iso_8601_date, '%Y-%m-%dT%H:%M:%S.%f'[:-3] + 'Z'), result)", "od": 0}
{"code": "def test_decrypt(self):\n        encrypted_payload = \"5208ae703cc2fa0851347f55d3b76d3fd6035ee081d71a401e8bc92ebdc25d42440f62310bda60628537744ac03f200d78da9e61f1019ce02087b7ce6c976e7b2d8ad6aa978c532cea8f3e744cc6a5cafedc4ae6cd1b08a4ef75d6e37aa3c0c76954d16d57750be2980c2c91ac7ef0bbd0722abd59bf6be22493ea9b9759c3ff4d17f17ab670b0b6fc320e6de982313f1c4e74c0897f9f5a32d58e3e53050ae8fdbebba9009d0d1250fe34dcde1ebb42acbc22834a02f53889076140f0eb8db1\"\n        result = EncryptionUtils.decrypt(encrypted_payload, self.SECRET_KEY)\n\n        self.assertEqual(result.cid, self.CID)\n        self.assertEqual(result.fp, self.FP)", "od": 0}
{"code": "def test_get_sdk_instance_without_init_throws(self):\n        with self.assertRaises(SecureNativeSDKIllegalStateException):\n            SecureNative.get_instance()", "od": 0}
{"code": "def test_init_sdk_without_api_key_should_throw(self):\n        with self.assertRaises(SecureNativeSDKException):\n            SecureNative.init_with_options(SecureNativeOptions())", "od": 0}
{"code": "def test_init_sdk_with_empty_api_key_should_throw(self):\n        with self.assertRaises(SecureNativeConfigException):\n            SecureNativeSDKException, SecureNative.init_with_api_key(\"\")", "od": 0}
{"code": "def test_init_sdk_with_api_key_and_defaults(self):\n        SecureNative._flush()\n        api_key = \"API_KEY\"\n        securenative = SecureNative.init_with_api_key(api_key)\n        options = securenative.get_options()\n\n        self.assertEqual(options.api_key, api_key)\n        self.assertEqual(options.api_url, \"https://api.securenative.com/collector/api/v1\")\n        self.assertEqual(options.interval, 1000)\n        self.assertEqual(options.timeout, 1500)\n        self.assertEqual(options.max_events, 1000)\n        self.assertEqual(options.auto_send, True)\n        self.assertEqual(options.disable, False)\n        self.assertEqual(options.log_level, \"CRITICAL\")\n        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_OPEN.value)", "od": 0}
{"code": "def test_init_sdk_twice_will_throw(self):\n        with self.assertRaises(SecureNativeSDKException):\n            SecureNative.init_with_api_key(\"API_KEY\")\n            SecureNative.init_with_api_key(\"API_KEY\")", "od": 0}
{"code": "def test_init_sdk_with_api_key_and_get_instance(self):\n        SecureNative._flush()\n        api_key = \"API_KEY\"\n        securenative = SecureNative.init_with_api_key(api_key)\n\n        self.assertEqual(securenative, SecureNative.get_instance())", "od": 0}
{"code": "def test_init_sdk_with_options(self):\n        SecureNative._flush()\n        options = SecureNativeOptions(api_key=\"API_KEY\", log_level=\"ERROR\", max_events=10,\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n        securenative = SecureNative.init_with_options(options)\n\n        options = securenative.get_options()\n        self.assertEqual(options.api_key, \"API_KEY\")\n        self.assertEqual(options.max_events, 10)\n        self.assertEqual(options.log_level, \"ERROR\")", "od": 0}
{"code": "def test_version(self):\n        version = VersionUtils.get_version()\n\n        self.assertIsNotNone(version)", "od": 0}
{"code": "def test_track_event(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\", auto_send=True, interval=10,\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        expected = \"{\\\"eventType\\\":\\\"sn.user.login\\\",\\\"userId\\\":\\\"USER_ID\\\",\\\"userTraits\\\":{\" \\\n                   \"\\\"name\\\":\\\"USER_NAME\\\",\\\"email\\\":\\\"USER_EMAIL\\\",\\\"createdAt\\\":null},\\\"request\\\":{\" \\\n                   \"\\\"cid\\\":null,\\\"vid\\\":null,\\\"fp\\\":null,\\\"ip\\\":\\\"127.0.0.1\\\",\\\"remoteIp\\\":null,\\\"headers\\\":{\" \\\n                   \"\\\"user-agent\\\":\\\"Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) \" \\\n                   \"AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405\\\"},\\\"url\\\":null,\\\"method\\\":null},\" \\\n                   \"\\\"properties\\\":{\\\"prop2\\\":true,\\\"prop1\\\":\\\"CUSTOM_PARAM_VALUE\\\",\\\"prop3\\\":3}}\"\n\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/track\",\n                      json=json.loads(expected), status=200)\n        event_manager = EventManager(options)\n        event_manager.start_event_persist()\n        api_manager = ApiManager(event_manager, options)\n\n        try:\n            api_manager.track(self.event_options)\n        finally:\n            event_manager.stop_event_persist()", "od": 0}
{"code": "def test_should_timeout_on_post(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\", auto_send=True, timeout=0.000001,\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/verify\",\n                      json={\"event\": \"SOME_EVENT_NAME\"}, status=408)\n\n        event_manager = EventManager(options)\n        event_manager.start_event_persist()\n        api_manager = ApiManager(event_manager, options)\n\n        verify_result = VerifyResult(RiskLevel.LOW.value, 0, [])\n        res = api_manager.verify(self.event_options)\n\n        self.assertEqual(res.risk_level, verify_result.risk_level)\n        self.assertEqual(res.score, verify_result.score)\n        self.assertEqual(res.triggers, verify_result.triggers)", "od": 0}
{"code": "def test_verify_event(self):\n        options = SecureNativeOptions(api_key=\"YOUR_API_KEY\",\n                                      api_url=\"https://api.securenative-stg.com/collector/api/v1\")\n\n        responses.add(responses.POST, \"https://api.securenative-stg.com/collector/api/v1/verify\",\n                      json={\n                          \"riskLevel\": \"low\",\n                          \"score\": 0,\n                          \"triggers\": None\n                      }, status=200)\n        verify_result = VerifyResult(RiskLevel.LOW, 0, None)\n\n        event_manager = EventManager(options)\n        event_manager.start_event_persist()\n        api_manager = ApiManager(event_manager, options)\n\n        result = api_manager.verify(self.event_options)\n\n        self.assertIsNotNone(result)\n        self.assertEqual(result.risk_level, verify_result.risk_level.value)\n        self.assertEqual(result.score, verify_result.score)\n        self.assertEqual(result.triggers, verify_result.triggers)", "od": 0}
{"code": "def test_proxy_headers_extraction_from_request_ipv4(self):\n        options = SecureNativeOptions(proxy_headers=['CF-Connecting-IP'])\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"CF-Connecting-IP\": \"203.0.113.1\"}\n\n            client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n            self.assertEqual(\"203.0.113.1\", client_ip)", "od": 0}
{"code": "def test_proxy_headers_extraction_from_request_ipv6(self):\n        options = SecureNativeOptions(proxy_headers=['CF-Connecting-IP'])\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"CF-Connecting-IP\": \"6559:6335:f572:14c6:4198:dd09:ddea:04f4\"}\n\n            client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n            self.assertEqual(\"6559:6335:f572:14c6:4198:dd09:ddea:04f4\", client_ip)", "od": 0}
{"code": "def test_proxy_headers_extraction_from_request_multiple_ips(self):\n        options = SecureNativeOptions(proxy_headers=['CF-Connecting-IP'])\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"CF-Connecting-IP\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n            client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n            self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_HTTP_X_FORWARDED_FOR_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"HTTP_X_FORWARDED_FOR\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_HTTP_X_FORWARDED_FOR_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"HTTP_X_FORWARDED_FOR\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_X_FORWARDED_FOR_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"X_FORWARDED_FOR\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_X_FORWARDED_FOR_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"X_FORWARDED_FOR\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_REMOTE_ADDR_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"REMOTE_ADDR\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_REMOTE_ADDR_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"REMOTE_ADDR\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_forwarded_for_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-forwarded-for\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_forwarded_for_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-forwarded-for\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_client_ip_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-client-ip\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_client_ip_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-client-ip\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_real_ip_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-real-ip\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_real_ip_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-real-ip\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_forwarded_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-forwarded\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_forwarded_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-forwarded\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_cluster_client_ip_for_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-cluster-client-ip\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_x_cluster_client_ip_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-client-ip\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_forwarded_for_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"forwarded-for\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_forwarded_for_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"forwarded-for\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_forwarded_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"forwarded\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_forwarded_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"forwarded\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_via_for_header_single_ip(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"via\": \"141.246.115.116\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_from_via_header_multiple_ips(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"via\": \"141.246.115.116, 203.0.113.1, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"141.246.115.116\", client_ip)", "od": 0}
{"code": "def test_extraction_priority_with_x_forwarded_for(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-forwarded-for\": \"203.0.113.1\",\n                \"x-real-ip\": \"198.51.100.101\",\n                \"x-client-ip\": \"198.51.100.102\"\n            }\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"203.0.113.1\", client_ip)", "od": 0}
{"code": "def test_extraction_priority_without_x_forwarded_for(self):\n        options = SecureNativeOptions()\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = {\n                \"x-real-ip\": \"198.51.100.101\",\n                \"x-client-ip\": \"203.0.113.1, 141.246.115.116, 12.34.56.3\"}\n\n        client_ip = RequestUtils.get_client_ip_from_request(request, options)\n\n        self.assertEqual(\"203.0.113.1\", client_ip)", "od": 0}
{"code": "def test_strip_down_pii_data_from_headers(self):\n        headers = {\n            'Host': 'net.example.com',\n            'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.5) Gecko/20091102 Firefox/3.5.5 (.NET CLR 3.5.30729)',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n            'Accept-Language': 'en-us,en;q=0.5',\n            'Accept-Encoding': 'gzip,deflate',\n            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.7',\n            'Keep-Alive': '300',\n            'Connection': 'keep-alive',\n            'Cookie': 'PHPSESSID=r2t5uvjq435r4q7ib3vtdjq120',\n            'Pragma': 'no-cache',\n            'Cache-Control': 'no-cache',\n            'authorization': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'access_token': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'apikey': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'password': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'passwd': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'secret': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'api_key': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z'\n        }\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = headers\n\n        h = RequestUtils.get_headers_from_request(request.headers)\n\n        self.assertEqual(h.get('authorization'), None)\n        self.assertEqual(h.get('access_token'), None)\n        self.assertEqual(h.get('apikey'), None)\n        self.assertEqual(h.get('password'), None)\n        self.assertEqual(h.get('passwd'), None)\n        self.assertEqual(h.get('secret'), None)\n        self.assertEqual(h.get('api_key'), None)", "od": 0}
{"code": "def test_strip_down_pii_data_from_custom_headers(self):\n        headers = {\n            'Host': 'net.example.com',\n            'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.5) Gecko/20091102 Firefox/3.5.5 (.NET CLR 3.5.30729)',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n            'Accept-Language': 'en-us,en;q=0.5',\n            'Accept-Encoding': 'gzip,deflate',\n            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.7',\n            'Keep-Alive': '300',\n            'Connection': 'keep-alive',\n            'Cookie': 'PHPSESSID=r2t5uvjq435r4q7ib3vtdjq120',\n            'Pragma': 'no-cache',\n            'Cache-Control': 'no-cache',\n            'authorization': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'access_token': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'apikey': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'password': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'passwd': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'secret': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'api_key': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z'\n        }\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = headers\n\n        options = SecureNativeOptions(pii_headers=['authorization', 'access_token', 'apikey', 'password',\n                                                   'passwd', 'secret', 'api_key'])\n        h = RequestUtils.get_headers_from_request(request.headers, options)\n\n        self.assertEqual(h.get('authorization'), None)\n        self.assertEqual(h.get('access_token'), None)\n        self.assertEqual(h.get('apikey'), None)\n        self.assertEqual(h.get('password'), None)\n        self.assertEqual(h.get('passwd'), None)\n        self.assertEqual(h.get('secret'), None)\n        self.assertEqual(h.get('api_key'), None)", "od": 0}
{"code": "def test_strip_down_pii_data_from_regex_pattern(self):\n        headers = {\n            'Host': 'net.example.com',\n            'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.5) Gecko/20091102 Firefox/3.5.5 (.NET CLR 3.5.30729)',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n            'Accept-Language': 'en-us,en;q=0.5',\n            'Accept-Encoding': 'gzip,deflate',\n            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.7',\n            'Keep-Alive': '300',\n            'Connection': 'keep-alive',\n            'Cookie': 'PHPSESSID=r2t5uvjq435r4q7ib3vtdjq120',\n            'Pragma': 'no-cache',\n            'Cache-Control': 'no-cache',\n            'http_auth_authorization': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'http_auth_access_token': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'http_auth_apikey': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'http_auth_password': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'http_auth_passwd': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'http_auth_secret': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z',\n            'http_auth_api_key': 'ylSkZIjbdWybfs4fUQe9BqP0LH5Z'\n        }\n\n        with requests_mock.Mocker(real_http=True) as request:\n            request.headers = headers\n\n        options = SecureNativeOptions(pii_regex_pattern='((?i)(http_auth_)(\\w+)?)')\n        h = RequestUtils.get_headers_from_request(request.headers, options)\n\n        self.assertEqual(h.get('http_auth_authorization'), None)\n        self.assertEqual(h.get('http_auth_access_token'), None)\n        self.assertEqual(h.get('http_auth_apikey'), None)\n        self.assertEqual(h.get('http_auth_password'), None)\n        self.assertEqual(h.get('http_auth_passwd'), None)\n        self.assertEqual(h.get('http_auth_secret'), None)\n        self.assertEqual(h.get('http_auth_api_key'), None)", "od": 0}
{"code": "def test_headline_node_insert_as_child(\n        parent_node, left_sibling_id, child_node, expected):\n    \"Does HeadlineNode.external_insert_as_child talk to Emacs correctly?\"\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._repl_make_headline_command.assert_called_with(expected)", "od": 0}
{"code": "def test_filename_node_insert_as_child(\n        parent_node, left_sibling_id, child_node, expected):\n    \"Does FilenameNode.external_insert_as_child talk to Emacs correctly?\"\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._repl_to_source_command.assert_called_with(expected)", "od": 0}
{"code": "def test_headline_node_insert_as_child_result():\n    \"Does HeadlineNode.external_insert_as_child update the child correctly?\"\n    parent_node = mock_headline_node()\n    left_sibling_id = \"1\"\n    child_node = mock_headline_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    assert child_node.id == MOCK_CREATED_HEADLINE_ID", "od": 0}
{"code": "def test_headline_node_update(current_node, new_node, expected):\n    \"Does HeadlineNode.external_update talk to Emacs correctly?\"\n    current_node.external_update(new_node)\n    current_node._repl_to_source_command.assert_called_with(expected)", "od": 0}
{"code": "def test_headline_node_move_to(child_node, pos, parent_node, expected):\n    \"Does HeadlineNode.external_move_to talk to Emacs correctly?\"\n    child_node.external_move_to(pos, parent_node)\n    child_node._repl_to_source_command.assert_called_with(expected)", "od": 0}
{"code": "def test_filename_node_move_to():\n    \"Does FilenameNode.external_move_to do nothing?\"\n    parent_node = mock_root_node()\n    left_sibling_id = \"1\"\n    child_node = mock_filename_node()\n    child_node.external_move_to(left_sibling_id, parent_node)\n    child_node._repl_to_source_command.assert_not_called()", "od": 0}
{"code": "def test_headline_node_delete(node_to_delete, expected):\n    \"Does HeadlineNode.external_delete talk to Emacs correctly?\"\n    node_to_delete.external_delete()\n    node_to_delete._repl_to_source_command.assert_called_with(expected)", "od": 0}
{"code": "def test_source_from_repl(source_class):\n    \"Can we make an Org Source from an Emacs REPL?\"\n    mock_repl = mock.Mock(['run_command'])\n    mock_child = mock.Mock(['sendeof'])\n    mock_repl.attach_mock(mock_child, 'child')\n    assert source_class.from_emacs_repl(mock_repl)", "od": 0}
{"code": "def test_source_get_all_items_result(org_source, expected):\n    \"Does Source.get_all_items listen to Emacs correctly?\"\n    result = org_source.get_all_items()\n    assert_trees_equal_p(result, expected)", "od": 0}
{"code": "def test_source_context():\n    \"Does an Org Source, as a context manager, talk to Emacs correctly?\"\n    org_source = mock_source()\n    with org_source:\n        org_source._repl_get_source_command.assert_called_with('(ts-init)')\n    org_source._repl_to_source_command.assert_called_with('(ts-final)')\n    org_source._repl_sendeof.assert_called()", "od": 0}
{"code": "def test_conformity(tree_b, tree_a):\n    edit_script.edit_script(tree_b, tree_a, map_fn, eql_fn, make_fn)\n    assert_trees_equal_p(tree_b, tree_a)", "od": 0}
{"code": "def test_a2o_behind_source_creation(mocker):\n    \"Can we get an Asana Source?\"\n    mocker.patch('asana.Client')\n    s = a2o.behind_source(None, dry_run=True)\n    assert isinstance(s, a.Source)", "od": 0}
{"code": "def test_a2o_ahead_source_creation(mocker):\n    \"Can we get an Org Source?\"\n    mocker.patch('pexpect.spawn')\n    mocker.patch('pexpect.replwrap.REPLWrapper')\n    s = a2o.ahead_source(None)\n    assert isinstance(s, o.Source)", "od": 0}
{"code": "def test_a2o_behind_get_tree(behind_source):\n    \"Does the Asana Source have a special get_tree method?\"\n    behind_source.get_tree()\n    behind_source.get_all_items.assert_called_with()", "od": 0}
{"code": "def test_a2o_ahead_get_tree(ahead_source):\n    \"Does the Org Source have a special get_tree method?\"\n    ahead_source.get_tree()\n    ahead_source.get_all_items.assert_called_with(\n        ['asana_id', 'asana_project_id'])", "od": 0}
{"code": "def test_a2o_behind_make_fn(o_node, expected_node, behind_source):\n    \"Does the Asana Source have a special make_fn method?\"\n    a_node = a2o.make_fn(behind_source, o_node)\n    assert_trees_equal_p(a_node, expected_node)", "od": 0}
{"code": "def test_a2o_map_fn(a_node, o_node, expected):\n    \"Can we map from Asana nodes to Org nodes?\"\n    assert a2o.map_fn(a_node, o_node) == expected", "od": 0}
{"code": "def test_a2o_eql_fn(a_node, o_node, expected):\n    \"Can we compare Asana nodes to Org nodes?\"\n    assert a2o.eql_fn(a_node, o_node) == expected", "od": 0}
{"code": "def test_o2a_behind_source_creation(mocker):\n    \"Can we get an Org Source?\"\n    mocker.patch('pexpect.spawn')\n    mocker.patch('pexpect.replwrap.REPLWrapper')\n    s = o2a.behind_source(None, dry_run=True)\n    assert isinstance(s, o.Source)", "od": 0}
{"code": "def test_o2a_ahead_source_creation(mocker):\n    \"Can we get an Asana Source?\"\n    mocker.patch('asana.Client')\n    s = o2a.ahead_source(None)\n    assert isinstance(s, a.Source)", "od": 0}
{"code": "def test_o2a_behind_get_tree(behind_source):\n    \"Does the Org Source have a special get_tree method?\"\n    behind_source.get_tree()\n    behind_source.get_all_items.assert_called_with(\n        ['asana_id', 'asana_project_id'])", "od": 0}
{"code": "def test_o2a_ahead_get_tree(ahead_source):\n    \"Does the Asana Source have a special get_tree method?\"\n    ahead_source.get_tree()\n    ahead_source.get_all_items.assert_called_with()", "od": 0}
{"code": "def test_o2a_behind_make_fn(a_node, expected_node, behind_source):\n    \"Does the Org Source have a special make_fn method?\"\n    o_node = behind_source.make_fn(a_node)\n    assert_trees_equal_p(o_node, expected_node, ['id'])", "od": 1}
{"code": "def test_o2a_map_fn(o_node, a_node, expected):\n    \"Can we map from Org nodes to Asana nodes?\"\n    assert o2a.map_fn(o_node, a_node) == expected", "od": 0}
{"code": "def test_o2a_eql_fn(o_node, a_node, expected):\n    \"Can we compare Org nodes to Asana nodes?\"\n    assert o2a.eql_fn(o_node, a_node) == expected", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_make_a_project():\n    \"Does TaskNode.external_insert_as_child create a project?\"\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    parent_node._project_create_in_workspace.assert_called_with(\n        MOCK_WORKSPACE_ID, params={'name': parent_node.name,\n                                   'archived': parent_node.completed})", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_set_project_id():\n    \"Does TaskNode.external_insert_as_child set the project id?\"\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    assert parent_node.project_id == MOCK_CREATED_PROJECT_ID", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_unset_parent():\n    \"Does TaskNode.external_insert_as_child unparent other subtasks?\"\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_tree(mock_task_node(),\n                             task_list=[{'id': 'A'}, {'id': 'B'}])\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    for c_node in parent_node.children:\n        c_node._task_set_parent.assert_called_with(\n            c_node.id, params={'parent': None})", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_add_subtasks():\n    \"Does TaskNode.external_insert_as_child add subtasks to the project in order?\"\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_tree(mock_task_node(),\n                             task_list=[{'id': 'A'}, {'id': 'B'}])\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    task_add_project_params = {'project': MOCK_CREATED_PROJECT_ID,\n                               'insert_after': None}\n    for c_node in parent_node.children:\n        c_node._task_add_project.assert_called_with(\n            c_node.id, params=task_add_project_params)\n        task_add_project_params['insert_after'] = c_node.id", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_make_a_task(\n        child_node, expected_task_create):\n    \"Does TaskNode.external_insert_as_child create a task?\"\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._task_create.assert_called_with(\n        params=expected_task_create)", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_make_a_tagged_task(\n        child_node, expected_task_create):\n    \"Does TaskNode.external_insert_as_child create a task with tags?\"\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._task_create.assert_called_with(\n        params=expected_task_create)", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_make_a_tag():\n    \"Does TaskNode.external_insert_as_child create new tags for tasks?\"\n    child_node = mock_task_node({'tags': {'morning'}},\n                                tag_dict={})\n    tag_name_lookup = child_node._tag_name_lookup\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    tag_name_lookup._tag_create_in_workspace.assert_called_with(\n        MOCK_WORKSPACE_ID, params={'name': 'morning'})", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_store_a_tag():\n    \"Does TaskNode.external_insert_as_child store new tags?\"\n    child_node = mock_task_node({'tags': {'morning'}},\n                                tag_dict={})\n    tag_name_lookup = child_node._tag_name_lookup\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    assert 'morning' in tag_name_lookup", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_set_task_id():\n    \"Does TaskNode.external_insert_as_child set the task id?\"\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    assert child_node.id == MOCK_CREATED_TASK_ID", "od": 0}
{"code": "def test_task_node_insert_as_child_under_task_add_project(\n        left_sibling_id, parent_node):\n    \"Does TaskNode.external_insert_as_child add the task to the project?\"\n    child_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._task_add_project.assert_called_with(\n        child_node.id, params={'project': MOCK_CREATED_PROJECT_ID,\n                               'insert_after': left_sibling_id})", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projectified_task_no_project():\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_projtask_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    parent_node._project_create_in_workspace.assert_not_called()", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projectified_task_no_reparent():\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_tree(mock_projtask_node(),\n                            task_list=[{'id': 'A'}, {'id': 'B'}])\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    for c_node in parent_node.children:\n        if c_node.id != child_node.id:\n            c_node._task_set_parent.assert_not_called()", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projectified_task_no_reproject():\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_tree(mock_projtask_node(),\n                            task_list=[{'id': 'A'}, {'id': 'B'}])\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    for c_node in parent_node.children:\n        if c_node.id != child_node.id:\n            c_node._task_add_project.assert_not_called()", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projectified_task_create_task(\n        parent_node, left_sibling_id, child_node, expected_task_create):\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._task_create.assert_called_with(\n        params=expected_task_create)", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projectified_task_set_task_id():\n    \"Does TaskNode.external_insert_as_child set the task id?\"\n    child_node = mock_task_node()\n    left_sibling_id = None\n    parent_node = mock_projtask_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    assert child_node.id == MOCK_CREATED_TASK_ID", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projectified_task_add_project(\n        left_sibling_id, parent_node):\n    \"Does TaskNode.external_insert_as_child add the task to the project?\"\n    child_node = mock_task_node()\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    child_node._task_add_project.assert_called_with(\n        child_node.id, params={'project': MOCK_EXTANT_PROJECT_ID,\n                               'insert_after': left_sibling_id})", "od": 0}
{"code": "def test_task_node_insert_as_child_under_project_nodes(\n        parent_node, left_sibling_id, child_node, expected_task_create,\n        expected_task_reparent):\n    \"Does TaskNode.external_insert_as_child talk to Asana correctly?\"\n    child_node.external_insert_as_child(left_sibling_id, parent_node)\n    parent_node._create_in_workspace.assert_not_called()\n    child_node._task_create.assert_called_with(\n        params=expected_task_create)\n    child_node._task_add_project.assert_called_with(\n        child_node.id, params=expected_task_reparent)", "od": 0}
{"code": "def test_project_node_insert_as_child(\n        parent_node, pos, child_node, expected_project_create):\n    \"Does ProjectNode.external_insert_as_child talk to Asana correctly?\"\n    child_node.external_insert_as_child(pos, parent_node)\n    child_node._create_in_workspace.assert_called_with(\n        MOCK_WORKSPACE_ID, params=expected_project_create)", "od": 0}
{"code": "def test_task_node_insert_as_child_under_projecty_node_result(\n        parent_node, pos, child_node):\n    \"Does TaskNode.external_insert_as_child update the child correctly?\"\n    child_node.external_insert_as_child(pos, parent_node)\n    assert child_node.id == MOCK_CREATED_TASK_ID", "od": 0}
{"code": "def test_project_node_insert_as_child_result():\n    \"Does ProjectNode.external_insert_as_child update the child correctly?\"\n    parent_node = mock_root_node()\n    pos = 0\n    child_node = mock_project_node()\n    child_node.external_insert_as_child(pos, parent_node)\n    assert child_node.id == MOCK_CREATED_PROJECT_ID", "od": 0}
{"code": "def test_task_node_update(current_node, new_node, expected):\n    \"Does TaskNode.external_update talk to Asana correctly?\"\n    current_node.external_update(new_node)\n    current_node._task_update.assert_called_with(current_node.id,\n                                                 params=expected)", "od": 0}
{"code": "def test_task_node_update_tags(current_node, new_node,\n                               expected_add, expected_remove):\n    \"Does TaskNode.external_update handle tags correctly?\"\n    current_node.external_update(new_node)\n    add_calls = [mock.call(current_node.id, params={'tag': t})\n                 for t in expected_add]\n    current_node._task_add_tag.assert_has_calls(add_calls, any_order=True)\n    remove_calls = [mock.call(current_node.id, params={'tag': t})\n                    for t in expected_remove]\n    current_node._task_remove_tag.assert_has_calls(\n        remove_calls, any_order=True)\n    current_node._task_update.assert_not_called()", "od": 0}
{"code": "def test_task_node_update_tags_noop():\n    \"Does TaskNode.external_update handle tags correctly?\"\n    current_node = mock_task_node({'tags': {'project'}})\n    new_node = mock_task_node({'tags': {'project'}})\n    current_node.external_update(new_node)\n    current_node._task_add_tag.assert_not_called()\n    current_node._task_remove_tag.assert_not_called()", "od": 0}
{"code": "def test_projectified_task_node_update(\n        current_node, new_node, expected_task_update,\n        expected_project_update):\n    \"Does TaskNode.external_update talk to Asana correctly?\"\n    current_node.external_update(new_node)\n    current_node._task_update.assert_called_with(\n        current_node.id, params=expected_task_update)\n    current_node._project_update.assert_called_with(\n        current_node.project_id, params=expected_project_update)", "od": 0}
{"code": "def test_project_node_update(current_node, new_node, expected):\n    \"Does ProjectNode.external_update talk to Asana correctly?\"\n    current_node.external_update(new_node)\n    current_node._update.assert_called_with(current_node.id,\n                                            params=expected)", "od": 0}
{"code": "def test_task_node_move_to_task(\n        child_node, left_sibling_id, parent_node, expected_project_create,\n        expected_task_reparent):\n    \"Does TaskNode.external_move_to talk to Asana correctly?\"\n    old_parent_node = child_node.parent\n    child_node.external_move_to(left_sibling_id, parent_node)\n    parent_node._project_create_in_workspace.assert_called_with(\n        MOCK_WORKSPACE_ID, params=expected_project_create)\n    new_left_sibling_id = None\n    for c_node in parent_node.children:\n        expected_task_reparent['insert_after'] = new_left_sibling_id\n        c_node._task_set_parent.assert_called_with(\n            c_node.id, params={'parent': None})\n        c_node._task_add_project.assert_called_with(\n            c_node.id, params=expected_task_reparent)\n        new_left_sibling_id = c_node.id\n    expected_task_reparent['insert_after'] = left_sibling_id\n    if old_parent_node:\n        if old_parent_node.project_id:\n            child_node._task_remove_project.assert_called_with(\n                child_node.id, params={\n                    'project': old_parent_node.project_id})\n        else:\n            child_node._task_set_parent.assert_called_with(\n                child_node.id, params={'parent': None})\n    child_node._task_add_project.assert_called_with(\n        child_node.id, params=expected_task_reparent)", "od": 0}
{"code": "def test_task_node_move_to_projectified_task_node(\n        child_node, left_sibling_id, parent_node, expected_task_reparent):\n    \"Does TaskNode.external_move_to talk to Asana correctly?\"\n    old_parent_node = child_node.parent\n    child_node.external_move_to(left_sibling_id, parent_node)\n    parent_node._project_create_in_workspace.assert_not_called()\n    if old_parent_node:\n        if old_parent_node.project_id:\n            child_node._task_remove_project.assert_called_with(\n                child_node.id, params={\n                    'project': old_parent_node.project_id})\n        else:\n            child_node._task_set_parent.assert_called_with(\n                child_node.id, params={'parent': None})\n    child_node._task_add_project.assert_called_with(\n        child_node.id, params=expected_task_reparent)", "od": 0}
{"code": "def test_task_node_move_to_project_node(\n        child_node, left_sibling_id, parent_node, expected_task_reparent):\n    \"Does TaskNode.external_move_to talk to Asana correctly?\"\n    child_node.external_move_to(left_sibling_id, parent_node)\n    parent_node._create_in_workspace.assert_not_called()\n    child_node._task_add_project.assert_called_with(\n        child_node.id, params=expected_task_reparent)", "od": 0}
{"code": "def test_task_node_delete():\n    \"Does TaskNode.external_delete talk to Asana correctly?\"\n    node = mock_task_node({'id': 1})\n    node.external_delete()\n    node._task_delete.assert_called_with(node.id)", "od": 0}
{"code": "def test_projectified_task_node_delete():\n    \"Does TaskNode.external_delete talk to Asana correctly?\"\n    node = mock_task_node({'id': 1, 'project_id': 1})\n    node.external_delete()\n    node._task_delete.assert_called_with(node.id)\n    node._project_delete.assert_called_with(node.project_id)", "od": 0}
{"code": "def test_project_node_delete():\n    \"Does ProjectNode.external_delete talk to Asana correctly?\"\n    node = mock_project_node({'id': 1})\n    node.external_delete()\n    node._delete.assert_called_with(node.id)", "od": 0}
{"code": "def test_source_from_client(source_class):\n    \"Can we make an Asana Source from an Asana Client?\"\n    mock_client = mock.Mock(asana.Client)\n    users_kwargs = {'me.return_value':\n                    {'workspaces': [{'id': MOCK_WORKSPACE_ID}]}}\n    mock_users = mock.Mock(asana.resources.users.Users, **users_kwargs)\n    mock_client.attach_mock(mock_users, 'users')\n    mock_projects = mock.Mock(asana.resources.projects.Projects)\n    mock_client.attach_mock(mock_projects, 'projects')\n    mock_tasks = mock.Mock(asana.resources.tasks.Tasks)\n    mock_client.attach_mock(mock_tasks, 'tasks')\n    mock_tags = mock.Mock(asana.resources.tags.Tags)\n    mock_client.attach_mock(mock_tags, 'tags')\n    assert source_class.from_client(mock_client)", "od": 0}
{"code": "def test_source_get_all_items_result(asana_source, expected):\n    \"Does Source.get_all_items listen to Asana correctly?\"\n    result = asana_source.get_all_items()\n    assert_trees_equal_p(result, expected)", "od": 0}
{"code": "def test_source_get_all_items(asana_source, expected_fields):\n    \"Does Source.get_all_items talk to Asana correctly?\"\n    asana_source.get_all_items()\n    asana_source._project_find_by_workspace.assert_called_with(\n        asana_source._w_id, params={'archived': False})\n    asana_source._task_find_all.assert_called_with(\n        params={'assignee': 'me', 'workspace': asana_source._w_id},\n        fields=expected_fields)", "od": 0}
{"code": "def test_node_insert_as_child(parent_node, left_sibling_id, child_node,\n                              expected_node):\n    \"Can a node insert itself as a child?\"\n    child_node.insert_as_child(left_sibling_id, parent_node)\n    assert_trees_equal_p(parent_node, expected_node)", "od": 0}
{"code": "def test_node_delete(parent_node, child_pos_to_delete, expected_node):\n    \"Can a node delete itself?\"\n    parent_node.children[child_pos_to_delete].delete()\n    assert_trees_equal_p(parent_node, expected_node)", "od": 0}
{"code": "def test_node_update(node_to_update, target_node, expected_node):\n    \"Can a node update itself from another node?\"\n    node_to_update.update(target_node)\n    assert_trees_equal_p(node_to_update, expected_node)", "od": 0}
{"code": "def test_node_move_to(node_to_move, left_sibling_id, parent_node,\n                      expected_node):\n    \"Can a node reparent itself under another node?\"\n    node_to_move.move_to(left_sibling_id, parent_node)\n    assert_trees_equal_p(parent_node, expected_node)", "od": 0}
